1+8+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-1-shot-8
textattack: Updating TextAttack package dependencies.
textattack: Downloading NLTK required packages.
2024-03-08 08:43:49.305782: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 08:43:50.095900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /root/nltk_data...
[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.
[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Unzipping corpora/stopwords.zip.
[nltk_data] Downloading package omw to /root/nltk_data...
[nltk_data] Downloading package universal_tagset to /root/nltk_data...
[nltk_data]   Unzipping taggers/universal_tagset.zip.
[nltk_data] Downloading package wordnet to /root/nltk_data...
[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt.zip.
textattack: Downloading https://textattack.s3.amazonaws.com/word_embeddings/paragramcf.
  0%|          | 0.00/481M [00:00<?, ?B/s]  0%|          | 69.6k/481M [00:00<20:10, 398kB/s]  0%|          | 279k/481M [00:00<09:20, 858kB/s]   0%|          | 1.22M/481M [00:00<02:46, 2.89MB/s]  1%|          | 3.64M/481M [00:00<00:55, 8.62MB/s]  2%|▏         | 7.23M/481M [00:00<00:34, 13.7MB/s]  2%|▏         | 10.7M/481M [00:00<00:24, 18.9MB/s]  3%|▎         | 14.3M/481M [00:00<00:19, 23.6MB/s]  4%|▎         | 17.0M/481M [00:01<00:22, 21.0MB/s]  4%|▍         | 20.5M/481M [00:01<00:18, 24.7MB/s]  5%|▌         | 24.2M/481M [00:01<00:19, 23.5MB/s]  6%|▌         | 27.9M/481M [00:01<00:16, 26.9MB/s]  7%|▋         | 31.6M/481M [00:01<00:17, 25.2MB/s]  7%|▋         | 35.3M/481M [00:01<00:16, 27.8MB/s]  8%|▊         | 38.9M/481M [00:01<00:17, 25.7MB/s]  9%|▉         | 42.7M/481M [00:02<00:15, 28.5MB/s] 10%|▉         | 46.5M/481M [00:02<00:14, 30.8MB/s] 10%|█         | 49.7M/481M [00:02<00:16, 26.7MB/s] 11%|█         | 53.5M/481M [00:02<00:14, 29.4MB/s] 12%|█▏        | 56.7M/481M [00:02<00:16, 25.7MB/s] 12%|█▏        | 60.0M/481M [00:02<00:15, 27.4MB/s] 13%|█▎        | 64.0M/481M [00:02<00:13, 30.8MB/s] 14%|█▍        | 67.3M/481M [00:02<00:15, 27.1MB/s] 15%|█▍        | 71.3M/481M [00:03<00:13, 30.3MB/s] 15%|█▌        | 74.6M/481M [00:03<00:13, 31.1MB/s] 16%|█▌        | 77.9M/481M [00:03<00:14, 27.4MB/s] 17%|█▋        | 81.6M/481M [00:03<00:13, 29.8MB/s] 18%|█▊        | 85.0M/481M [00:03<00:12, 30.8MB/s] 18%|█▊        | 88.3M/481M [00:03<00:14, 27.5MB/s] 19%|█▉        | 92.2M/481M [00:03<00:12, 30.5MB/s] 20%|█▉        | 95.5M/481M [00:03<00:12, 31.2MB/s] 21%|██        | 99.1M/481M [00:04<00:13, 27.9MB/s] 21%|██▏       | 103M/481M [00:04<00:12, 31.0MB/s]  22%|██▏       | 106M/481M [00:04<00:11, 31.4MB/s] 23%|██▎       | 110M/481M [00:04<00:13, 28.5MB/s] 24%|██▎       | 114M/481M [00:04<00:11, 31.2MB/s] 24%|██▍       | 117M/481M [00:04<00:11, 31.6MB/s] 25%|██▌       | 121M/481M [00:04<00:12, 28.5MB/s] 26%|██▌       | 125M/481M [00:04<00:11, 31.2MB/s] 27%|██▋       | 129M/481M [00:04<00:10, 33.1MB/s] 27%|██▋       | 132M/481M [00:05<00:12, 28.8MB/s] 28%|██▊       | 136M/481M [00:05<00:11, 31.1MB/s] 29%|██▉       | 140M/481M [00:05<00:10, 33.9MB/s] 30%|██▉       | 144M/481M [00:05<00:10, 32.2MB/s] 31%|███       | 147M/481M [00:05<00:10, 31.0MB/s] 31%|███▏      | 151M/481M [00:05<00:10, 32.1MB/s] 32%|███▏      | 154M/481M [00:05<00:09, 34.0MB/s] 33%|███▎      | 158M/481M [00:05<00:10, 31.9MB/s] 34%|███▎      | 162M/481M [00:05<00:10, 31.7MB/s] 34%|███▍      | 165M/481M [00:06<00:09, 32.6MB/s] 35%|███▌      | 169M/481M [00:06<00:08, 34.8MB/s] 36%|███▌      | 173M/481M [00:06<00:09, 32.4MB/s] 37%|███▋      | 176M/481M [00:06<00:09, 31.7MB/s] 37%|███▋      | 180M/481M [00:06<00:09, 32.3MB/s] 38%|███▊      | 184M/481M [00:06<00:08, 34.3MB/s] 39%|███▉      | 187M/481M [00:06<00:09, 32.1MB/s] 40%|███▉      | 191M/481M [00:06<00:08, 32.7MB/s] 40%|████      | 194M/481M [00:06<00:09, 31.5MB/s] 41%|████      | 198M/481M [00:07<00:08, 33.3MB/s] 42%|████▏     | 201M/481M [00:07<00:08, 31.9MB/s] 43%|████▎     | 205M/481M [00:07<00:08, 30.8MB/s] 43%|████▎     | 209M/481M [00:07<00:08, 32.4MB/s] 44%|████▍     | 212M/481M [00:07<00:07, 34.0MB/s] 45%|████▍     | 216M/481M [00:07<00:08, 32.1MB/s] 46%|████▌     | 219M/481M [00:07<00:08, 30.2MB/s] 46%|████▋     | 223M/481M [00:07<00:08, 31.8MB/s] 47%|████▋     | 227M/481M [00:07<00:07, 34.0MB/s] 48%|████▊     | 230M/481M [00:08<00:07, 32.0MB/s] 48%|████▊     | 233M/481M [00:08<00:08, 30.0MB/s] 49%|████▉     | 237M/481M [00:08<00:07, 32.4MB/s] 50%|█████     | 241M/481M [00:08<00:07, 31.7MB/s] 51%|█████     | 245M/481M [00:08<00:07, 30.2MB/s] 52%|█████▏    | 248M/481M [00:08<00:07, 31.9MB/s] 52%|█████▏    | 252M/481M [00:08<00:06, 34.7MB/s] 53%|█████▎    | 256M/481M [00:08<00:06, 32.5MB/s] 54%|█████▍    | 259M/481M [00:09<00:07, 30.8MB/s] 55%|█████▍    | 263M/481M [00:09<00:06, 32.6MB/s] 55%|█████▌    | 267M/481M [00:09<00:06, 32.2MB/s] 56%|█████▌    | 271M/481M [00:09<00:06, 31.3MB/s] 57%|█████▋    | 274M/481M [00:09<00:06, 32.8MB/s] 58%|█████▊    | 279M/481M [00:09<00:05, 35.0MB/s] 59%|█████▊    | 282M/481M [00:09<00:06, 33.0MB/s] 59%|█████▉    | 285M/481M [00:09<00:06, 31.0MB/s] 60%|██████    | 289M/481M [00:09<00:05, 33.5MB/s] 61%|██████    | 293M/481M [00:10<00:05, 32.5MB/s] 62%|██████▏   | 297M/481M [00:10<00:05, 30.8MB/s] 62%|██████▏   | 301M/481M [00:10<00:05, 33.0MB/s] 63%|██████▎   | 305M/481M [00:10<00:05, 34.8MB/s] 64%|██████▍   | 308M/481M [00:10<00:05, 32.9MB/s] 65%|██████▍   | 312M/481M [00:10<00:05, 28.8MB/s] 65%|██████▌   | 315M/481M [00:10<00:06, 26.4MB/s] 66%|██████▋   | 319M/481M [00:10<00:05, 29.5MB/s] 67%|██████▋   | 323M/481M [00:11<00:05, 31.4MB/s] 68%|██████▊   | 326M/481M [00:11<00:05, 27.1MB/s] 69%|██████▊   | 330M/481M [00:11<00:05, 29.7MB/s] 69%|██████▉   | 333M/481M [00:11<00:05, 25.9MB/s] 70%|██████▉   | 337M/481M [00:11<00:05, 28.8MB/s] 71%|███████   | 340M/481M [00:11<00:05, 25.3MB/s] 71%|███████▏  | 344M/481M [00:11<00:04, 27.8MB/s] 72%|███████▏  | 347M/481M [00:11<00:05, 25.5MB/s] 73%|███████▎  | 351M/481M [00:12<00:04, 27.9MB/s] 74%|███████▎  | 354M/481M [00:12<00:04, 25.5MB/s] 74%|███████▍  | 358M/481M [00:12<00:04, 27.8MB/s] 75%|███████▌  | 361M/481M [00:12<00:04, 25.1MB/s] 76%|███████▌  | 365M/481M [00:12<00:04, 27.2MB/s] 76%|███████▋  | 368M/481M [00:12<00:04, 24.9MB/s] 77%|███████▋  | 372M/481M [00:12<00:04, 27.2MB/s] 78%|███████▊  | 375M/481M [00:13<00:04, 24.9MB/s] 79%|███████▊  | 379M/481M [00:13<00:03, 27.2MB/s] 79%|███████▉  | 382M/481M [00:13<00:03, 25.1MB/s] 80%|████████  | 386M/481M [00:13<00:03, 27.6MB/s] 81%|████████  | 389M/481M [00:13<00:03, 25.3MB/s] 82%|████████▏ | 393M/481M [00:13<00:03, 28.0MB/s] 82%|████████▏ | 397M/481M [00:13<00:03, 25.6MB/s] 83%|████████▎ | 400M/481M [00:13<00:02, 28.1MB/s] 84%|████████▍ | 404M/481M [00:14<00:03, 25.7MB/s] 85%|████████▍ | 407M/481M [00:14<00:02, 27.8MB/s] 85%|████████▌ | 411M/481M [00:14<00:02, 25.6MB/s] 86%|████████▌ | 415M/481M [00:14<00:02, 27.9MB/s] 87%|████████▋ | 418M/481M [00:14<00:02, 25.6MB/s] 88%|████████▊ | 422M/481M [00:14<00:02, 28.0MB/s] 88%|████████▊ | 425M/481M [00:14<00:02, 25.5MB/s] 89%|████████▉ | 429M/481M [00:15<00:01, 27.8MB/s] 90%|████████▉ | 432M/481M [00:15<00:01, 25.1MB/s] 90%|█████████ | 436M/481M [00:15<00:01, 27.4MB/s] 91%|█████████ | 439M/481M [00:15<00:01, 24.8MB/s] 92%|█████████▏| 442M/481M [00:15<00:01, 26.9MB/s] 93%|█████████▎| 446M/481M [00:15<00:01, 24.5MB/s] 93%|█████████▎| 449M/481M [00:15<00:01, 26.8MB/s] 94%|█████████▍| 453M/481M [00:15<00:01, 24.3MB/s] 95%|█████████▍| 456M/481M [00:16<00:00, 26.4MB/s] 95%|█████████▌| 459M/481M [00:16<00:00, 24.5MB/s] 96%|█████████▌| 463M/481M [00:16<00:00, 27.2MB/s] 97%|█████████▋| 467M/481M [00:16<00:00, 25.1MB/s] 98%|█████████▊| 470M/481M [00:16<00:00, 27.5MB/s] 98%|█████████▊| 474M/481M [00:16<00:00, 25.4MB/s] 99%|█████████▉| 477M/481M [00:16<00:00, 27.8MB/s]100%|█████████▉| 481M/481M [00:17<00:00, 25.7MB/s]100%|██████████| 481M/481M [00:17<00:00, 28.2MB/s]
textattack: Unzipping file /root/.cache/textattack/tmpaabkfxkt.zip to /root/.cache/textattack/word_embeddings/paragramcf.
textattack: Successfully saved word_embeddings/paragramcf to cache.
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]Downloading builder script: 4.21kB [00:00, 20.0MB/s]                   2024-03-08 08:44:19.636212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:44:19.645107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:44:19.647531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:44:19.661392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:44:19.663809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:44:19.666181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:44:19.847769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:44:19.849422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:44:19.850888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:44:19.852376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0

Downloading builder script:   0%|          | 0.00/5.03k [00:00<?, ?B/s]Downloading builder script: 100%|██████████| 5.03k/5.03k [00:00<00:00, 27.8MB/s]
Downloading readme:   0%|          | 0.00/7.25k [00:00<?, ?B/s]Downloading readme: 100%|██████████| 7.25k/7.25k [00:00<00:00, 38.6MB/s]
Downloading data:   0%|          | 0.00/488k [00:00<?, ?B/s]Downloading data: 100%|██████████| 488k/488k [00:00<00:00, 5.37MB/s]
Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]Generating train split:  57%|█████▋    | 4834/8530 [00:00<00:00, 47895.38 examples/s]Generating train split: 100%|██████████| 8530/8530 [00:00<00:00, 50755.74 examples/s]
Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]Generating validation split: 100%|██████████| 1066/1066 [00:00<00:00, 33896.32 examples/s]
Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 1066/1066 [00:00<00:00, 36479.35 examples/s]
Map:   0%|          | 0/8530 [00:00<?, ? examples/s]Map:  28%|██▊       | 2377/8530 [00:00<00:00, 23609.04 examples/s]Map:  56%|█████▌    | 4791/8530 [00:00<00:00, 23910.44 examples/s]Map:  85%|████████▍ | 7241/8530 [00:00<00:00, 24064.20 examples/s]Map: 100%|██████████| 8530/8530 [00:00<00:00, 23820.13 examples/s]
Map:   0%|          | 0/1066 [00:00<?, ? examples/s]Map: 100%|██████████| 1066/1066 [00:00<00:00, 22448.35 examples/s]
Map:   0%|          | 0/1066 [00:00<?, ? examples/s]Map: 100%|██████████| 1066/1066 [00:00<00:00, 22524.69 examples/s]
Map:   0%|          | 0/8103 [00:00<?, ? examples/s]Map:  16%|█▌        | 1280/8103 [00:00<00:00, 12726.34 examples/s]Map:  32%|███▏      | 2561/8103 [00:00<00:00, 12770.15 examples/s]Map:  48%|████▊     | 3900/8103 [00:00<00:00, 13050.67 examples/s]Map:  72%|███████▏  | 5854/8103 [00:00<00:00, 13035.21 examples/s]Map:  96%|█████████▌| 7778/8103 [00:00<00:00, 12943.92 examples/s]Map: 100%|██████████| 8103/8103 [00:00<00:00, 12887.47 examples/s]
Map:   0%|          | 0/1066 [00:00<?, ? examples/s]Map: 100%|██████████| 1066/1066 [00:00<00:00, 22041.11 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 23637.61 examples/s]
Downloading tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]Downloading tokenizer_config.json: 100%|██████████| 776/776 [00:00<00:00, 227kB/s]
Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]Downloading tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 7.77MB/s]
Downloading tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]Downloading tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 12.2MB/s]Downloading tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 12.1MB/s]
Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|██████████| 414/414 [00:00<00:00, 390kB/s]
Downloading config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]Downloading config.json: 100%|██████████| 609/609 [00:00<00:00, 153kB/s]
Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]Downloading (…)fetensors.index.json: 100%|██████████| 26.8k/26.8k [00:00<00:00, 24.9MB/s]
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s][A
Downloading (…)of-00002.safetensors:   0%|          | 10.5M/9.98G [00:00<03:09, 52.7MB/s][A
Downloading (…)of-00002.safetensors:   0%|          | 31.5M/9.98G [00:00<01:48, 91.6MB/s][A
Downloading (…)of-00002.safetensors:   0%|          | 41.9M/9.98G [00:00<01:49, 90.7MB/s][A
Downloading (…)of-00002.safetensors:   1%|          | 52.4M/9.98G [00:00<01:48, 91.3MB/s][A
Downloading (…)of-00002.safetensors:   1%|          | 62.9M/9.98G [00:00<01:47, 92.0MB/s][A
Downloading (…)of-00002.safetensors:   1%|          | 73.4M/9.98G [00:00<01:48, 91.3MB/s][A
Downloading (…)of-00002.safetensors:   1%|          | 83.9M/9.98G [00:00<01:47, 92.2MB/s][A
Downloading (…)of-00002.safetensors:   1%|          | 94.4M/9.98G [00:01<01:55, 85.7MB/s][A
Downloading (…)of-00002.safetensors:   1%|          | 105M/9.98G [00:01<01:53, 87.0MB/s] [A
Downloading (…)of-00002.safetensors:   1%|          | 115M/9.98G [00:01<01:50, 89.0MB/s][A
Downloading (…)of-00002.safetensors:   1%|▏         | 126M/9.98G [00:01<01:48, 90.5MB/s][A
Downloading (…)of-00002.safetensors:   1%|▏         | 136M/9.98G [00:01<01:49, 89.6MB/s][A
Downloading (…)of-00002.safetensors:   1%|▏         | 147M/9.98G [00:01<01:48, 91.0MB/s][A
Downloading (…)of-00002.safetensors:   2%|▏         | 157M/9.98G [00:01<01:48, 90.5MB/s][A
Downloading (…)of-00002.safetensors:   2%|▏         | 168M/9.98G [00:01<01:49, 89.3MB/s][A
Downloading (…)of-00002.safetensors:   2%|▏         | 178M/9.98G [00:02<01:47, 90.9MB/s][A
Downloading (…)of-00002.safetensors:   2%|▏         | 189M/9.98G [00:02<01:47, 90.9MB/s][A
Downloading (…)of-00002.safetensors:   2%|▏         | 199M/9.98G [00:02<01:48, 90.3MB/s][A
Downloading (…)of-00002.safetensors:   2%|▏         | 210M/9.98G [00:02<01:49, 89.5MB/s][A
Downloading (…)of-00002.safetensors:   2%|▏         | 220M/9.98G [00:02<01:47, 90.9MB/s][A
Downloading (…)of-00002.safetensors:   2%|▏         | 231M/9.98G [00:02<01:46, 91.7MB/s][A
Downloading (…)of-00002.safetensors:   2%|▏         | 241M/9.98G [00:02<01:48, 89.4MB/s][A
Downloading (…)of-00002.safetensors:   3%|▎         | 252M/9.98G [00:02<01:47, 90.6MB/s][A
Downloading (…)of-00002.safetensors:   3%|▎         | 262M/9.98G [00:02<01:46, 90.9MB/s][A
Downloading (…)of-00002.safetensors:   3%|▎         | 273M/9.98G [00:03<01:46, 91.1MB/s][A
Downloading (…)of-00002.safetensors:   3%|▎         | 283M/9.98G [00:03<01:46, 91.3MB/s][A
Downloading (…)of-00002.safetensors:   3%|▎         | 294M/9.98G [00:03<01:46, 91.1MB/s][A
Downloading (…)of-00002.safetensors:   3%|▎         | 304M/9.98G [00:03<01:45, 91.3MB/s][A
Downloading (…)of-00002.safetensors:   3%|▎         | 315M/9.98G [00:03<01:45, 91.9MB/s][A
Downloading (…)of-00002.safetensors:   3%|▎         | 325M/9.98G [00:03<01:45, 91.3MB/s][A
Downloading (…)of-00002.safetensors:   3%|▎         | 336M/9.98G [00:03<01:44, 92.2MB/s][A
Downloading (…)of-00002.safetensors:   3%|▎         | 346M/9.98G [00:03<01:45, 90.9MB/s][A
Downloading (…)of-00002.safetensors:   4%|▎         | 357M/9.98G [00:03<01:45, 90.9MB/s][A
Downloading (…)of-00002.safetensors:   4%|▎         | 367M/9.98G [00:04<01:45, 91.2MB/s][A
Downloading (…)of-00002.safetensors:   4%|▍         | 377M/9.98G [00:04<01:44, 91.7MB/s][A
Downloading (…)of-00002.safetensors:   4%|▍         | 388M/9.98G [00:04<01:44, 91.8MB/s][A
Downloading (…)of-00002.safetensors:   4%|▍         | 398M/9.98G [00:04<01:45, 91.2MB/s][A
Downloading (…)of-00002.safetensors:   4%|▍         | 409M/9.98G [00:04<01:43, 92.0MB/s][A
Downloading (…)of-00002.safetensors:   4%|▍         | 419M/9.98G [00:04<01:42, 92.9MB/s][A
Downloading (…)of-00002.safetensors:   4%|▍         | 430M/9.98G [00:04<01:44, 91.8MB/s][A
Downloading (…)of-00002.safetensors:   4%|▍         | 440M/9.98G [00:04<01:42, 93.4MB/s][A
Downloading (…)of-00002.safetensors:   5%|▍         | 451M/9.98G [00:04<01:41, 94.2MB/s][A
Downloading (…)of-00002.safetensors:   5%|▍         | 461M/9.98G [00:05<01:46, 89.5MB/s][A
Downloading (…)of-00002.safetensors:   5%|▍         | 472M/9.98G [00:05<01:44, 90.9MB/s][A
Downloading (…)of-00002.safetensors:   5%|▍         | 482M/9.98G [00:05<01:43, 91.7MB/s][A
Downloading (…)of-00002.safetensors:   5%|▍         | 493M/9.98G [00:05<01:42, 92.5MB/s][A
Downloading (…)of-00002.safetensors:   5%|▌         | 503M/9.98G [00:05<01:43, 91.8MB/s][A
Downloading (…)of-00002.safetensors:   5%|▌         | 514M/9.98G [00:05<01:47, 88.3MB/s][A
Downloading (…)of-00002.safetensors:   5%|▌         | 524M/9.98G [00:05<01:45, 89.9MB/s][A
Downloading (…)of-00002.safetensors:   5%|▌         | 535M/9.98G [00:05<01:43, 91.1MB/s][A
Downloading (…)of-00002.safetensors:   5%|▌         | 545M/9.98G [00:06<01:43, 91.0MB/s][A
Downloading (…)of-00002.safetensors:   6%|▌         | 556M/9.98G [00:06<01:42, 92.0MB/s][A
Downloading (…)of-00002.safetensors:   6%|▌         | 566M/9.98G [00:06<01:44, 90.2MB/s][A
Downloading (…)of-00002.safetensors:   6%|▌         | 577M/9.98G [00:06<01:44, 90.3MB/s][A
Downloading (…)of-00002.safetensors:   6%|▌         | 587M/9.98G [00:06<01:43, 90.3MB/s][A
Downloading (…)of-00002.safetensors:   6%|▌         | 598M/9.98G [00:06<01:43, 90.8MB/s][A
Downloading (…)of-00002.safetensors:   6%|▌         | 608M/9.98G [00:06<01:41, 92.0MB/s][A
Downloading (…)of-00002.safetensors:   6%|▌         | 619M/9.98G [00:06<01:41, 92.6MB/s][A
Downloading (…)of-00002.safetensors:   6%|▋         | 629M/9.98G [00:06<01:45, 88.5MB/s][A
Downloading (…)of-00002.safetensors:   6%|▋         | 640M/9.98G [00:07<01:42, 90.7MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 650M/9.98G [00:07<01:41, 91.7MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 661M/9.98G [00:07<01:40, 92.9MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 671M/9.98G [00:07<01:42, 91.1MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 682M/9.98G [00:07<01:42, 91.1MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 692M/9.98G [00:07<01:40, 92.2MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 703M/9.98G [00:07<01:38, 93.8MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 713M/9.98G [00:07<01:38, 93.6MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 724M/9.98G [00:07<01:40, 92.0MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 734M/9.98G [00:08<01:38, 93.6MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 744M/9.98G [00:08<01:40, 91.8MB/s][A
Downloading (…)of-00002.safetensors:   8%|▊         | 755M/9.98G [00:08<01:43, 89.0MB/s][A
Downloading (…)of-00002.safetensors:   8%|▊         | 765M/9.98G [00:08<01:47, 85.8MB/s][A
Downloading (…)of-00002.safetensors:   8%|▊         | 776M/9.98G [00:08<01:44, 87.7MB/s][A
Downloading (…)of-00002.safetensors:   8%|▊         | 786M/9.98G [00:08<01:45, 87.0MB/s][A
Downloading (…)of-00002.safetensors:   8%|▊         | 797M/9.98G [00:08<01:44, 88.2MB/s][A
Downloading (…)of-00002.safetensors:   8%|▊         | 807M/9.98G [00:08<01:42, 89.6MB/s][A
Downloading (…)of-00002.safetensors:   8%|▊         | 818M/9.98G [00:09<01:45, 87.1MB/s][A
Downloading (…)of-00002.safetensors:   8%|▊         | 828M/9.98G [00:09<01:42, 88.8MB/s][A
Downloading (…)of-00002.safetensors:   8%|▊         | 839M/9.98G [00:09<01:42, 89.4MB/s][A
Downloading (…)of-00002.safetensors:   9%|▊         | 849M/9.98G [00:09<01:41, 90.1MB/s][A
Downloading (…)of-00002.safetensors:   9%|▊         | 860M/9.98G [00:09<01:39, 91.3MB/s][A
Downloading (…)of-00002.safetensors:   9%|▊         | 870M/9.98G [00:09<01:39, 91.1MB/s][A
Downloading (…)of-00002.safetensors:   9%|▉         | 881M/9.98G [00:09<01:48, 83.9MB/s][A
Downloading (…)of-00002.safetensors:   9%|▉         | 891M/9.98G [00:09<01:46, 85.7MB/s][A
Downloading (…)of-00002.safetensors:   9%|▉         | 902M/9.98G [00:09<01:43, 87.3MB/s][A
Downloading (…)of-00002.safetensors:   9%|▉         | 912M/9.98G [00:10<01:43, 87.8MB/s][A
Downloading (…)of-00002.safetensors:   9%|▉         | 923M/9.98G [00:10<01:42, 88.7MB/s][A
Downloading (…)of-00002.safetensors:   9%|▉         | 933M/9.98G [00:10<01:40, 89.9MB/s][A
Downloading (…)of-00002.safetensors:   9%|▉         | 944M/9.98G [00:10<01:39, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  10%|▉         | 954M/9.98G [00:10<01:39, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  10%|▉         | 965M/9.98G [00:10<01:39, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  10%|▉         | 975M/9.98G [00:10<01:40, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  10%|▉         | 986M/9.98G [00:10<01:40, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  10%|▉         | 996M/9.98G [00:11<01:42, 87.4MB/s][A
Downloading (…)of-00002.safetensors:  10%|█         | 1.01G/9.98G [00:11<01:40, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  10%|█         | 1.02G/9.98G [00:11<01:39, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  10%|█         | 1.03G/9.98G [00:11<01:39, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  10%|█         | 1.04G/9.98G [00:11<01:38, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  11%|█         | 1.05G/9.98G [00:11<01:38, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  11%|█         | 1.06G/9.98G [00:11<01:38, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  11%|█         | 1.07G/9.98G [00:11<01:45, 84.5MB/s][A
Downloading (…)of-00002.safetensors:  11%|█         | 1.08G/9.98G [00:11<01:42, 86.6MB/s][A
Downloading (…)of-00002.safetensors:  11%|█         | 1.09G/9.98G [00:12<01:43, 85.9MB/s][A
Downloading (…)of-00002.safetensors:  11%|█         | 1.10G/9.98G [00:12<01:40, 88.0MB/s][A
Downloading (…)of-00002.safetensors:  11%|█         | 1.11G/9.98G [00:12<01:39, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  11%|█         | 1.12G/9.98G [00:12<01:38, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  11%|█▏        | 1.13G/9.98G [00:12<01:36, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  11%|█▏        | 1.14G/9.98G [00:12<01:36, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  12%|█▏        | 1.15G/9.98G [00:12<01:35, 92.5MB/s][A
Downloading (…)of-00002.safetensors:  12%|█▏        | 1.16G/9.98G [00:12<01:34, 93.1MB/s][A
Downloading (…)of-00002.safetensors:  12%|█▏        | 1.17G/9.98G [00:13<01:34, 92.8MB/s][A
Downloading (…)of-00002.safetensors:  12%|█▏        | 1.18G/9.98G [00:13<01:35, 92.5MB/s][A
Downloading (…)of-00002.safetensors:  12%|█▏        | 1.20G/9.98G [00:13<01:35, 92.3MB/s][A
Downloading (…)of-00002.safetensors:  12%|█▏        | 1.21G/9.98G [00:13<01:37, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  12%|█▏        | 1.22G/9.98G [00:13<01:36, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  12%|█▏        | 1.23G/9.98G [00:13<01:39, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  12%|█▏        | 1.24G/9.98G [00:13<01:41, 85.7MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 1.25G/9.98G [00:13<01:40, 87.2MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 1.26G/9.98G [00:13<01:40, 86.7MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 1.27G/9.98G [00:14<01:37, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 1.28G/9.98G [00:14<01:36, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 1.29G/9.98G [00:14<01:35, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 1.30G/9.98G [00:14<01:34, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 1.31G/9.98G [00:14<01:36, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 1.32G/9.98G [00:14<01:35, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 1.33G/9.98G [00:14<01:36, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 1.34G/9.98G [00:14<01:34, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  14%|█▎        | 1.35G/9.98G [00:15<01:35, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  14%|█▎        | 1.36G/9.98G [00:15<01:33, 92.2MB/s][A
Downloading (…)of-00002.safetensors:  14%|█▍        | 1.37G/9.98G [00:15<01:32, 92.6MB/s][A
Downloading (…)of-00002.safetensors:  14%|█▍        | 1.38G/9.98G [00:15<01:32, 93.3MB/s][A
Downloading (…)of-00002.safetensors:  14%|█▍        | 1.39G/9.98G [00:15<01:32, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  14%|█▍        | 1.41G/9.98G [00:15<01:32, 92.8MB/s][A
Downloading (…)of-00002.safetensors:  14%|█▍        | 1.42G/9.98G [00:15<01:34, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  14%|█▍        | 1.43G/9.98G [00:15<01:34, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  14%|█▍        | 1.44G/9.98G [00:15<01:33, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▍        | 1.45G/9.98G [00:16<01:32, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▍        | 1.46G/9.98G [00:16<01:32, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▍        | 1.47G/9.98G [00:16<01:32, 92.1MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▍        | 1.48G/9.98G [00:16<01:33, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▍        | 1.49G/9.98G [00:16<01:32, 91.3MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▌        | 1.50G/9.98G [00:16<01:32, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▌        | 1.51G/9.98G [00:16<01:31, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▌        | 1.52G/9.98G [00:16<01:34, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▌        | 1.53G/9.98G [00:16<01:33, 90.0MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▌        | 1.54G/9.98G [00:17<01:32, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  16%|█▌        | 1.55G/9.98G [00:17<01:34, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  16%|█▌        | 1.56G/9.98G [00:17<01:32, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  16%|█▌        | 1.57G/9.98G [00:17<01:31, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  16%|█▌        | 1.58G/9.98G [00:17<01:31, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  16%|█▌        | 1.59G/9.98G [00:17<01:31, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  16%|█▌        | 1.60G/9.98G [00:17<01:30, 92.7MB/s][A
Downloading (…)of-00002.safetensors:  16%|█▌        | 1.61G/9.98G [00:17<01:33, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  16%|█▋        | 1.63G/9.98G [00:18<01:33, 88.9MB/s][A
Downloading (…)of-00002.safetensors:  16%|█▋        | 1.64G/9.98G [00:18<01:38, 84.7MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 1.65G/9.98G [00:18<01:35, 87.3MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 1.66G/9.98G [00:18<01:34, 88.5MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 1.67G/9.98G [00:18<01:34, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 1.68G/9.98G [00:18<01:33, 88.8MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 1.69G/9.98G [00:18<01:31, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 1.70G/9.98G [00:18<01:32, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 1.71G/9.98G [00:18<01:34, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 1.72G/9.98G [00:19<01:31, 90.0MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 1.73G/9.98G [00:19<01:30, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 1.74G/9.98G [00:19<01:34, 87.5MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 1.75G/9.98G [00:19<01:33, 88.2MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 1.76G/9.98G [00:19<01:31, 90.0MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 1.77G/9.98G [00:19<01:29, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 1.78G/9.98G [00:19<01:30, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 1.79G/9.98G [00:19<01:30, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 1.80G/9.98G [00:19<01:29, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 1.81G/9.98G [00:20<01:27, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 1.82G/9.98G [00:20<01:26, 94.2MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 1.84G/9.98G [00:20<01:26, 94.3MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 1.85G/9.98G [00:20<01:28, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▊        | 1.86G/9.98G [00:20<01:31, 88.8MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▊        | 1.87G/9.98G [00:20<01:28, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▉        | 1.88G/9.98G [00:20<01:28, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▉        | 1.89G/9.98G [00:20<01:27, 92.4MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▉        | 1.90G/9.98G [00:21<01:27, 92.4MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▉        | 1.91G/9.98G [00:21<01:26, 93.4MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▉        | 1.92G/9.98G [00:21<01:26, 93.1MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▉        | 1.93G/9.98G [00:21<01:26, 92.8MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▉        | 1.94G/9.98G [00:21<01:26, 92.9MB/s][A
Downloading (…)of-00002.safetensors:  20%|█▉        | 1.95G/9.98G [00:21<01:28, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  20%|█▉        | 1.96G/9.98G [00:21<01:28, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  20%|█▉        | 1.97G/9.98G [00:21<01:28, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  20%|█▉        | 1.98G/9.98G [00:21<01:27, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  20%|█▉        | 1.99G/9.98G [00:22<01:30, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  20%|██        | 2.00G/9.98G [00:22<01:28, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  20%|██        | 2.01G/9.98G [00:22<01:28, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  20%|██        | 2.02G/9.98G [00:22<01:27, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  20%|██        | 2.03G/9.98G [00:22<01:32, 85.5MB/s][A
Downloading (…)of-00002.safetensors:  20%|██        | 2.04G/9.98G [00:22<02:07, 62.2MB/s][A
Downloading (…)of-00002.safetensors:  21%|██        | 2.07G/9.98G [00:23<01:47, 73.7MB/s][A
Downloading (…)of-00002.safetensors:  21%|██        | 2.08G/9.98G [00:23<01:41, 77.8MB/s][A
Downloading (…)of-00002.safetensors:  21%|██        | 2.09G/9.98G [00:23<01:36, 81.3MB/s][A
Downloading (…)of-00002.safetensors:  21%|██        | 2.10G/9.98G [00:23<01:34, 83.0MB/s][A
Downloading (…)of-00002.safetensors:  21%|██        | 2.11G/9.98G [00:23<01:30, 86.8MB/s][A
Downloading (…)of-00002.safetensors:  21%|██        | 2.12G/9.98G [00:23<01:28, 88.6MB/s][A
Downloading (…)of-00002.safetensors:  21%|██▏       | 2.13G/9.98G [00:23<01:27, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  21%|██▏       | 2.14G/9.98G [00:23<01:29, 87.2MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 2.15G/9.98G [00:23<01:30, 86.3MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 2.16G/9.98G [00:24<01:30, 86.5MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 2.17G/9.98G [00:24<01:28, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 2.18G/9.98G [00:24<01:28, 88.0MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 2.19G/9.98G [00:24<01:28, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 2.20G/9.98G [00:24<01:28, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 2.21G/9.98G [00:24<01:27, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 2.22G/9.98G [00:24<01:26, 90.0MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 2.23G/9.98G [00:24<01:25, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 2.24G/9.98G [00:25<01:26, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  23%|██▎       | 2.25G/9.98G [00:25<01:27, 88.6MB/s][A
Downloading (…)of-00002.safetensors:  23%|██▎       | 2.26G/9.98G [00:25<01:29, 86.0MB/s][A
Downloading (…)of-00002.safetensors:  23%|██▎       | 2.28G/9.98G [00:25<01:27, 88.0MB/s][A
Downloading (…)of-00002.safetensors:  23%|██▎       | 2.29G/9.98G [00:25<01:28, 87.4MB/s][A
Downloading (…)of-00002.safetensors:  23%|██▎       | 2.30G/9.98G [00:25<01:25, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  23%|██▎       | 2.31G/9.98G [00:25<01:25, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  23%|██▎       | 2.32G/9.98G [00:25<01:24, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  23%|██▎       | 2.33G/9.98G [00:25<01:24, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  23%|██▎       | 2.34G/9.98G [00:26<01:24, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▎       | 2.35G/9.98G [00:26<01:25, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▎       | 2.36G/9.98G [00:26<01:24, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▍       | 2.37G/9.98G [00:26<01:26, 88.0MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▍       | 2.38G/9.98G [00:26<01:24, 89.8MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▍       | 2.39G/9.98G [00:26<01:24, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▍       | 2.40G/9.98G [00:26<01:23, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▍       | 2.41G/9.98G [00:26<01:23, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▍       | 2.42G/9.98G [00:27<01:23, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▍       | 2.43G/9.98G [00:27<01:24, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▍       | 2.44G/9.98G [00:27<01:28, 85.5MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▍       | 2.45G/9.98G [00:27<01:25, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▍       | 2.46G/9.98G [00:27<01:25, 87.5MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▍       | 2.47G/9.98G [00:27<01:26, 86.3MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▍       | 2.49G/9.98G [00:27<01:25, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▌       | 2.50G/9.98G [00:27<01:23, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▌       | 2.51G/9.98G [00:27<01:24, 88.0MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▌       | 2.52G/9.98G [00:28<01:25, 87.3MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▌       | 2.53G/9.98G [00:28<01:23, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▌       | 2.54G/9.98G [00:28<01:24, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▌       | 2.55G/9.98G [00:28<01:23, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▌       | 2.56G/9.98G [00:28<01:29, 83.2MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▌       | 2.57G/9.98G [00:28<01:32, 80.5MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▌       | 2.58G/9.98G [00:28<01:28, 83.8MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▌       | 2.59G/9.98G [00:28<01:26, 85.8MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▌       | 2.60G/9.98G [00:29<01:25, 86.6MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▌       | 2.61G/9.98G [00:29<01:23, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▋       | 2.62G/9.98G [00:29<01:22, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▋       | 2.63G/9.98G [00:29<01:22, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▋       | 2.64G/9.98G [00:29<01:22, 88.6MB/s][A
Downloading (…)of-00002.safetensors:  27%|██▋       | 2.65G/9.98G [00:29<01:23, 88.2MB/s][A
Downloading (…)of-00002.safetensors:  27%|██▋       | 2.66G/9.98G [00:29<01:22, 88.6MB/s][A
Downloading (…)of-00002.safetensors:  27%|██▋       | 2.67G/9.98G [00:29<01:25, 85.6MB/s][A
Downloading (…)of-00002.safetensors:  27%|██▋       | 2.68G/9.98G [00:30<01:24, 86.3MB/s][A
Downloading (…)of-00002.safetensors:  27%|██▋       | 2.69G/9.98G [00:30<01:22, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  27%|██▋       | 2.71G/9.98G [00:30<01:21, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  27%|██▋       | 2.72G/9.98G [00:30<01:21, 88.9MB/s][A
Downloading (…)of-00002.safetensors:  27%|██▋       | 2.73G/9.98G [00:30<01:20, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  27%|██▋       | 2.74G/9.98G [00:30<01:21, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 2.75G/9.98G [00:30<01:20, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 2.76G/9.98G [00:30<01:19, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 2.77G/9.98G [00:30<01:20, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 2.78G/9.98G [00:31<01:23, 86.6MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 2.79G/9.98G [00:31<01:22, 87.6MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 2.80G/9.98G [00:31<01:20, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 2.81G/9.98G [00:31<01:18, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 2.82G/9.98G [00:31<01:21, 88.2MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 2.83G/9.98G [00:31<01:19, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 2.84G/9.98G [00:31<01:19, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  29%|██▊       | 2.85G/9.98G [00:31<01:19, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  29%|██▊       | 2.86G/9.98G [00:32<01:18, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  29%|██▉       | 2.87G/9.98G [00:32<01:17, 91.3MB/s][A
Downloading (…)of-00002.safetensors:  29%|██▉       | 2.88G/9.98G [00:32<01:19, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  29%|██▉       | 2.89G/9.98G [00:32<01:18, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  29%|██▉       | 2.90G/9.98G [00:32<01:18, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  29%|██▉       | 2.92G/9.98G [00:32<01:18, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  29%|██▉       | 2.93G/9.98G [00:32<01:17, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  29%|██▉       | 2.94G/9.98G [00:32<01:16, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  30%|██▉       | 2.95G/9.98G [00:32<01:17, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  30%|██▉       | 2.96G/9.98G [00:33<01:16, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  30%|██▉       | 2.97G/9.98G [00:33<01:15, 92.4MB/s][A
Downloading (…)of-00002.safetensors:  30%|██▉       | 2.98G/9.98G [00:33<01:15, 92.7MB/s][A
Downloading (…)of-00002.safetensors:  30%|██▉       | 2.99G/9.98G [00:33<01:19, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  30%|███       | 3.00G/9.98G [00:33<01:20, 86.6MB/s][A
Downloading (…)of-00002.safetensors:  30%|███       | 3.01G/9.98G [00:33<01:19, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  30%|███       | 3.02G/9.98G [00:33<01:18, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  30%|███       | 3.03G/9.98G [00:33<01:18, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  30%|███       | 3.04G/9.98G [00:33<01:16, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  31%|███       | 3.05G/9.98G [00:34<01:16, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  31%|███       | 3.06G/9.98G [00:34<01:15, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  31%|███       | 3.07G/9.98G [00:34<01:14, 92.1MB/s][A
Downloading (…)of-00002.safetensors:  31%|███       | 3.08G/9.98G [00:34<01:14, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  31%|███       | 3.09G/9.98G [00:34<01:15, 91.5MB/s][A
Downloading (…)of-00002.safetensors:  31%|███       | 3.10G/9.98G [00:34<01:19, 86.2MB/s][A
Downloading (…)of-00002.safetensors:  31%|███       | 3.11G/9.98G [00:34<01:17, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  31%|███▏      | 3.12G/9.98G [00:34<01:17, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  31%|███▏      | 3.14G/9.98G [00:35<01:17, 88.8MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 3.15G/9.98G [00:35<01:16, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 3.16G/9.98G [00:35<01:14, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 3.17G/9.98G [00:35<01:14, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 3.18G/9.98G [00:35<01:14, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 3.19G/9.98G [00:35<01:14, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 3.20G/9.98G [00:35<01:15, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 3.21G/9.98G [00:35<01:17, 87.5MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 3.22G/9.98G [00:35<01:15, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 3.23G/9.98G [00:36<01:14, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 3.24G/9.98G [00:36<01:14, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  33%|███▎      | 3.25G/9.98G [00:36<01:13, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  33%|███▎      | 3.26G/9.98G [00:36<01:12, 92.7MB/s][A
Downloading (…)of-00002.safetensors:  33%|███▎      | 3.27G/9.98G [00:36<01:18, 85.4MB/s][A
Downloading (…)of-00002.safetensors:  33%|███▎      | 3.28G/9.98G [00:36<01:22, 81.0MB/s][A
Downloading (…)of-00002.safetensors:  33%|███▎      | 3.29G/9.98G [00:36<01:20, 82.7MB/s][A
Downloading (…)of-00002.safetensors:  33%|███▎      | 3.30G/9.98G [00:36<01:20, 82.6MB/s][A
Downloading (…)of-00002.safetensors:  33%|███▎      | 3.31G/9.98G [00:37<01:20, 83.0MB/s][A
Downloading (…)of-00002.safetensors:  33%|███▎      | 3.32G/9.98G [00:37<01:19, 84.0MB/s][A
Downloading (…)of-00002.safetensors:  33%|███▎      | 3.33G/9.98G [00:37<01:17, 85.8MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▎      | 3.34G/9.98G [00:37<01:17, 85.2MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▎      | 3.36G/9.98G [00:37<01:19, 83.5MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▎      | 3.37G/9.98G [00:37<01:19, 83.4MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▍      | 3.38G/9.98G [00:37<01:16, 86.1MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▍      | 3.39G/9.98G [00:37<01:14, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▍      | 3.40G/9.98G [00:38<01:13, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▍      | 3.41G/9.98G [00:38<01:16, 85.4MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▍      | 3.42G/9.98G [00:38<01:16, 85.2MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▍      | 3.43G/9.98G [00:38<01:15, 87.0MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▍      | 3.44G/9.98G [00:38<01:14, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  35%|███▍      | 3.45G/9.98G [00:38<01:13, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  35%|███▍      | 3.46G/9.98G [00:38<01:13, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  35%|███▍      | 3.47G/9.98G [00:38<01:12, 90.0MB/s][A
Downloading (…)of-00002.safetensors:  35%|███▍      | 3.48G/9.98G [00:39<01:11, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  35%|███▍      | 3.49G/9.98G [00:39<01:11, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  35%|███▌      | 3.50G/9.98G [00:39<01:13, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  35%|███▌      | 3.51G/9.98G [00:39<01:14, 86.8MB/s][A
Downloading (…)of-00002.safetensors:  35%|███▌      | 3.52G/9.98G [00:39<01:15, 86.0MB/s][A
Downloading (…)of-00002.safetensors:  35%|███▌      | 3.53G/9.98G [00:39<01:13, 87.5MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▌      | 3.54G/9.98G [00:39<01:11, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▌      | 3.55G/9.98G [00:39<01:11, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▌      | 3.57G/9.98G [00:39<01:10, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▌      | 3.58G/9.98G [00:40<01:10, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▌      | 3.59G/9.98G [00:40<01:09, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▌      | 3.60G/9.98G [00:40<01:09, 92.2MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▌      | 3.61G/9.98G [00:40<01:08, 93.4MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▋      | 3.62G/9.98G [00:40<01:07, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▋      | 3.63G/9.98G [00:40<01:09, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▋      | 3.64G/9.98G [00:40<01:08, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 3.65G/9.98G [00:40<01:08, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 3.66G/9.98G [00:40<01:10, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 3.67G/9.98G [00:41<01:08, 92.1MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 3.68G/9.98G [00:41<01:09, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 3.69G/9.98G [00:41<01:10, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 3.70G/9.98G [00:41<01:09, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 3.71G/9.98G [00:41<01:11, 88.2MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 3.72G/9.98G [00:41<01:10, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 3.73G/9.98G [00:41<01:12, 86.5MB/s][A
Downloading (…)of-00002.safetensors:  38%|███▊      | 3.74G/9.98G [00:41<01:10, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  38%|███▊      | 3.75G/9.98G [00:42<01:10, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  38%|███▊      | 3.76G/9.98G [00:42<01:09, 88.9MB/s][A
Downloading (…)of-00002.safetensors:  38%|███▊      | 3.77G/9.98G [00:42<01:11, 86.7MB/s][A
Downloading (…)of-00002.safetensors:  38%|███▊      | 3.79G/9.98G [00:42<01:10, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  38%|███▊      | 3.80G/9.98G [00:42<01:10, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  38%|███▊      | 3.81G/9.98G [00:42<01:36, 63.8MB/s][A
Downloading (…)of-00002.safetensors:  38%|███▊      | 3.83G/9.98G [00:42<01:10, 87.7MB/s][A
Downloading (…)of-00002.safetensors:  38%|███▊      | 3.84G/9.98G [00:43<01:09, 88.0MB/s][A
Downloading (…)of-00002.safetensors:  39%|███▊      | 3.85G/9.98G [00:43<01:09, 88.0MB/s][A
Downloading (…)of-00002.safetensors:  39%|███▊      | 3.86G/9.98G [00:43<01:08, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  39%|███▉      | 3.87G/9.98G [00:43<01:07, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  39%|███▉      | 3.88G/9.98G [00:43<01:07, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  39%|███▉      | 3.89G/9.98G [00:43<01:07, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  39%|███▉      | 3.90G/9.98G [00:43<01:07, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  39%|███▉      | 3.91G/9.98G [00:43<01:07, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  39%|███▉      | 3.92G/9.98G [00:43<01:06, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  39%|███▉      | 3.93G/9.98G [00:44<01:17, 78.1MB/s][A
Downloading (…)of-00002.safetensors:  40%|███▉      | 3.94G/9.98G [00:44<01:14, 81.0MB/s][A
Downloading (…)of-00002.safetensors:  40%|███▉      | 3.95G/9.98G [00:44<01:12, 83.3MB/s][A
Downloading (…)of-00002.safetensors:  40%|███▉      | 3.96G/9.98G [00:44<01:10, 85.1MB/s][A
Downloading (…)of-00002.safetensors:  40%|███▉      | 3.97G/9.98G [00:44<01:08, 87.3MB/s][A
Downloading (…)of-00002.safetensors:  40%|███▉      | 3.98G/9.98G [00:44<01:10, 84.7MB/s][A
Downloading (…)of-00002.safetensors:  40%|████      | 4.00G/9.98G [00:44<01:09, 86.5MB/s][A
Downloading (…)of-00002.safetensors:  40%|████      | 4.01G/9.98G [00:44<01:09, 85.8MB/s][A
Downloading (…)of-00002.safetensors:  40%|████      | 4.02G/9.98G [00:45<01:08, 86.6MB/s][A
Downloading (…)of-00002.safetensors:  40%|████      | 4.03G/9.98G [00:45<01:08, 87.2MB/s][A
Downloading (…)of-00002.safetensors:  40%|████      | 4.04G/9.98G [00:45<01:08, 86.8MB/s][A
Downloading (…)of-00002.safetensors:  41%|████      | 4.05G/9.98G [00:45<01:06, 88.8MB/s][A
Downloading (…)of-00002.safetensors:  41%|████      | 4.06G/9.98G [00:45<01:05, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  41%|████      | 4.07G/9.98G [00:45<01:04, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  41%|████      | 4.08G/9.98G [00:45<01:04, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  41%|████      | 4.09G/9.98G [00:45<01:03, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  41%|████      | 4.10G/9.98G [00:46<01:05, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  41%|████      | 4.11G/9.98G [00:46<01:06, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  41%|████▏     | 4.12G/9.98G [00:46<01:04, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  41%|████▏     | 4.13G/9.98G [00:46<01:03, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 4.14G/9.98G [00:46<01:05, 88.9MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 4.15G/9.98G [00:46<01:03, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 4.16G/9.98G [00:46<01:03, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 4.17G/9.98G [00:46<01:03, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 4.18G/9.98G [00:46<01:03, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 4.19G/9.98G [00:47<01:02, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 4.20G/9.98G [00:47<01:03, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 4.22G/9.98G [00:47<01:02, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 4.23G/9.98G [00:47<01:03, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 4.24G/9.98G [00:47<01:14, 76.9MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 4.25G/9.98G [00:47<01:12, 79.3MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 4.26G/9.98G [00:47<01:08, 83.0MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 4.27G/9.98G [00:47<01:07, 85.2MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 4.28G/9.98G [00:48<01:05, 87.5MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 4.29G/9.98G [00:48<01:06, 85.8MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 4.30G/9.98G [00:48<01:07, 84.4MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 4.31G/9.98G [00:48<01:05, 86.6MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 4.32G/9.98G [00:48<01:05, 86.5MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 4.33G/9.98G [00:48<01:03, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▎     | 4.34G/9.98G [00:48<01:02, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▎     | 4.35G/9.98G [00:48<01:03, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▎     | 4.36G/9.98G [00:49<01:02, 89.8MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▍     | 4.37G/9.98G [00:49<01:01, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▍     | 4.38G/9.98G [00:49<01:02, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▍     | 4.39G/9.98G [00:49<01:02, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▍     | 4.40G/9.98G [00:49<01:02, 88.9MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▍     | 4.41G/9.98G [00:49<01:02, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▍     | 4.42G/9.98G [00:49<01:01, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▍     | 4.44G/9.98G [00:49<01:00, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  45%|████▍     | 4.45G/9.98G [00:49<01:00, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  45%|████▍     | 4.46G/9.98G [00:50<01:02, 88.5MB/s][A
Downloading (…)of-00002.safetensors:  45%|████▍     | 4.47G/9.98G [00:50<01:01, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  45%|████▍     | 4.48G/9.98G [00:50<01:00, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  45%|████▍     | 4.49G/9.98G [00:50<01:00, 91.3MB/s][A
Downloading (…)of-00002.safetensors:  45%|████▌     | 4.50G/9.98G [00:50<00:59, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  45%|████▌     | 4.51G/9.98G [00:50<00:59, 92.6MB/s][A
Downloading (…)of-00002.safetensors:  45%|████▌     | 4.52G/9.98G [00:50<00:58, 92.6MB/s][A
Downloading (…)of-00002.safetensors:  45%|████▌     | 4.53G/9.98G [00:50<00:58, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▌     | 4.54G/9.98G [00:50<00:58, 93.3MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▌     | 4.55G/9.98G [00:51<00:57, 93.6MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▌     | 4.56G/9.98G [00:51<00:59, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▌     | 4.57G/9.98G [00:51<00:59, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▌     | 4.58G/9.98G [00:51<00:58, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▌     | 4.59G/9.98G [00:51<00:59, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▌     | 4.60G/9.98G [00:51<00:58, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▌     | 4.61G/9.98G [00:51<00:57, 92.5MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▋     | 4.62G/9.98G [00:51<00:57, 92.5MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▋     | 4.63G/9.98G [00:51<00:58, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  47%|████▋     | 4.65G/9.98G [00:52<00:59, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  47%|████▋     | 4.66G/9.98G [00:52<00:59, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  47%|████▋     | 4.67G/9.98G [00:52<01:00, 87.1MB/s][A
Downloading (…)of-00002.safetensors:  47%|████▋     | 4.68G/9.98G [00:52<01:00, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  47%|████▋     | 4.69G/9.98G [00:52<00:59, 88.6MB/s][A
Downloading (…)of-00002.safetensors:  47%|████▋     | 4.70G/9.98G [00:52<00:58, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  47%|████▋     | 4.71G/9.98G [00:52<00:57, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  47%|████▋     | 4.72G/9.98G [00:52<00:57, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  47%|████▋     | 4.73G/9.98G [00:53<00:57, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 4.74G/9.98G [00:53<00:58, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 4.75G/9.98G [00:53<00:58, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 4.76G/9.98G [00:53<00:57, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 4.77G/9.98G [00:53<00:57, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 4.78G/9.98G [00:53<00:58, 88.9MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 4.79G/9.98G [00:53<00:57, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 4.80G/9.98G [00:53<00:56, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 4.81G/9.98G [00:53<00:56, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 4.82G/9.98G [00:54<00:56, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 4.83G/9.98G [00:54<00:56, 91.5MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▊     | 4.84G/9.98G [00:54<00:55, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▊     | 4.85G/9.98G [00:54<00:55, 92.3MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▉     | 4.87G/9.98G [00:54<00:55, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▉     | 4.88G/9.98G [00:54<00:55, 92.3MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▉     | 4.89G/9.98G [00:54<00:58, 87.2MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▉     | 4.90G/9.98G [00:54<00:57, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▉     | 4.91G/9.98G [00:55<00:56, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▉     | 4.92G/9.98G [00:55<00:55, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▉     | 4.93G/9.98G [00:55<00:56, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  50%|████▉     | 4.94G/9.98G [00:55<00:56, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  50%|████▉     | 4.95G/9.98G [00:55<00:55, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  50%|████▉     | 4.96G/9.98G [00:55<00:55, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  50%|████▉     | 4.97G/9.98G [00:55<00:54, 91.5MB/s][A
Downloading (…)of-00002.safetensors:  50%|████▉     | 4.98G/9.98G [00:55<00:54, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  50%|█████     | 4.99G/9.98G [00:55<00:55, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  50%|█████     | 5.00G/9.98G [00:56<00:54, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  50%|█████     | 5.01G/9.98G [00:56<00:54, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  50%|█████     | 5.02G/9.98G [00:56<00:54, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  50%|█████     | 5.03G/9.98G [00:56<00:54, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  51%|█████     | 5.04G/9.98G [00:56<00:54, 91.3MB/s][A
Downloading (…)of-00002.safetensors:  51%|█████     | 5.05G/9.98G [00:56<00:53, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  51%|█████     | 5.06G/9.98G [00:56<00:53, 91.3MB/s][A
Downloading (…)of-00002.safetensors:  51%|█████     | 5.08G/9.98G [00:56<00:54, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  51%|█████     | 5.09G/9.98G [00:56<00:53, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  51%|█████     | 5.10G/9.98G [00:57<00:54, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  51%|█████     | 5.11G/9.98G [00:57<00:54, 88.8MB/s][A
Downloading (…)of-00002.safetensors:  51%|█████▏    | 5.12G/9.98G [00:57<00:54, 88.9MB/s][A
Downloading (…)of-00002.safetensors:  51%|█████▏    | 5.13G/9.98G [00:57<00:53, 90.0MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.14G/9.98G [00:57<00:53, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.15G/9.98G [00:57<00:54, 88.8MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.16G/9.98G [00:57<00:53, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.17G/9.98G [00:57<00:52, 91.3MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.18G/9.98G [00:58<00:52, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.19G/9.98G [00:58<00:52, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.20G/9.98G [00:58<00:51, 92.4MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.21G/9.98G [00:58<00:53, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.22G/9.98G [00:58<00:52, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 5.23G/9.98G [00:58<00:52, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.24G/9.98G [00:58<00:52, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.25G/9.98G [00:58<00:51, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.26G/9.98G [00:58<00:52, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.27G/9.98G [00:59<00:52, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.28G/9.98G [00:59<00:52, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.30G/9.98G [00:59<00:51, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.31G/9.98G [00:59<00:51, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.32G/9.98G [00:59<00:54, 85.7MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.33G/9.98G [00:59<00:55, 83.4MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 5.34G/9.98G [00:59<00:54, 84.7MB/s][A
Downloading (…)of-00002.safetensors:  54%|█████▎    | 5.35G/9.98G [00:59<00:53, 86.7MB/s][A
Downloading (…)of-00002.safetensors:  54%|█████▎    | 5.36G/9.98G [01:00<00:52, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.37G/9.98G [01:00<00:51, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.38G/9.98G [01:00<00:51, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.39G/9.98G [01:00<00:51, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.40G/9.98G [01:00<00:50, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.41G/9.98G [01:00<00:49, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.42G/9.98G [01:00<00:50, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  54%|█████▍    | 5.43G/9.98G [01:00<00:51, 88.6MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.44G/9.98G [01:00<00:50, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.45G/9.98G [01:01<00:49, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.46G/9.98G [01:01<00:49, 91.3MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.47G/9.98G [01:01<00:48, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▍    | 5.48G/9.98G [01:01<00:48, 93.6MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.49G/9.98G [01:01<00:48, 93.1MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.51G/9.98G [01:01<00:48, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.52G/9.98G [01:01<00:47, 93.1MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.53G/9.98G [01:01<00:50, 88.5MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▌    | 5.54G/9.98G [01:01<00:49, 89.8MB/s][A
Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.55G/9.98G [01:02<00:48, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.56G/9.98G [01:02<00:48, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.57G/9.98G [01:02<00:49, 88.5MB/s][A
Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.58G/9.98G [01:02<00:48, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.59G/9.98G [01:02<00:48, 91.3MB/s][A
Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.60G/9.98G [01:02<00:47, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  56%|█████▌    | 5.61G/9.98G [01:02<00:47, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  56%|█████▋    | 5.62G/9.98G [01:02<00:47, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  56%|█████▋    | 5.63G/9.98G [01:03<00:48, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.64G/9.98G [01:03<00:47, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.65G/9.98G [01:03<00:47, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.66G/9.98G [01:03<00:47, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.67G/9.98G [01:03<00:47, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.68G/9.98G [01:03<00:46, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.69G/9.98G [01:03<00:46, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.70G/9.98G [01:03<00:47, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.71G/9.98G [01:03<00:47, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.73G/9.98G [01:04<00:47, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 5.74G/9.98G [01:04<00:48, 87.0MB/s][A
Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.75G/9.98G [01:04<00:51, 81.9MB/s][A
Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.76G/9.98G [01:04<00:50, 84.0MB/s][A
Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.77G/9.98G [01:04<01:07, 62.4MB/s][A
Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.79G/9.98G [01:04<00:47, 88.0MB/s][A
Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.80G/9.98G [01:04<00:47, 87.4MB/s][A
Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.81G/9.98G [01:05<00:47, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.82G/9.98G [01:05<00:46, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  58%|█████▊    | 5.83G/9.98G [01:05<00:46, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▊    | 5.84G/9.98G [01:05<00:47, 86.9MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▊    | 5.85G/9.98G [01:05<00:47, 87.2MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.86G/9.98G [01:05<00:46, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.87G/9.98G [01:05<00:45, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.88G/9.98G [01:05<00:45, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.89G/9.98G [01:06<00:46, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.90G/9.98G [01:06<00:45, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.91G/9.98G [01:06<00:45, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.92G/9.98G [01:06<00:45, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▉    | 5.93G/9.98G [01:06<00:44, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.95G/9.98G [01:06<00:50, 80.5MB/s][A
Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.96G/9.98G [01:06<00:48, 82.8MB/s][A
Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.97G/9.98G [01:06<00:47, 85.2MB/s][A
Downloading (…)of-00002.safetensors:  60%|█████▉    | 5.98G/9.98G [01:07<00:46, 86.3MB/s][A
Downloading (…)of-00002.safetensors:  60%|██████    | 5.99G/9.98G [01:07<00:45, 87.2MB/s][A
Downloading (…)of-00002.safetensors:  60%|██████    | 6.00G/9.98G [01:07<00:44, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  60%|██████    | 6.01G/9.98G [01:07<00:44, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  60%|██████    | 6.02G/9.98G [01:07<00:43, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  60%|██████    | 6.03G/9.98G [01:07<00:43, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████    | 6.04G/9.98G [01:07<00:43, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████    | 6.05G/9.98G [01:07<00:44, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████    | 6.06G/9.98G [01:07<00:43, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████    | 6.07G/9.98G [01:08<00:43, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████    | 6.08G/9.98G [01:08<00:44, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████    | 6.09G/9.98G [01:08<00:43, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████    | 6.10G/9.98G [01:08<00:43, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████▏   | 6.11G/9.98G [01:08<00:43, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████▏   | 6.12G/9.98G [01:08<00:43, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████▏   | 6.13G/9.98G [01:08<00:43, 88.9MB/s][A
Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.14G/9.98G [01:08<00:42, 89.8MB/s][A
Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.16G/9.98G [01:09<00:43, 87.4MB/s][A
Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.17G/9.98G [01:09<00:42, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.18G/9.98G [01:09<00:44, 86.0MB/s][A
Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.19G/9.98G [01:09<00:43, 86.7MB/s][A
Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.20G/9.98G [01:09<00:43, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.21G/9.98G [01:09<00:42, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.22G/9.98G [01:09<00:41, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  62%|██████▏   | 6.23G/9.98G [01:09<00:40, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.24G/9.98G [01:09<00:40, 92.5MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.25G/9.98G [01:10<00:40, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.26G/9.98G [01:10<00:42, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.27G/9.98G [01:10<00:42, 87.3MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.28G/9.98G [01:10<00:41, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.29G/9.98G [01:10<00:41, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.30G/9.98G [01:10<00:40, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.31G/9.98G [01:10<00:40, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.32G/9.98G [01:10<00:41, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 6.33G/9.98G [01:11<00:41, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▎   | 6.34G/9.98G [01:11<00:40, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▎   | 6.35G/9.98G [01:11<00:39, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.36G/9.98G [01:11<00:41, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.38G/9.98G [01:11<00:40, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.39G/9.98G [01:11<00:39, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.40G/9.98G [01:11<00:39, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.41G/9.98G [01:11<00:39, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.42G/9.98G [01:11<00:39, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▍   | 6.43G/9.98G [01:12<00:38, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.44G/9.98G [01:12<00:38, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.45G/9.98G [01:12<00:38, 91.5MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.46G/9.98G [01:12<00:38, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.47G/9.98G [01:12<00:39, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▍   | 6.48G/9.98G [01:12<00:38, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.49G/9.98G [01:12<00:38, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.50G/9.98G [01:12<00:38, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.51G/9.98G [01:12<00:39, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.52G/9.98G [01:13<00:38, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▌   | 6.53G/9.98G [01:13<00:37, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.54G/9.98G [01:13<00:37, 91.5MB/s][A
Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.55G/9.98G [01:13<00:38, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.56G/9.98G [01:13<00:37, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.57G/9.98G [01:13<00:38, 87.5MB/s][A
Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.59G/9.98G [01:13<00:38, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.60G/9.98G [01:13<00:38, 88.8MB/s][A
Downloading (…)of-00002.safetensors:  66%|██████▌   | 6.61G/9.98G [01:14<00:37, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  66%|██████▋   | 6.62G/9.98G [01:14<00:37, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  66%|██████▋   | 6.63G/9.98G [01:14<00:36, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.64G/9.98G [01:14<00:38, 86.8MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.65G/9.98G [01:14<00:38, 85.5MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.66G/9.98G [01:14<00:38, 86.2MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.67G/9.98G [01:14<00:39, 84.2MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.68G/9.98G [01:14<00:37, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.69G/9.98G [01:14<00:36, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.70G/9.98G [01:15<00:36, 88.6MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.71G/9.98G [01:15<00:36, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.72G/9.98G [01:15<00:36, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 6.73G/9.98G [01:15<00:35, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.74G/9.98G [01:15<00:35, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.75G/9.98G [01:15<00:35, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.76G/9.98G [01:15<00:35, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.77G/9.98G [01:15<00:34, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.78G/9.98G [01:16<00:34, 92.2MB/s][A
Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.79G/9.98G [01:16<00:35, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.81G/9.98G [01:16<00:34, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.82G/9.98G [01:16<00:34, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  68%|██████▊   | 6.83G/9.98G [01:16<00:34, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▊   | 6.84G/9.98G [01:16<00:34, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▊   | 6.85G/9.98G [01:16<00:34, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▊   | 6.86G/9.98G [01:16<00:33, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.87G/9.98G [01:16<00:37, 83.9MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.88G/9.98G [01:17<00:35, 87.3MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.90G/9.98G [01:17<00:32, 94.2MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.91G/9.98G [01:17<00:32, 93.6MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.92G/9.98G [01:17<00:33, 92.4MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▉   | 6.93G/9.98G [01:17<00:32, 92.8MB/s][A
Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.94G/9.98G [01:17<00:32, 92.4MB/s][A
Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.95G/9.98G [01:17<00:32, 92.3MB/s][A
Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.96G/9.98G [01:18<00:33, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.97G/9.98G [01:18<00:34, 87.4MB/s][A
Downloading (…)of-00002.safetensors:  70%|██████▉   | 6.98G/9.98G [01:18<00:33, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  70%|███████   | 6.99G/9.98G [01:18<00:33, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  70%|███████   | 7.00G/9.98G [01:18<00:33, 88.2MB/s][A
Downloading (…)of-00002.safetensors:  70%|███████   | 7.01G/9.98G [01:18<00:33, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  70%|███████   | 7.03G/9.98G [01:18<00:32, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████   | 7.04G/9.98G [01:18<00:32, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████   | 7.05G/9.98G [01:18<00:32, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████   | 7.06G/9.98G [01:19<00:32, 89.8MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████   | 7.07G/9.98G [01:19<00:32, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████   | 7.08G/9.98G [01:19<00:32, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████   | 7.09G/9.98G [01:19<00:32, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████   | 7.10G/9.98G [01:19<00:31, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████▏  | 7.11G/9.98G [01:19<00:32, 87.3MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████▏  | 7.12G/9.98G [01:19<00:32, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████▏  | 7.13G/9.98G [01:19<00:31, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.14G/9.98G [01:19<00:31, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.15G/9.98G [01:20<00:30, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.16G/9.98G [01:20<00:30, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.17G/9.98G [01:20<00:30, 92.5MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.18G/9.98G [01:20<00:30, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.19G/9.98G [01:20<00:31, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.20G/9.98G [01:20<00:30, 89.8MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.21G/9.98G [01:20<00:31, 87.0MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 7.22G/9.98G [01:20<00:30, 88.9MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.24G/9.98G [01:21<00:30, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.25G/9.98G [01:21<00:30, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.26G/9.98G [01:21<00:30, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.27G/9.98G [01:21<00:30, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.28G/9.98G [01:21<00:30, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.29G/9.98G [01:21<00:30, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.30G/9.98G [01:21<00:29, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.31G/9.98G [01:21<00:29, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.32G/9.98G [01:21<00:29, 88.6MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 7.33G/9.98G [01:22<00:29, 89.8MB/s][A
Downloading (…)of-00002.safetensors:  74%|███████▎  | 7.34G/9.98G [01:22<00:29, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  74%|███████▎  | 7.35G/9.98G [01:22<00:29, 89.8MB/s][A
Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.36G/9.98G [01:22<00:28, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.37G/9.98G [01:22<00:28, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.38G/9.98G [01:22<00:28, 92.6MB/s][A
Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.39G/9.98G [01:22<00:28, 92.2MB/s][A
Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.40G/9.98G [01:22<00:28, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.41G/9.98G [01:23<00:28, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  74%|███████▍  | 7.42G/9.98G [01:23<00:39, 64.0MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.44G/9.98G [01:23<00:28, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.46G/9.98G [01:23<00:27, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.47G/9.98G [01:23<00:27, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▍  | 7.48G/9.98G [01:23<00:27, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.49G/9.98G [01:23<00:28, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.50G/9.98G [01:23<00:27, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.51G/9.98G [01:24<00:27, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.52G/9.98G [01:24<00:27, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▌  | 7.53G/9.98G [01:24<00:28, 85.1MB/s][A
Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.54G/9.98G [01:24<00:27, 87.5MB/s][A
Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.55G/9.98G [01:24<00:27, 88.8MB/s][A
Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.56G/9.98G [01:24<00:26, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.57G/9.98G [01:24<00:26, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.58G/9.98G [01:24<00:26, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.59G/9.98G [01:25<00:26, 90.0MB/s][A
Downloading (…)of-00002.safetensors:  76%|███████▌  | 7.60G/9.98G [01:25<00:26, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  76%|███████▋  | 7.61G/9.98G [01:25<00:26, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  76%|███████▋  | 7.62G/9.98G [01:25<00:25, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.63G/9.98G [01:25<00:25, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.64G/9.98G [01:25<00:26, 87.7MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.65G/9.98G [01:25<00:26, 88.5MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.67G/9.98G [01:25<00:26, 87.6MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.68G/9.98G [01:25<00:25, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.69G/9.98G [01:26<00:25, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.70G/9.98G [01:26<00:25, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.71G/9.98G [01:26<00:26, 87.3MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.72G/9.98G [01:26<00:25, 88.2MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 7.73G/9.98G [01:26<00:25, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.74G/9.98G [01:26<00:29, 76.5MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.75G/9.98G [01:26<00:28, 79.2MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.76G/9.98G [01:27<00:27, 81.9MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.77G/9.98G [01:27<00:26, 84.6MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.78G/9.98G [01:27<00:25, 86.2MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.79G/9.98G [01:27<00:25, 85.3MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.80G/9.98G [01:27<00:24, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.81G/9.98G [01:27<00:24, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 7.82G/9.98G [01:27<00:23, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  79%|███████▊  | 7.83G/9.98G [01:27<00:23, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  79%|███████▊  | 7.84G/9.98G [01:27<00:24, 86.2MB/s][A
Downloading (…)of-00002.safetensors:  79%|███████▊  | 7.85G/9.98G [01:28<00:24, 86.8MB/s][A
Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.86G/9.98G [01:28<00:24, 87.1MB/s][A
Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.87G/9.98G [01:28<00:23, 88.2MB/s][A
Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.89G/9.98G [01:28<00:23, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.90G/9.98G [01:28<00:23, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.91G/9.98G [01:28<00:22, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.92G/9.98G [01:28<00:22, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  79%|███████▉  | 7.93G/9.98G [01:28<00:22, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.94G/9.98G [01:28<00:22, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.95G/9.98G [01:29<00:23, 87.4MB/s][A
Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.96G/9.98G [01:29<00:22, 88.5MB/s][A
Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.97G/9.98G [01:29<00:23, 87.0MB/s][A
Downloading (…)of-00002.safetensors:  80%|███████▉  | 7.98G/9.98G [01:29<00:22, 87.6MB/s][A
Downloading (…)of-00002.safetensors:  80%|████████  | 7.99G/9.98G [01:29<00:22, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  80%|████████  | 8.00G/9.98G [01:29<00:22, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  80%|████████  | 8.01G/9.98G [01:29<00:21, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  80%|████████  | 8.02G/9.98G [01:29<00:21, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████  | 8.03G/9.98G [01:30<00:21, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████  | 8.04G/9.98G [01:30<00:21, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████  | 8.05G/9.98G [01:30<00:21, 88.8MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████  | 8.06G/9.98G [01:30<00:21, 88.9MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████  | 8.07G/9.98G [01:30<00:21, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████  | 8.08G/9.98G [01:30<00:20, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████  | 8.10G/9.98G [01:30<00:20, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████  | 8.11G/9.98G [01:30<00:20, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████▏ | 8.12G/9.98G [01:30<00:20, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████▏ | 8.13G/9.98G [01:31<00:20, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.14G/9.98G [01:31<00:20, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.15G/9.98G [01:31<00:20, 87.5MB/s][A
Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.16G/9.98G [01:31<00:20, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.17G/9.98G [01:31<00:20, 89.8MB/s][A
Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.18G/9.98G [01:31<00:19, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.19G/9.98G [01:31<00:19, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.20G/9.98G [01:31<00:19, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.21G/9.98G [01:32<00:19, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  82%|████████▏ | 8.22G/9.98G [01:32<00:19, 89.8MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.23G/9.98G [01:32<00:19, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.24G/9.98G [01:32<00:20, 86.4MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.25G/9.98G [01:32<00:19, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.26G/9.98G [01:32<00:19, 86.5MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.27G/9.98G [01:32<00:19, 88.0MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.28G/9.98G [01:32<00:19, 86.6MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.29G/9.98G [01:33<00:19, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.30G/9.98G [01:33<00:18, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.32G/9.98G [01:33<00:18, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 8.33G/9.98G [01:33<00:18, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▎ | 8.34G/9.98G [01:33<00:18, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▎ | 8.35G/9.98G [01:33<00:18, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.36G/9.98G [01:33<00:18, 90.0MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.37G/9.98G [01:33<00:18, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.38G/9.98G [01:33<00:18, 87.3MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.39G/9.98G [01:34<00:17, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.40G/9.98G [01:34<00:18, 87.3MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.41G/9.98G [01:34<00:18, 86.3MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▍ | 8.42G/9.98G [01:34<00:18, 86.2MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.43G/9.98G [01:34<00:17, 87.1MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.44G/9.98G [01:34<00:17, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.45G/9.98G [01:34<00:17, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.46G/9.98G [01:34<00:17, 86.4MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▍ | 8.47G/9.98G [01:35<00:17, 85.2MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.48G/9.98G [01:35<00:17, 85.7MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.49G/9.98G [01:35<00:17, 87.2MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.50G/9.98G [01:35<00:16, 88.9MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.51G/9.98G [01:35<00:16, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▌ | 8.52G/9.98G [01:35<00:16, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.54G/9.98G [01:35<00:15, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.55G/9.98G [01:35<00:15, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.56G/9.98G [01:35<00:15, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.57G/9.98G [01:36<00:15, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.58G/9.98G [01:36<00:16, 86.4MB/s][A
Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.59G/9.98G [01:36<00:16, 86.2MB/s][A
Downloading (…)of-00002.safetensors:  86%|████████▌ | 8.60G/9.98G [01:36<00:15, 87.7MB/s][A
Downloading (…)of-00002.safetensors:  86%|████████▋ | 8.61G/9.98G [01:36<00:15, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  86%|████████▋ | 8.62G/9.98G [01:36<00:15, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.63G/9.98G [01:36<00:15, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.64G/9.98G [01:36<00:14, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.65G/9.98G [01:37<00:15, 83.2MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.66G/9.98G [01:37<00:15, 84.8MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.67G/9.98G [01:37<00:15, 84.4MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.68G/9.98G [01:37<00:15, 83.7MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.69G/9.98G [01:37<00:15, 85.5MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.70G/9.98G [01:37<00:14, 85.9MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.71G/9.98G [01:37<00:14, 87.7MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 8.72G/9.98G [01:37<00:14, 88.0MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.73G/9.98G [01:38<00:14, 87.6MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.75G/9.98G [01:38<00:13, 88.2MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.76G/9.98G [01:38<00:13, 88.8MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.77G/9.98G [01:38<00:13, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.78G/9.98G [01:38<00:13, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.79G/9.98G [01:38<00:13, 87.0MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.80G/9.98G [01:38<00:13, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.81G/9.98G [01:38<00:13, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.82G/9.98G [01:38<00:12, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 8.83G/9.98G [01:39<00:12, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  89%|████████▊ | 8.84G/9.98G [01:39<00:12, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  89%|████████▊ | 8.85G/9.98G [01:39<00:12, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.86G/9.98G [01:39<00:18, 59.4MB/s][A
Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.89G/9.98G [01:39<00:12, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.90G/9.98G [01:39<00:11, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.91G/9.98G [01:40<00:11, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  89%|████████▉ | 8.92G/9.98G [01:40<00:11, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.93G/9.98G [01:40<00:11, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.94G/9.98G [01:40<00:12, 85.5MB/s][A
Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.95G/9.98G [01:40<00:11, 86.4MB/s][A
Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.97G/9.98G [01:40<00:11, 87.7MB/s][A
Downloading (…)of-00002.safetensors:  90%|████████▉ | 8.98G/9.98G [01:40<00:11, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  90%|█████████ | 8.99G/9.98G [01:40<00:11, 88.0MB/s][A
Downloading (…)of-00002.safetensors:  90%|█████████ | 9.00G/9.98G [01:41<00:11, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  90%|█████████ | 9.01G/9.98G [01:41<00:10, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  90%|█████████ | 9.02G/9.98G [01:41<00:10, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  90%|█████████ | 9.03G/9.98G [01:41<00:11, 86.1MB/s][A
Downloading (…)of-00002.safetensors:  91%|█████████ | 9.04G/9.98G [01:41<00:10, 87.0MB/s][A
Downloading (…)of-00002.safetensors:  91%|█████████ | 9.05G/9.98G [01:41<00:10, 88.6MB/s][A
Downloading (…)of-00002.safetensors:  91%|█████████ | 9.06G/9.98G [01:41<00:10, 88.2MB/s][A
Downloading (…)of-00002.safetensors:  91%|█████████ | 9.07G/9.98G [01:41<00:10, 83.8MB/s][A
Downloading (…)of-00002.safetensors:  91%|█████████ | 9.08G/9.98G [01:42<00:10, 85.3MB/s][A
Downloading (…)of-00002.safetensors:  91%|█████████ | 9.09G/9.98G [01:42<00:10, 85.2MB/s][A
Downloading (…)of-00002.safetensors:  91%|█████████ | 9.10G/9.98G [01:42<00:10, 86.7MB/s][A
Downloading (…)of-00002.safetensors:  91%|█████████▏| 9.11G/9.98G [01:42<00:09, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  91%|█████████▏| 9.12G/9.98G [01:42<00:09, 88.0MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.13G/9.98G [01:42<00:09, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.14G/9.98G [01:42<00:09, 90.0MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.15G/9.98G [01:42<00:09, 88.6MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.16G/9.98G [01:42<00:09, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.18G/9.98G [01:43<00:08, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.19G/9.98G [01:43<00:08, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.20G/9.98G [01:43<00:09, 84.4MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.21G/9.98G [01:43<00:08, 86.1MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.22G/9.98G [01:43<00:08, 85.6MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 9.23G/9.98G [01:43<00:08, 87.5MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.24G/9.98G [01:43<00:08, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.25G/9.98G [01:43<00:08, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.26G/9.98G [01:44<00:07, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.27G/9.98G [01:44<00:07, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.28G/9.98G [01:44<00:07, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.29G/9.98G [01:44<00:07, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.30G/9.98G [01:44<00:07, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.31G/9.98G [01:44<00:07, 87.3MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 9.32G/9.98G [01:44<00:07, 88.5MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▎| 9.33G/9.98G [01:44<00:07, 89.4MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▎| 9.34G/9.98G [01:44<00:07, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.35G/9.98G [01:45<00:06, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.36G/9.98G [01:45<00:06, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.37G/9.98G [01:45<00:06, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.38G/9.98G [01:45<00:06, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.40G/9.98G [01:45<00:06, 87.1MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.41G/9.98G [01:45<00:06, 84.5MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.42G/9.98G [01:45<00:06, 86.8MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▍| 9.43G/9.98G [01:45<00:06, 86.2MB/s][A
Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.44G/9.98G [01:46<00:06, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.45G/9.98G [01:46<00:05, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.46G/9.98G [01:46<00:05, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  95%|█████████▍| 9.47G/9.98G [01:46<00:05, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.48G/9.98G [01:46<00:05, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.49G/9.98G [01:46<00:05, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.50G/9.98G [01:46<00:05, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.51G/9.98G [01:46<00:05, 87.1MB/s][A
Downloading (…)of-00002.safetensors:  95%|█████████▌| 9.52G/9.98G [01:46<00:05, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.53G/9.98G [01:47<00:05, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.54G/9.98G [01:47<00:04, 89.7MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.55G/9.98G [01:47<00:04, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.56G/9.98G [01:47<00:04, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.57G/9.98G [01:47<00:04, 91.5MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.58G/9.98G [01:47<00:04, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▌| 9.59G/9.98G [01:47<00:04, 86.3MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▋| 9.60G/9.98G [01:47<00:04, 87.2MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▋| 9.62G/9.98G [01:48<00:04, 86.2MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▋| 9.63G/9.98G [01:48<00:03, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.64G/9.98G [01:48<00:03, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.65G/9.98G [01:48<00:03, 85.3MB/s][A
Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.66G/9.98G [01:48<00:03, 85.9MB/s][A
Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.67G/9.98G [01:48<00:03, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.68G/9.98G [01:48<00:03, 88.8MB/s][A
Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.69G/9.98G [01:48<00:03, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.70G/9.98G [01:48<00:03, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.71G/9.98G [01:49<00:02, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  97%|█████████▋| 9.72G/9.98G [01:49<00:02, 88.6MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.73G/9.98G [01:49<00:02, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.74G/9.98G [01:49<00:02, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.75G/9.98G [01:49<00:02, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.76G/9.98G [01:49<00:02, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.77G/9.98G [01:49<00:02, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.78G/9.98G [01:49<00:02, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.79G/9.98G [01:50<00:02, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.80G/9.98G [01:50<00:01, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.81G/9.98G [01:50<00:01, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 9.83G/9.98G [01:50<00:01, 88.6MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▊| 9.84G/9.98G [01:50<00:01, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▊| 9.85G/9.98G [01:50<00:01, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.86G/9.98G [01:50<00:01, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.87G/9.98G [01:50<00:01, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.88G/9.98G [01:50<00:01, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.89G/9.98G [01:51<00:00, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.90G/9.98G [01:51<00:00, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.91G/9.98G [01:51<00:00, 92.3MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▉| 9.92G/9.98G [01:51<00:00, 92.9MB/s][A
Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.93G/9.98G [01:51<00:00, 91.6MB/s][A
Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.94G/9.98G [01:51<00:00, 91.8MB/s][A
Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.95G/9.98G [01:51<00:00, 87.9MB/s][A
Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.96G/9.98G [01:51<00:00, 90.2MB/s][A
Downloading (…)of-00002.safetensors: 100%|█████████▉| 9.97G/9.98G [01:52<00:00, 90.6MB/s][ADownloading (…)of-00002.safetensors: 100%|██████████| 9.98G/9.98G [01:52<00:00, 89.0MB/s]
Downloading shards:  50%|█████     | 1/2 [01:52<01:52, 112.18s/it]
Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s][A
Downloading (…)of-00002.safetensors:   0%|          | 10.5M/3.50G [00:00<00:42, 81.5MB/s][A
Downloading (…)of-00002.safetensors:   1%|          | 21.0M/3.50G [00:00<00:37, 93.6MB/s][A
Downloading (…)of-00002.safetensors:   1%|          | 31.5M/3.50G [00:00<00:37, 93.2MB/s][A
Downloading (…)of-00002.safetensors:   1%|          | 41.9M/3.50G [00:00<00:37, 92.9MB/s][A
Downloading (…)of-00002.safetensors:   1%|▏         | 52.4M/3.50G [00:00<00:37, 93.0MB/s][A
Downloading (…)of-00002.safetensors:   2%|▏         | 62.9M/3.50G [00:00<00:36, 93.1MB/s][A
Downloading (…)of-00002.safetensors:   2%|▏         | 73.4M/3.50G [00:00<00:38, 89.2MB/s][A
Downloading (…)of-00002.safetensors:   2%|▏         | 83.9M/3.50G [00:00<00:38, 88.9MB/s][A
Downloading (…)of-00002.safetensors:   3%|▎         | 94.4M/3.50G [00:01<00:37, 89.9MB/s][A
Downloading (…)of-00002.safetensors:   3%|▎         | 105M/3.50G [00:01<00:37, 91.6MB/s] [A
Downloading (…)of-00002.safetensors:   3%|▎         | 115M/3.50G [00:01<00:36, 91.6MB/s][A
Downloading (…)of-00002.safetensors:   4%|▎         | 126M/3.50G [00:01<00:36, 91.2MB/s][A
Downloading (…)of-00002.safetensors:   4%|▍         | 136M/3.50G [00:01<00:36, 92.0MB/s][A
Downloading (…)of-00002.safetensors:   4%|▍         | 147M/3.50G [00:01<00:36, 90.7MB/s][A
Downloading (…)of-00002.safetensors:   4%|▍         | 157M/3.50G [00:01<00:36, 90.6MB/s][A
Downloading (…)of-00002.safetensors:   5%|▍         | 168M/3.50G [00:01<00:36, 91.4MB/s][A
Downloading (…)of-00002.safetensors:   5%|▌         | 178M/3.50G [00:01<00:36, 91.1MB/s][A
Downloading (…)of-00002.safetensors:   5%|▌         | 189M/3.50G [00:02<00:36, 91.9MB/s][A
Downloading (…)of-00002.safetensors:   6%|▌         | 199M/3.50G [00:02<00:35, 91.8MB/s][A
Downloading (…)of-00002.safetensors:   6%|▌         | 210M/3.50G [00:02<00:35, 91.8MB/s][A
Downloading (…)of-00002.safetensors:   6%|▋         | 220M/3.50G [00:02<00:36, 89.9MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 231M/3.50G [00:02<00:36, 89.1MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 241M/3.50G [00:02<00:36, 89.5MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 252M/3.50G [00:02<00:35, 90.3MB/s][A
Downloading (…)of-00002.safetensors:   7%|▋         | 262M/3.50G [00:02<00:36, 89.2MB/s][A
Downloading (…)of-00002.safetensors:   8%|▊         | 273M/3.50G [00:03<00:35, 90.9MB/s][A
Downloading (…)of-00002.safetensors:   8%|▊         | 283M/3.50G [00:03<00:35, 91.9MB/s][A
Downloading (…)of-00002.safetensors:   8%|▊         | 294M/3.50G [00:03<00:34, 91.8MB/s][A
Downloading (…)of-00002.safetensors:   9%|▊         | 304M/3.50G [00:03<00:34, 92.4MB/s][A
Downloading (…)of-00002.safetensors:   9%|▉         | 315M/3.50G [00:03<00:34, 93.1MB/s][A
Downloading (…)of-00002.safetensors:   9%|▉         | 325M/3.50G [00:03<00:34, 93.4MB/s][A
Downloading (…)of-00002.safetensors:  10%|▉         | 336M/3.50G [00:03<00:34, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  10%|▉         | 346M/3.50G [00:03<00:34, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  10%|█         | 357M/3.50G [00:03<00:33, 92.8MB/s][A
Downloading (…)of-00002.safetensors:  10%|█         | 367M/3.50G [00:04<00:33, 93.4MB/s][A
Downloading (…)of-00002.safetensors:  11%|█         | 377M/3.50G [00:04<00:33, 93.2MB/s][A
Downloading (…)of-00002.safetensors:  11%|█         | 388M/3.50G [00:04<00:33, 93.3MB/s][A
Downloading (…)of-00002.safetensors:  11%|█▏        | 398M/3.50G [00:04<00:33, 93.5MB/s][A
Downloading (…)of-00002.safetensors:  12%|█▏        | 409M/3.50G [00:04<00:33, 92.7MB/s][A
Downloading (…)of-00002.safetensors:  12%|█▏        | 419M/3.50G [00:04<00:33, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  12%|█▏        | 430M/3.50G [00:04<00:32, 93.4MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 440M/3.50G [00:04<00:32, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 451M/3.50G [00:04<00:32, 92.7MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 461M/3.50G [00:05<00:32, 92.1MB/s][A
Downloading (…)of-00002.safetensors:  13%|█▎        | 472M/3.50G [00:05<00:32, 92.3MB/s][A
Downloading (…)of-00002.safetensors:  14%|█▍        | 482M/3.50G [00:05<00:32, 92.9MB/s][A
Downloading (…)of-00002.safetensors:  14%|█▍        | 493M/3.50G [00:05<00:32, 92.8MB/s][A
Downloading (…)of-00002.safetensors:  14%|█▍        | 503M/3.50G [00:05<00:32, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▍        | 514M/3.50G [00:05<00:32, 92.2MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▍        | 524M/3.50G [00:05<00:33, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  15%|█▌        | 535M/3.50G [00:06<00:50, 58.3MB/s][A
Downloading (…)of-00002.safetensors:  16%|█▌        | 566M/3.50G [00:06<00:32, 91.3MB/s][A
Downloading (…)of-00002.safetensors:  16%|█▋        | 577M/3.50G [00:06<00:32, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 587M/3.50G [00:06<00:31, 92.1MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 598M/3.50G [00:06<00:31, 93.2MB/s][A
Downloading (…)of-00002.safetensors:  17%|█▋        | 608M/3.50G [00:06<00:31, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 619M/3.50G [00:06<00:30, 93.7MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 629M/3.50G [00:06<00:30, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  18%|█▊        | 640M/3.50G [00:07<00:30, 93.7MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▊        | 650M/3.50G [00:07<00:30, 94.6MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▉        | 661M/3.50G [00:07<00:29, 95.6MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▉        | 671M/3.50G [00:07<00:29, 96.1MB/s][A
Downloading (…)of-00002.safetensors:  19%|█▉        | 682M/3.50G [00:07<00:29, 96.2MB/s][A
Downloading (…)of-00002.safetensors:  20%|█▉        | 692M/3.50G [00:07<00:28, 96.9MB/s][A
Downloading (…)of-00002.safetensors:  20%|██        | 703M/3.50G [00:07<00:29, 95.9MB/s][A
Downloading (…)of-00002.safetensors:  20%|██        | 713M/3.50G [00:07<00:29, 95.6MB/s][A
Downloading (…)of-00002.safetensors:  21%|██        | 724M/3.50G [00:07<00:29, 93.1MB/s][A
Downloading (…)of-00002.safetensors:  21%|██        | 734M/3.50G [00:08<00:30, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  21%|██▏       | 744M/3.50G [00:08<00:30, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 755M/3.50G [00:08<00:29, 92.8MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 765M/3.50G [00:08<00:29, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 776M/3.50G [00:08<00:29, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  22%|██▏       | 786M/3.50G [00:08<00:28, 93.6MB/s][A
Downloading (…)of-00002.safetensors:  23%|██▎       | 797M/3.50G [00:08<00:28, 93.6MB/s][A
Downloading (…)of-00002.safetensors:  23%|██▎       | 807M/3.50G [00:08<00:28, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  23%|██▎       | 818M/3.50G [00:08<00:28, 95.1MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▎       | 828M/3.50G [00:09<00:28, 94.1MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▍       | 839M/3.50G [00:09<00:28, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  24%|██▍       | 849M/3.50G [00:09<00:28, 93.2MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▍       | 860M/3.50G [00:09<00:28, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▍       | 870M/3.50G [00:09<00:27, 94.6MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▌       | 881M/3.50G [00:09<00:27, 95.6MB/s][A
Downloading (…)of-00002.safetensors:  25%|██▌       | 891M/3.50G [00:09<00:27, 96.1MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▌       | 902M/3.50G [00:09<00:27, 95.9MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▌       | 912M/3.50G [00:09<00:27, 94.2MB/s][A
Downloading (…)of-00002.safetensors:  26%|██▋       | 923M/3.50G [00:10<00:27, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  27%|██▋       | 933M/3.50G [00:10<00:27, 94.7MB/s][A
Downloading (…)of-00002.safetensors:  27%|██▋       | 944M/3.50G [00:10<00:26, 95.6MB/s][A
Downloading (…)of-00002.safetensors:  27%|██▋       | 954M/3.50G [00:10<00:26, 95.4MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 965M/3.50G [00:10<00:27, 92.8MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 975M/3.50G [00:10<00:27, 93.1MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 986M/3.50G [00:10<00:27, 92.5MB/s][A
Downloading (…)of-00002.safetensors:  28%|██▊       | 996M/3.50G [00:10<00:28, 86.4MB/s][A
Downloading (…)of-00002.safetensors:  29%|██▉       | 1.01G/3.50G [00:10<00:28, 88.5MB/s][A
Downloading (…)of-00002.safetensors:  29%|██▉       | 1.02G/3.50G [00:11<00:27, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  29%|██▉       | 1.03G/3.50G [00:11<00:27, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  30%|██▉       | 1.04G/3.50G [00:11<00:26, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  30%|██▉       | 1.05G/3.50G [00:11<00:26, 93.1MB/s][A
Downloading (…)of-00002.safetensors:  30%|███       | 1.06G/3.50G [00:11<00:25, 94.0MB/s][A
Downloading (…)of-00002.safetensors:  31%|███       | 1.07G/3.50G [00:11<00:25, 95.3MB/s][A
Downloading (…)of-00002.safetensors:  31%|███       | 1.08G/3.50G [00:11<00:25, 96.1MB/s][A
Downloading (…)of-00002.safetensors:  31%|███       | 1.09G/3.50G [00:11<00:25, 94.1MB/s][A
Downloading (…)of-00002.safetensors:  31%|███▏      | 1.10G/3.50G [00:11<00:26, 91.7MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 1.11G/3.50G [00:12<00:25, 93.9MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 1.12G/3.50G [00:12<00:25, 94.9MB/s][A
Downloading (…)of-00002.safetensors:  32%|███▏      | 1.13G/3.50G [00:12<00:25, 93.6MB/s][A
Downloading (…)of-00002.safetensors:  33%|███▎      | 1.14G/3.50G [00:12<00:25, 93.7MB/s][A
Downloading (…)of-00002.safetensors:  33%|███▎      | 1.15G/3.50G [00:12<00:24, 94.4MB/s][A
Downloading (…)of-00002.safetensors:  33%|███▎      | 1.16G/3.50G [00:12<00:24, 95.5MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▎      | 1.17G/3.50G [00:12<00:24, 96.0MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▍      | 1.18G/3.50G [00:12<00:24, 94.8MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▍      | 1.20G/3.50G [00:12<00:24, 94.7MB/s][A
Downloading (…)of-00002.safetensors:  34%|███▍      | 1.21G/3.50G [00:13<00:24, 94.4MB/s][A
Downloading (…)of-00002.safetensors:  35%|███▍      | 1.22G/3.50G [00:13<00:24, 94.4MB/s][A
Downloading (…)of-00002.safetensors:  35%|███▌      | 1.23G/3.50G [00:13<00:23, 94.8MB/s][A
Downloading (…)of-00002.safetensors:  35%|███▌      | 1.24G/3.50G [00:13<00:23, 94.7MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▌      | 1.25G/3.50G [00:13<00:23, 94.9MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▌      | 1.26G/3.50G [00:13<00:23, 94.9MB/s][A
Downloading (…)of-00002.safetensors:  36%|███▌      | 1.27G/3.50G [00:13<00:23, 95.4MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 1.28G/3.50G [00:13<00:23, 95.2MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 1.29G/3.50G [00:13<00:23, 93.7MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 1.30G/3.50G [00:14<00:23, 93.5MB/s][A
Downloading (…)of-00002.safetensors:  37%|███▋      | 1.31G/3.50G [00:14<00:22, 95.3MB/s][A
Downloading (…)of-00002.safetensors:  38%|███▊      | 1.32G/3.50G [00:14<00:22, 95.9MB/s][A
Downloading (…)of-00002.safetensors:  38%|███▊      | 1.33G/3.50G [00:14<00:22, 95.6MB/s][A
Downloading (…)of-00002.safetensors:  38%|███▊      | 1.34G/3.50G [00:14<00:22, 95.2MB/s][A
Downloading (…)of-00002.safetensors:  39%|███▊      | 1.35G/3.50G [00:14<00:22, 95.4MB/s][A
Downloading (…)of-00002.safetensors:  39%|███▉      | 1.36G/3.50G [00:14<00:22, 95.3MB/s][A
Downloading (…)of-00002.safetensors:  39%|███▉      | 1.37G/3.50G [00:14<00:22, 95.5MB/s][A
Downloading (…)of-00002.safetensors:  40%|███▉      | 1.38G/3.50G [00:14<00:22, 94.2MB/s][A
Downloading (…)of-00002.safetensors:  40%|███▉      | 1.39G/3.50G [00:15<00:22, 95.6MB/s][A
Downloading (…)of-00002.safetensors:  40%|████      | 1.41G/3.50G [00:15<00:21, 95.3MB/s][A
Downloading (…)of-00002.safetensors:  40%|████      | 1.42G/3.50G [00:15<00:21, 95.0MB/s][A
Downloading (…)of-00002.safetensors:  41%|████      | 1.43G/3.50G [00:15<00:22, 93.2MB/s][A
Downloading (…)of-00002.safetensors:  41%|████      | 1.44G/3.50G [00:15<00:21, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  41%|████▏     | 1.45G/3.50G [00:15<00:21, 94.4MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 1.46G/3.50G [00:15<00:21, 95.2MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 1.47G/3.50G [00:15<00:21, 95.8MB/s][A
Downloading (…)of-00002.safetensors:  42%|████▏     | 1.48G/3.50G [00:15<00:21, 94.6MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 1.49G/3.50G [00:16<00:21, 94.6MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 1.50G/3.50G [00:16<00:20, 95.6MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 1.51G/3.50G [00:16<00:20, 95.8MB/s][A
Downloading (…)of-00002.safetensors:  43%|████▎     | 1.52G/3.50G [00:16<00:20, 95.7MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▎     | 1.53G/3.50G [00:16<00:20, 94.9MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▍     | 1.54G/3.50G [00:16<00:20, 93.4MB/s][A
Downloading (…)of-00002.safetensors:  44%|████▍     | 1.55G/3.50G [00:16<00:20, 94.4MB/s][A
Downloading (…)of-00002.safetensors:  45%|████▍     | 1.56G/3.50G [00:16<00:20, 93.1MB/s][A
Downloading (…)of-00002.safetensors:  45%|████▍     | 1.57G/3.50G [00:16<00:20, 92.1MB/s][A
Downloading (…)of-00002.safetensors:  45%|████▌     | 1.58G/3.50G [00:17<00:21, 90.2MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▌     | 1.59G/3.50G [00:17<00:21, 90.0MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▌     | 1.60G/3.50G [00:17<00:20, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▌     | 1.61G/3.50G [00:17<00:20, 92.5MB/s][A
Downloading (…)of-00002.safetensors:  46%|████▋     | 1.63G/3.50G [00:17<00:19, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  47%|████▋     | 1.64G/3.50G [00:17<00:19, 94.4MB/s][A
Downloading (…)of-00002.safetensors:  47%|████▋     | 1.65G/3.50G [00:17<00:19, 94.5MB/s][A
Downloading (…)of-00002.safetensors:  47%|████▋     | 1.66G/3.50G [00:17<00:19, 95.0MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 1.67G/3.50G [00:17<00:19, 93.2MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 1.68G/3.50G [00:18<00:19, 94.3MB/s][A
Downloading (…)of-00002.safetensors:  48%|████▊     | 1.69G/3.50G [00:18<00:19, 92.3MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▊     | 1.70G/3.50G [00:18<00:19, 93.2MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▉     | 1.71G/3.50G [00:18<00:19, 92.5MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▉     | 1.72G/3.50G [00:18<00:19, 92.9MB/s][A
Downloading (…)of-00002.safetensors:  49%|████▉     | 1.73G/3.50G [00:18<00:19, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  50%|████▉     | 1.74G/3.50G [00:18<00:18, 95.3MB/s][A
Downloading (…)of-00002.safetensors:  50%|█████     | 1.75G/3.50G [00:18<00:18, 95.9MB/s][A
Downloading (…)of-00002.safetensors:  50%|█████     | 1.76G/3.50G [00:18<00:18, 95.3MB/s][A
Downloading (…)of-00002.safetensors:  51%|█████     | 1.77G/3.50G [00:19<00:18, 94.7MB/s][A
Downloading (…)of-00002.safetensors:  51%|█████     | 1.78G/3.50G [00:19<00:17, 95.6MB/s][A
Downloading (…)of-00002.safetensors:  51%|█████     | 1.79G/3.50G [00:19<00:17, 95.2MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 1.80G/3.50G [00:19<00:17, 95.1MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 1.81G/3.50G [00:19<00:17, 94.6MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 1.82G/3.50G [00:19<00:17, 95.1MB/s][A
Downloading (…)of-00002.safetensors:  52%|█████▏    | 1.84G/3.50G [00:19<00:17, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 1.85G/3.50G [00:19<00:18, 87.4MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 1.86G/3.50G [00:20<00:18, 86.8MB/s][A
Downloading (…)of-00002.safetensors:  53%|█████▎    | 1.87G/3.50G [00:20<00:18, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  54%|█████▎    | 1.88G/3.50G [00:20<00:17, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  54%|█████▍    | 1.89G/3.50G [00:20<00:17, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  54%|█████▍    | 1.90G/3.50G [00:20<00:18, 87.4MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▍    | 1.91G/3.50G [00:20<00:18, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▍    | 1.92G/3.50G [00:20<00:18, 85.6MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▌    | 1.93G/3.50G [00:20<00:18, 85.2MB/s][A
Downloading (…)of-00002.safetensors:  55%|█████▌    | 1.94G/3.50G [00:20<00:17, 87.6MB/s][A
Downloading (…)of-00002.safetensors:  56%|█████▌    | 1.95G/3.50G [00:21<00:17, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  56%|█████▌    | 1.96G/3.50G [00:21<00:17, 88.7MB/s][A
Downloading (…)of-00002.safetensors:  56%|█████▋    | 1.97G/3.50G [00:21<00:17, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 1.98G/3.50G [00:21<00:16, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 1.99G/3.50G [00:21<00:16, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  57%|█████▋    | 2.00G/3.50G [00:21<00:16, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  58%|█████▊    | 2.01G/3.50G [00:21<00:16, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  58%|█████▊    | 2.02G/3.50G [00:21<00:16, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  58%|█████▊    | 2.03G/3.50G [00:21<00:16, 91.5MB/s][A
Downloading (…)of-00002.safetensors:  58%|█████▊    | 2.04G/3.50G [00:22<00:15, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▊    | 2.06G/3.50G [00:22<00:15, 92.2MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▉    | 2.07G/3.50G [00:22<00:15, 92.5MB/s][A
Downloading (…)of-00002.safetensors:  59%|█████▉    | 2.08G/3.50G [00:22<00:15, 93.7MB/s][A
Downloading (…)of-00002.safetensors:  60%|█████▉    | 2.09G/3.50G [00:22<00:15, 93.5MB/s][A
Downloading (…)of-00002.safetensors:  60%|█████▉    | 2.10G/3.50G [00:22<00:15, 92.2MB/s][A
Downloading (…)of-00002.safetensors:  60%|██████    | 2.11G/3.50G [00:22<00:15, 90.6MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████    | 2.12G/3.50G [00:22<00:15, 91.5MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████    | 2.13G/3.50G [00:23<00:14, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████    | 2.14G/3.50G [00:23<00:16, 84.7MB/s][A
Downloading (…)of-00002.safetensors:  61%|██████▏   | 2.15G/3.50G [00:23<00:15, 86.8MB/s][A
Downloading (…)of-00002.safetensors:  62%|██████▏   | 2.16G/3.50G [00:23<00:15, 88.1MB/s][A
Downloading (…)of-00002.safetensors:  62%|██████▏   | 2.17G/3.50G [00:23<00:15, 88.3MB/s][A
Downloading (…)of-00002.safetensors:  62%|██████▏   | 2.18G/3.50G [00:23<00:14, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 2.19G/3.50G [00:23<00:14, 90.1MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 2.20G/3.50G [00:23<00:14, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  63%|██████▎   | 2.21G/3.50G [00:23<00:14, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▎   | 2.22G/3.50G [00:24<00:13, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▍   | 2.23G/3.50G [00:24<00:13, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▍   | 2.24G/3.50G [00:24<00:13, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  64%|██████▍   | 2.25G/3.50G [00:24<00:13, 92.0MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▍   | 2.26G/3.50G [00:24<00:13, 92.8MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▌   | 2.28G/3.50G [00:24<00:13, 93.9MB/s][A
Downloading (…)of-00002.safetensors:  65%|██████▌   | 2.29G/3.50G [00:24<00:12, 94.2MB/s][A
Downloading (…)of-00002.safetensors:  66%|██████▌   | 2.30G/3.50G [00:24<00:12, 93.4MB/s][A
Downloading (…)of-00002.safetensors:  66%|██████▌   | 2.31G/3.50G [00:24<00:12, 93.4MB/s][A
Downloading (…)of-00002.safetensors:  66%|██████▌   | 2.32G/3.50G [00:25<00:12, 93.7MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 2.33G/3.50G [00:25<00:12, 94.9MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 2.34G/3.50G [00:25<00:12, 95.1MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 2.35G/3.50G [00:25<00:12, 94.2MB/s][A
Downloading (…)of-00002.safetensors:  67%|██████▋   | 2.36G/3.50G [00:25<00:12, 94.0MB/s][A
Downloading (…)of-00002.safetensors:  68%|██████▊   | 2.37G/3.50G [00:25<00:11, 94.5MB/s][A
Downloading (…)of-00002.safetensors:  68%|██████▊   | 2.38G/3.50G [00:25<00:11, 94.0MB/s][A
Downloading (…)of-00002.safetensors:  68%|██████▊   | 2.39G/3.50G [00:25<00:11, 93.7MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▊   | 2.40G/3.50G [00:25<00:11, 94.3MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▉   | 2.41G/3.50G [00:26<00:11, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▉   | 2.42G/3.50G [00:26<00:11, 93.6MB/s][A
Downloading (…)of-00002.safetensors:  69%|██████▉   | 2.43G/3.50G [00:26<00:11, 94.3MB/s][A
Downloading (…)of-00002.safetensors:  70%|██████▉   | 2.44G/3.50G [00:26<00:11, 94.2MB/s][A
Downloading (…)of-00002.safetensors:  70%|███████   | 2.45G/3.50G [00:26<00:11, 94.4MB/s][A
Downloading (…)of-00002.safetensors:  70%|███████   | 2.46G/3.50G [00:26<00:10, 95.6MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████   | 2.47G/3.50G [00:26<00:11, 93.1MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████   | 2.49G/3.50G [00:26<00:10, 93.1MB/s][A
Downloading (…)of-00002.safetensors:  71%|███████▏  | 2.50G/3.50G [00:26<00:10, 93.3MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 2.51G/3.50G [00:27<00:10, 93.6MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 2.52G/3.50G [00:27<00:10, 91.6MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 2.53G/3.50G [00:27<00:10, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  72%|███████▏  | 2.54G/3.50G [00:27<00:10, 93.4MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 2.55G/3.50G [00:27<00:10, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 2.56G/3.50G [00:27<00:10, 93.6MB/s][A
Downloading (…)of-00002.safetensors:  73%|███████▎  | 2.57G/3.50G [00:27<00:09, 94.2MB/s][A
Downloading (…)of-00002.safetensors:  74%|███████▎  | 2.58G/3.50G [00:27<00:09, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  74%|███████▍  | 2.59G/3.50G [00:27<00:09, 93.9MB/s][A
Downloading (…)of-00002.safetensors:  74%|███████▍  | 2.60G/3.50G [00:28<00:11, 78.5MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▍  | 2.61G/3.50G [00:28<00:10, 82.4MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▍  | 2.62G/3.50G [00:28<00:10, 85.1MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▌  | 2.63G/3.50G [00:28<00:10, 84.8MB/s][A
Downloading (…)of-00002.safetensors:  75%|███████▌  | 2.64G/3.50G [00:28<00:09, 86.0MB/s][A
Downloading (…)of-00002.safetensors:  76%|███████▌  | 2.65G/3.50G [00:28<00:09, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  76%|███████▌  | 2.66G/3.50G [00:28<00:09, 87.9MB/s][A
Downloading (…)of-00002.safetensors:  76%|███████▋  | 2.67G/3.50G [00:28<00:09, 90.0MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 2.68G/3.50G [00:29<00:08, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 2.69G/3.50G [00:29<00:08, 93.2MB/s][A
Downloading (…)of-00002.safetensors:  77%|███████▋  | 2.71G/3.50G [00:29<00:08, 94.0MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 2.72G/3.50G [00:29<00:08, 95.0MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 2.73G/3.50G [00:29<00:08, 95.0MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 2.74G/3.50G [00:29<00:08, 94.7MB/s][A
Downloading (…)of-00002.safetensors:  78%|███████▊  | 2.75G/3.50G [00:29<00:12, 60.4MB/s][A
Downloading (…)of-00002.safetensors:  79%|███████▉  | 2.77G/3.50G [00:30<00:08, 87.7MB/s][A
Downloading (…)of-00002.safetensors:  80%|███████▉  | 2.79G/3.50G [00:30<00:07, 93.4MB/s][A
Downloading (…)of-00002.safetensors:  80%|████████  | 2.81G/3.50G [00:30<00:07, 94.2MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████  | 2.82G/3.50G [00:30<00:07, 94.2MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████  | 2.83G/3.50G [00:30<00:07, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████  | 2.84G/3.50G [00:30<00:07, 90.3MB/s][A
Downloading (…)of-00002.safetensors:  81%|████████▏ | 2.85G/3.50G [00:30<00:07, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  82%|████████▏ | 2.86G/3.50G [00:31<00:06, 92.4MB/s][A
Downloading (…)of-00002.safetensors:  82%|████████▏ | 2.87G/3.50G [00:31<00:06, 93.2MB/s][A
Downloading (…)of-00002.safetensors:  82%|████████▏ | 2.88G/3.50G [00:31<00:06, 94.0MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 2.89G/3.50G [00:31<00:06, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 2.90G/3.50G [00:31<00:06, 93.2MB/s][A
Downloading (…)of-00002.safetensors:  83%|████████▎ | 2.92G/3.50G [00:31<00:06, 92.1MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▎ | 2.93G/3.50G [00:31<00:06, 88.2MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▍ | 2.94G/3.50G [00:31<00:06, 87.8MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▍ | 2.95G/3.50G [00:32<00:06, 89.2MB/s][A
Downloading (…)of-00002.safetensors:  84%|████████▍ | 2.96G/3.50G [00:32<00:06, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▍ | 2.97G/3.50G [00:32<00:05, 89.0MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▌ | 2.98G/3.50G [00:32<00:05, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  85%|████████▌ | 2.99G/3.50G [00:32<00:05, 90.5MB/s][A
Downloading (…)of-00002.safetensors:  86%|████████▌ | 3.00G/3.50G [00:32<00:05, 91.5MB/s][A
Downloading (…)of-00002.safetensors:  86%|████████▌ | 3.01G/3.50G [00:32<00:05, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  86%|████████▋ | 3.02G/3.50G [00:32<00:05, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 3.03G/3.50G [00:32<00:05, 91.4MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 3.04G/3.50G [00:33<00:04, 92.1MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 3.05G/3.50G [00:33<00:04, 91.9MB/s][A
Downloading (…)of-00002.safetensors:  87%|████████▋ | 3.06G/3.50G [00:33<00:04, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 3.07G/3.50G [00:33<00:04, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 3.08G/3.50G [00:33<00:04, 93.7MB/s][A
Downloading (…)of-00002.safetensors:  88%|████████▊ | 3.09G/3.50G [00:33<00:04, 90.8MB/s][A
Downloading (…)of-00002.safetensors:  89%|████████▊ | 3.10G/3.50G [00:33<00:04, 89.3MB/s][A
Downloading (…)of-00002.safetensors:  89%|████████▉ | 3.11G/3.50G [00:33<00:04, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  89%|████████▉ | 3.12G/3.50G [00:33<00:04, 89.5MB/s][A
Downloading (…)of-00002.safetensors:  90%|████████▉ | 3.14G/3.50G [00:34<00:04, 91.2MB/s][A
Downloading (…)of-00002.safetensors:  90%|████████▉ | 3.15G/3.50G [00:34<00:03, 89.6MB/s][A
Downloading (…)of-00002.safetensors:  90%|█████████ | 3.16G/3.50G [00:34<00:03, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  90%|█████████ | 3.17G/3.50G [00:34<00:03, 92.5MB/s][A
Downloading (…)of-00002.safetensors:  91%|█████████ | 3.18G/3.50G [00:34<00:03, 93.0MB/s][A
Downloading (…)of-00002.safetensors:  91%|█████████ | 3.19G/3.50G [00:34<00:03, 93.6MB/s][A
Downloading (…)of-00002.safetensors:  91%|█████████▏| 3.20G/3.50G [00:34<00:03, 93.4MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 3.21G/3.50G [00:34<00:03, 92.4MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 3.22G/3.50G [00:34<00:03, 92.7MB/s][A
Downloading (…)of-00002.safetensors:  92%|█████████▏| 3.23G/3.50G [00:35<00:02, 93.1MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 3.24G/3.50G [00:35<00:02, 92.7MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 3.25G/3.50G [00:35<00:02, 93.8MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 3.26G/3.50G [00:35<00:02, 92.7MB/s][A
Downloading (…)of-00002.safetensors:  93%|█████████▎| 3.27G/3.50G [00:35<00:02, 92.5MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▍| 3.28G/3.50G [00:35<00:02, 92.9MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▍| 3.29G/3.50G [00:35<00:02, 93.3MB/s][A
Downloading (…)of-00002.safetensors:  94%|█████████▍| 3.30G/3.50G [00:35<00:02, 93.3MB/s][A
Downloading (…)of-00002.safetensors:  95%|█████████▍| 3.31G/3.50G [00:35<00:02, 92.7MB/s][A
Downloading (…)of-00002.safetensors:  95%|█████████▍| 3.32G/3.50G [00:36<00:01, 89.8MB/s][A
Downloading (…)of-00002.safetensors:  95%|█████████▌| 3.33G/3.50G [00:36<00:01, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▌| 3.34G/3.50G [00:36<00:01, 92.7MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▌| 3.36G/3.50G [00:36<00:01, 91.0MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▌| 3.37G/3.50G [00:36<00:01, 90.7MB/s][A
Downloading (…)of-00002.safetensors:  96%|█████████▋| 3.38G/3.50G [00:36<00:01, 91.8MB/s][A
Downloading (…)of-00002.safetensors:  97%|█████████▋| 3.39G/3.50G [00:36<00:01, 89.9MB/s][A
Downloading (…)of-00002.safetensors:  97%|█████████▋| 3.40G/3.50G [00:36<00:01, 89.1MB/s][A
Downloading (…)of-00002.safetensors:  97%|█████████▋| 3.41G/3.50G [00:37<00:01, 91.1MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 3.42G/3.50G [00:37<00:00, 88.4MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 3.43G/3.50G [00:37<00:00, 89.8MB/s][A
Downloading (…)of-00002.safetensors:  98%|█████████▊| 3.44G/3.50G [00:37<00:00, 90.4MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▊| 3.45G/3.50G [00:37<00:00, 90.9MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▉| 3.46G/3.50G [00:37<00:00, 92.1MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▉| 3.47G/3.50G [00:37<00:00, 93.3MB/s][A
Downloading (…)of-00002.safetensors:  99%|█████████▉| 3.48G/3.50G [00:37<00:00, 88.9MB/s][A
Downloading (…)of-00002.safetensors: 100%|█████████▉| 3.49G/3.50G [00:37<00:00, 89.4MB/s][ADownloading (…)of-00002.safetensors: 100%|██████████| 3.50G/3.50G [00:38<00:00, 91.9MB/s]
Downloading shards: 100%|██████████| 2/2 [02:30<00:00, 68.66s/it] Downloading shards: 100%|██████████| 2/2 [02:30<00:00, 75.19s/it]
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.32s/it]
Downloading generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]Downloading generation_config.json: 100%|██████████| 188/188 [00:00<00:00, 39.4kB/s]
  0%|          | 0/14 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  7%|▋         | 1/14 [00:00<00:02,  5.42it/s] 36%|███▌      | 5/14 [00:00<00:00, 19.18it/s] 64%|██████▍   | 9/14 [00:00<00:00, 25.59it/s] 93%|█████████▎| 13/14 [00:00<00:00, 29.13it/s]100%|██████████| 14/14 [00:00<00:00, 25.21it/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 16972.88 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-1-shot-8/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.020 MB uploadedwandb: | 0.026 MB of 0.032 MB uploaded (0.005 MB deduped)wandb: / 0.035 MB of 0.035 MB uploaded (0.005 MB deduped)Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
2024-03-08 08:49:40.076575: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 08:49:40.821077: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 08:49:47.676952: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:49:47.690939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:49:47.693427: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:49:47.707678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:49:47.710188: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:49:47.712561: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:49:47.896941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:49:47.898605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:49:47.900086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:49:47.901573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.29s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:05,  5.41it/s] 13%|█▎        | 4/30 [00:00<00:01, 16.13it/s] 27%|██▋       | 8/30 [00:00<00:00, 24.23it/s] 40%|████      | 12/30 [00:00<00:00, 28.57it/s] 53%|█████▎    | 16/30 [00:00<00:00, 31.10it/s] 67%|██████▋   | 20/30 [00:00<00:00, 32.74it/s] 80%|████████  | 24/30 [00:00<00:00, 33.75it/s] 93%|█████████▎| 28/30 [00:00<00:00, 34.35it/s]100%|██████████| 30/30 [00:01<00:00, 29.72it/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 16858.54 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-1-shot-8/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.029 MB uploadedwandb: | 0.020 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
13+8+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-13-shot-8
2024-03-08 08:52:32.002421: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 08:52:32.805800: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 08:52:39.472825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:52:39.481621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:52:39.484046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:52:39.497849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:52:39.500252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:52:39.502630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:52:39.696586: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:52:39.698221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:52:39.699701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:52:39.701178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:32<00:32, 32.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.42s/it]
  0%|          | 0/14 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  7%|▋         | 1/14 [00:00<00:02,  5.16it/s] 36%|███▌      | 5/14 [00:00<00:00, 18.40it/s] 64%|██████▍   | 9/14 [00:00<00:00, 24.95it/s] 93%|█████████▎| 13/14 [00:00<00:00, 28.61it/s]100%|██████████| 14/14 [00:00<00:00, 24.63it/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 15136.81 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-13-shot-8/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
2024-03-08 08:55:22.389387: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 08:55:23.196613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 08:55:30.202047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:55:30.211545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:55:30.214010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:55:30.233168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:55:30.235591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:55:30.237969: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:55:30.421322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:55:30.422976: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:55:30.424454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:55:30.425952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.14s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:05,  4.92it/s] 17%|█▋        | 5/30 [00:00<00:01, 18.09it/s] 30%|███       | 9/30 [00:00<00:00, 24.65it/s] 43%|████▎     | 13/30 [00:00<00:00, 28.50it/s] 57%|█████▋    | 17/30 [00:00<00:00, 30.97it/s] 70%|███████   | 21/30 [00:00<00:00, 31.19it/s] 83%|████████▎ | 25/30 [00:00<00:00, 32.13it/s] 97%|█████████▋| 29/30 [00:01<00:00, 32.69it/s]100%|██████████| 30/30 [00:01<00:00, 28.62it/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 16695.61 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-13-shot-8/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
42+8+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-42-shot-8
2024-03-08 08:58:11.313334: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 08:58:12.081174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 08:58:18.846698: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:58:18.855610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:58:18.858025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:58:18.872062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:58:18.874449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:58:18.876808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:58:19.051597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:58:19.053170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:58:19.054619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 08:58:19.056083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.33s/it]
  0%|          | 0/14 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  7%|▋         | 1/14 [00:00<00:02,  5.45it/s] 36%|███▌      | 5/14 [00:00<00:00, 19.17it/s] 64%|██████▍   | 9/14 [00:00<00:00, 25.39it/s] 93%|█████████▎| 13/14 [00:00<00:00, 27.77it/s]100%|██████████| 14/14 [00:00<00:00, 24.12it/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 16765.28 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-42-shot-8/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.021 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
2024-03-08 09:01:00.014823: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:01:00.814781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:01:07.758380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:01:07.767520: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:01:07.769983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:01:07.783331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:01:07.785741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:01:07.788112: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:01:07.973300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:01:07.974934: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:01:07.976405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:01:07.977883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.18s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:06,  4.77it/s] 17%|█▋        | 5/30 [00:00<00:01, 17.71it/s] 30%|███       | 9/30 [00:00<00:00, 24.08it/s] 43%|████▎     | 13/30 [00:00<00:00, 27.87it/s] 57%|█████▋    | 17/30 [00:00<00:00, 30.25it/s] 70%|███████   | 21/30 [00:00<00:00, 31.55it/s] 83%|████████▎ | 25/30 [00:00<00:00, 32.55it/s] 97%|█████████▋| 29/30 [00:01<00:00, 33.19it/s]100%|██████████| 30/30 [00:01<00:00, 28.56it/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 12166.15 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-42-shot-8/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.021 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
1+2+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-1-shot-2
2024-03-08 09:03:50.376797: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:03:51.154431: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:03:57.859444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:03:57.869057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:03:57.871527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:03:57.885814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:03:57.888324: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:03:57.890684: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:03:58.069263: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:03:58.070902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:03:58.072370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:03:58.073861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:32<00:32, 32.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:43<00:00, 19.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:43<00:00, 21.53s/it]
  0%|          | 0/2 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
 50%|█████     | 1/2 [00:00<00:00,  4.87it/s]100%|██████████| 2/2 [00:00<00:00,  8.51it/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 16177.42 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-1-shot-2/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
2024-03-08 09:06:39.827545: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:06:40.602942: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:06:48.912573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:06:48.922184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:06:48.924671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:06:48.940168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:06:48.942583: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:06:48.944958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:06:49.337148: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:06:49.338777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:06:49.340254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:06:49.341752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.21s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:06,  4.79it/s] 13%|█▎        | 4/30 [00:00<00:01, 14.93it/s] 27%|██▋       | 8/30 [00:00<00:00, 22.78it/s] 40%|████      | 12/30 [00:00<00:00, 27.21it/s] 53%|█████▎    | 16/30 [00:00<00:00, 29.86it/s] 67%|██████▋   | 20/30 [00:00<00:00, 31.35it/s] 80%|████████  | 24/30 [00:00<00:00, 32.32it/s] 93%|█████████▎| 28/30 [00:01<00:00, 32.97it/s]100%|██████████| 30/30 [00:01<00:00, 28.26it/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-1-shot-2/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.020 MB uploadedwandb: | 0.020 MB of 0.026 MB uploadedwandb: / 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
13+2+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-13-shot-2
2024-03-08 09:09:32.858831: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:09:33.634945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:09:41.556116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:09:41.565563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:09:41.568041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:09:41.583177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:09:41.585556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:09:41.587914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:09:41.870610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:09:41.872206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:09:41.873670: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:09:41.875128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.30s/it]
  0%|          | 0/2 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
 50%|█████     | 1/2 [00:00<00:00,  5.18it/s]100%|██████████| 2/2 [00:00<00:00,  8.50it/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 15591.51 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-13-shot-2/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.026 MB uploadedwandb: | 0.026 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
2024-03-08 09:12:24.018661: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:12:24.801262: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:12:31.950433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:12:31.958536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:12:31.959924: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:12:31.972581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:12:31.973952: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:12:31.975287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:12:32.149551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:12:32.151028: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:12:32.152374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:12:32.153723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.44s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:06,  4.73it/s] 17%|█▋        | 5/30 [00:00<00:01, 17.62it/s] 30%|███       | 9/30 [00:00<00:00, 24.24it/s] 43%|████▎     | 13/30 [00:00<00:00, 27.77it/s] 57%|█████▋    | 17/30 [00:00<00:00, 29.93it/s] 70%|███████   | 21/30 [00:00<00:00, 31.69it/s] 83%|████████▎ | 25/30 [00:00<00:00, 32.97it/s] 97%|█████████▋| 29/30 [00:01<00:00, 33.70it/s]100%|██████████| 30/30 [00:01<00:00, 28.73it/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-13-shot-2/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.026 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
42+2+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-42-shot-2
2024-03-08 09:15:14.356966: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:15:15.149005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:15:21.970750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:15:21.980325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:15:21.982800: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:15:21.997942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:15:22.000355: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:15:22.002753: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:15:22.186997: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:15:22.188648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:15:22.190125: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:15:22.191604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.18s/it]
  0%|          | 0/2 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
 50%|█████     | 1/2 [00:00<00:00,  4.85it/s]100%|██████████| 2/2 [00:00<00:00,  8.46it/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 16136.72 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-42-shot-2/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.021 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
2024-03-08 09:18:07.376514: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:18:08.211413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:18:15.435737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:18:15.444701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:18:15.447096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:18:15.461015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:18:15.463387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:18:15.465731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:18:15.650245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:18:15.651830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:18:15.653288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:18:15.654753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.39s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:05,  5.07it/s] 17%|█▋        | 5/30 [00:00<00:01, 18.62it/s] 30%|███       | 9/30 [00:00<00:00, 25.34it/s] 43%|████▎     | 13/30 [00:00<00:00, 29.18it/s] 57%|█████▋    | 17/30 [00:00<00:00, 31.40it/s] 70%|███████   | 21/30 [00:00<00:00, 32.87it/s] 83%|████████▎ | 25/30 [00:00<00:00, 33.83it/s] 97%|█████████▋| 29/30 [00:00<00:00, 34.45it/s]100%|██████████| 30/30 [00:01<00:00, 29.54it/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-42-shot-2/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
1+4+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-1-shot-4
2024-03-08 09:20:58.177979: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:20:58.948758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:21:05.900618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:21:05.909850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:21:05.912279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:21:05.933082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:21:05.935491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:21:05.937872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:21:06.129675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:21:06.131402: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:21:06.132881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:21:06.134368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.45s/it]
  0%|          | 0/6 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
 17%|█▋        | 1/6 [00:00<00:01,  4.67it/s] 83%|████████▎ | 5/6 [00:00<00:00, 17.24it/s]100%|██████████| 6/6 [00:00<00:00, 16.36it/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 16705.92 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-1-shot-4/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
2024-03-08 09:23:50.811057: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:23:51.595712: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:23:58.876587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:23:58.886192: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:23:58.888599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:23:58.903765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:23:58.906235: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:23:58.908580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:23:59.102343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:23:59.104294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:23:59.105745: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:23:59.107220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.05s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:05,  5.36it/s] 17%|█▋        | 5/30 [00:00<00:01, 18.22it/s] 30%|███       | 9/30 [00:00<00:00, 24.77it/s] 43%|████▎     | 13/30 [00:00<00:00, 28.43it/s] 57%|█████▋    | 17/30 [00:00<00:00, 30.74it/s] 70%|███████   | 21/30 [00:00<00:00, 32.20it/s] 83%|████████▎ | 25/30 [00:00<00:00, 33.18it/s] 97%|█████████▋| 29/30 [00:00<00:00, 33.79it/s]100%|██████████| 30/30 [00:01<00:00, 29.28it/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-1-shot-4/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
13+4+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-13-shot-4
2024-03-08 09:26:40.307705: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:26:41.095459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:26:48.214212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:26:48.223676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:26:48.226118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:26:48.240390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:26:48.242802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:26:48.245164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:26:48.430629: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:26:48.432262: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:26:48.433736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:26:48.435209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.29s/it]
  0%|          | 0/6 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
 17%|█▋        | 1/6 [00:00<00:00,  5.02it/s] 83%|████████▎ | 5/6 [00:00<00:00, 17.61it/s]100%|██████████| 6/6 [00:00<00:00, 16.93it/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 16937.44 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-13-shot-4/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
2024-03-08 09:29:31.304756: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:29:32.089917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:29:39.410363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:29:39.419326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:29:39.421773: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:29:39.444992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:29:39.447500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:29:39.449897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:29:39.638271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:29:39.639918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:29:39.641395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:29:39.642882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 19.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.92s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:06,  4.78it/s] 17%|█▋        | 5/30 [00:00<00:01, 17.78it/s] 30%|███       | 9/30 [00:00<00:00, 24.42it/s] 43%|████▎     | 13/30 [00:00<00:00, 28.18it/s] 57%|█████▋    | 17/30 [00:00<00:00, 30.47it/s] 70%|███████   | 21/30 [00:00<00:00, 31.86it/s] 83%|████████▎ | 25/30 [00:00<00:00, 33.06it/s] 97%|█████████▋| 29/30 [00:01<00:00, 33.79it/s]100%|██████████| 30/30 [00:01<00:00, 28.89it/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-13-shot-4/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
42+4+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-42-shot-4
2024-03-08 09:32:21.005524: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:32:21.838543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:32:28.756695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:32:28.766023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:32:28.768485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:32:28.783654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:32:28.786060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:32:28.788437: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:32:28.978759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:32:28.980395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:32:28.981869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:32:28.983365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:32<00:32, 32.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:43<00:00, 19.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:43<00:00, 21.53s/it]
  0%|          | 0/6 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
 17%|█▋        | 1/6 [00:00<00:01,  4.98it/s] 83%|████████▎ | 5/6 [00:00<00:00, 18.39it/s]100%|██████████| 6/6 [00:00<00:00, 17.39it/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 17107.46 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-42-shot-4/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.026 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
2024-03-08 09:35:10.893601: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:35:11.668217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:35:19.014482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:35:19.024080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:35:19.026971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:35:19.041967: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:35:19.044345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:35:19.046699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:35:19.235428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:35:19.237011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:35:19.238464: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:35:19.239947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:32<00:32, 32.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.36s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:06,  4.36it/s] 17%|█▋        | 5/30 [00:00<00:01, 16.59it/s] 30%|███       | 9/30 [00:00<00:00, 22.87it/s] 43%|████▎     | 13/30 [00:00<00:00, 27.16it/s] 57%|█████▋    | 17/30 [00:00<00:00, 29.84it/s] 70%|███████   | 21/30 [00:00<00:00, 31.65it/s] 83%|████████▎ | 25/30 [00:00<00:00, 32.82it/s] 97%|█████████▋| 29/30 [00:01<00:00, 33.65it/s]100%|██████████| 30/30 [00:01<00:00, 28.20it/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-42-shot-4/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.021 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
1+16+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-1-shot-16
2024-03-08 09:38:01.795748: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:38:02.586801: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:38:09.660246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:38:09.669480: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:38:09.672455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:38:09.686486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:38:09.688895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:38:09.691255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:38:10.177282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:38:10.178903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:38:10.180378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:38:10.181862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.34s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:05,  5.44it/s] 17%|█▋        | 5/30 [00:00<00:01, 18.61it/s] 30%|███       | 9/30 [00:00<00:00, 25.35it/s] 43%|████▎     | 13/30 [00:00<00:00, 27.94it/s] 53%|█████▎    | 16/30 [00:00<00:00, 28.04it/s] 67%|██████▋   | 20/30 [00:00<00:00, 29.93it/s] 80%|████████  | 24/30 [00:00<00:00, 30.57it/s] 93%|█████████▎| 28/30 [00:01<00:00, 31.10it/s]100%|██████████| 30/30 [00:01<00:00, 27.83it/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-1-shot-16/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
2024-03-08 09:40:53.534358: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:40:54.335912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:41:01.526297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:41:01.536392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:41:01.538781: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:41:01.553986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:41:01.556372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:41:01.558718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:41:01.745358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:41:01.746979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:41:01.748427: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:41:01.749889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.37s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:05,  5.29it/s] 17%|█▋        | 5/30 [00:00<00:01, 18.24it/s] 30%|███       | 9/30 [00:00<00:00, 24.75it/s] 43%|████▎     | 13/30 [00:00<00:00, 28.40it/s] 57%|█████▋    | 17/30 [00:00<00:00, 30.88it/s] 70%|███████   | 21/30 [00:00<00:00, 32.44it/s] 83%|████████▎ | 25/30 [00:00<00:00, 33.46it/s] 97%|█████████▋| 29/30 [00:00<00:00, 34.19it/s]100%|██████████| 30/30 [00:01<00:00, 29.45it/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-1-shot-16/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.021 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
13+16+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-13-shot-16
2024-03-08 09:43:43.498673: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:43:44.290157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:43:51.261565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:43:51.271144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:43:51.273540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:43:51.288529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:43:51.290902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:43:51.293247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:43:51.478363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:43:51.479972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:43:51.481424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:43:51.482883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:32<00:32, 32.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:43<00:00, 19.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:43<00:00, 21.61s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:06,  4.78it/s] 17%|█▋        | 5/30 [00:00<00:01, 18.11it/s] 30%|███       | 9/30 [00:00<00:00, 24.93it/s] 43%|████▎     | 13/30 [00:00<00:00, 28.85it/s] 57%|█████▋    | 17/30 [00:00<00:00, 31.04it/s] 70%|███████   | 21/30 [00:00<00:00, 32.59it/s] 83%|████████▎ | 25/30 [00:00<00:00, 33.39it/s] 97%|█████████▋| 29/30 [00:00<00:00, 33.95it/s]100%|██████████| 30/30 [00:01<00:00, 29.28it/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-13-shot-16/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.021 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
2024-03-08 09:46:34.850466: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:46:35.715577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:46:42.705739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:46:42.714733: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:46:42.717155: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:46:42.736857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:46:42.739249: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:46:42.741615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:46:42.923563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:46:42.925195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:46:42.926662: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:46:42.928163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.10s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:05,  4.85it/s] 17%|█▋        | 5/30 [00:00<00:01, 17.57it/s] 30%|███       | 9/30 [00:00<00:00, 23.76it/s] 43%|████▎     | 13/30 [00:00<00:00, 27.63it/s] 57%|█████▋    | 17/30 [00:00<00:00, 29.88it/s] 70%|███████   | 21/30 [00:00<00:00, 31.24it/s] 83%|████████▎ | 25/30 [00:00<00:00, 32.45it/s] 97%|█████████▋| 29/30 [00:01<00:00, 32.09it/s]100%|██████████| 30/30 [00:01<00:00, 28.06it/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-13-shot-16/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.026 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
42+16+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-42-shot-16
2024-03-08 09:49:23.469556: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:49:24.229265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:49:31.199129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:49:31.209209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:49:31.211634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:49:31.226473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:49:31.228837: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:49:31.231180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:49:31.419080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:49:31.420709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:49:31.422185: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:49:31.423667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:31<00:31, 31.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 19.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:42<00:00, 21.15s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:06,  4.54it/s] 17%|█▋        | 5/30 [00:00<00:01, 16.86it/s] 30%|███       | 9/30 [00:00<00:00, 23.52it/s] 43%|████▎     | 13/30 [00:00<00:00, 27.59it/s] 57%|█████▋    | 17/30 [00:00<00:00, 30.02it/s] 70%|███████   | 21/30 [00:00<00:00, 31.69it/s] 83%|████████▎ | 25/30 [00:00<00:00, 31.69it/s] 97%|█████████▋| 29/30 [00:01<00:00, 32.37it/s]100%|██████████| 30/30 [00:01<00:00, 27.94it/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-42-shot-16/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
2024-03-08 09:52:13.989544: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-08 09:52:14.855363: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-03-08 09:52:21.823734: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:52:21.832744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:52:21.835182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:52:21.850455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:52:21.852907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:52:21.855250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:52:22.046659: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:52:22.048327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:52:22.049803: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-08 09:52:22.051646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:257: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:32<00:32, 32.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:43<00:00, 19.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:43<00:00, 21.50s/it]
  0%|          | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  3%|▎         | 1/30 [00:00<00:06,  4.69it/s] 17%|█▋        | 5/30 [00:00<00:01, 17.18it/s] 30%|███       | 9/30 [00:00<00:00, 22.95it/s] 43%|████▎     | 13/30 [00:00<00:00, 26.52it/s] 57%|█████▋    | 17/30 [00:00<00:00, 28.54it/s] 70%|███████   | 21/30 [00:00<00:00, 30.01it/s] 83%|████████▎ | 25/30 [00:00<00:00, 30.81it/s] 97%|█████████▋| 29/30 [00:01<00:00, 31.68it/s]100%|██████████| 30/30 [00:01<00:00, 27.27it/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/knn_icl-seed-42-shot-16/swap_labels_log.csv
  0%|          | 0/1000 [00:00<?, ?it/s]wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.029 MB uploadedwandb: | 0.029 MB of 0.029 MB uploadedTraceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 301, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 444, in attack
    goal_function_result, _ = self.goal_function.init_attack_example(
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 68, in init_attack_example
    result, _ = self.get_result(attacked_text, check_skip=True)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 79, in get_result
    results, search_over = self.get_results([attacked_text], **kwargs)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 328, in insert_icl_prompts
    inputs = tokenizer.batch_encode_plus(prompts, padding=True, truncation=True, return_tensors="pt")
  File "/transformers/src/transformers/tokenization_utils_base.py", line 3073, in batch_encode_plus
    return self._batch_encode_plus(
  File "/transformers/src/transformers/tokenization_utils_fast.py", line 537, in _batch_encode_plus
    for key in tokens_and_encodings[0][0].keys():
IndexError: list index out of range
