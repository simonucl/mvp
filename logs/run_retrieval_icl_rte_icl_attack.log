
1+16+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/rte/meta-llama/Llama-2-7b-hf/icl_attack/retrieval_icl-seed-1-shot-16
textattack: Updating TextAttack package dependencies.
textattack: Downloading NLTK required packages.
2024-03-11 04:48:20.242978: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-11 04:48:21.118856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /root/nltk_data...
[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.
[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Unzipping corpora/stopwords.zip.
[nltk_data] Downloading package omw to /root/nltk_data...
[nltk_data] Downloading package universal_tagset to /root/nltk_data...
[nltk_data]   Unzipping taggers/universal_tagset.zip.
[nltk_data] Downloading package wordnet to /root/nltk_data...
[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt.zip.
textattack: Downloading https://textattack.s3.amazonaws.com/word_embeddings/paragramcf.

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py", line 3500, in _map_single
    writer.finalize()  # close_stream=bool(buf_writer is None))  # We only close if we are writing in a file
  File "/usr/local/lib/python3.8/dist-packages/datasets/arrow_writer.py", line 586, in finalize
    self.write_examples_on_file()
  File "/usr/local/lib/python3.8/dist-packages/datasets/arrow_writer.py", line 444, in write_examples_on_file
    batch_examples[col] = [
  File "/usr/local/lib/python3.8/dist-packages/datasets/arrow_writer.py", line 445, in <listcomp>
    row[0][col].to_pylist()[0] if isinstance(row[0][col], (pa.Array, pa.ChunkedArray)) else row[0][col]
KeyError: 'Premise_0'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 201, in attacker
    my_dataset = my_dataset[split].map(lambda x: convert_to_icl(x, icl_examples, verbalizer), batched=False)
  File "/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py", line 592, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py", line 557, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py", line 3097, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py", line 3505, in _map_single
    writer.finalize()
  File "/usr/local/lib/python3.8/dist-packages/datasets/arrow_writer.py", line 586, in finalize
    self.write_examples_on_file()
  File "/usr/local/lib/python3.8/dist-packages/datasets/arrow_writer.py", line 444, in write_examples_on_file
    batch_examples[col] = [
  File "/usr/local/lib/python3.8/dist-packages/datasets/arrow_writer.py", line 445, in <listcomp>
    row[0][col].to_pylist()[0] if isinstance(row[0][col], (pa.Array, pa.ChunkedArray)) else row[0][col]
KeyError: 'Premise_0'
