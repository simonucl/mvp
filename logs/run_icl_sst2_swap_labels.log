1+8+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-1-shot-8
textattack: Updating TextAttack package dependencies.
textattack: Downloading NLTK required packages.
2024-01-26 12:55:12.528457: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 12:55:13.480681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /root/nltk_data...
[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.
[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Unzipping corpora/stopwords.zip.
[nltk_data] Downloading package omw to /root/nltk_data...
[nltk_data] Downloading package universal_tagset to /root/nltk_data...
[nltk_data]   Unzipping taggers/universal_tagset.zip.
[nltk_data] Downloading package wordnet to /root/nltk_data...
[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt.zip.
textattack: Downloading https://textattack.s3.amazonaws.com/word_embeddings/paragramcf.
  0%|          | 0.00/481M [00:00<?, ?B/s]  0%|          | 54.3k/481M [00:00<24:39, 325kB/s]  0%|          | 153k/481M [00:00<12:50, 624kB/s]   0%|          | 305k/481M [00:00<09:52, 812kB/s]  0%|          | 1.08M/481M [00:00<02:39, 3.00MB/s]  0%|          | 2.36M/481M [00:00<01:31, 5.21MB/s]  1%|â–         | 6.27M/481M [00:00<00:32, 14.6MB/s]  2%|â–         | 10.2M/481M [00:00<00:25, 18.6MB/s]  3%|â–Ž         | 14.6M/481M [00:01<00:18, 25.2MB/s]  4%|â–         | 18.6M/481M [00:01<00:18, 25.5MB/s]  5%|â–         | 23.1M/481M [00:01<00:15, 30.4MB/s]  6%|â–Œ         | 27.0M/481M [00:01<00:15, 28.5MB/s]  7%|â–‹         | 31.4M/481M [00:01<00:13, 32.3MB/s]  7%|â–‹         | 35.3M/481M [00:01<00:14, 29.8MB/s]  8%|â–Š         | 39.5M/481M [00:01<00:13, 32.8MB/s]  9%|â–‰         | 43.6M/481M [00:01<00:14, 30.6MB/s] 10%|â–‰         | 48.1M/481M [00:02<00:12, 34.0MB/s] 11%|â–ˆ         | 52.2M/481M [00:02<00:13, 31.3MB/s] 12%|â–ˆâ–        | 56.4M/481M [00:02<00:12, 34.1MB/s] 13%|â–ˆâ–Ž        | 60.5M/481M [00:02<00:13, 31.2MB/s] 13%|â–ˆâ–Ž        | 64.8M/481M [00:02<00:12, 34.0MB/s] 14%|â–ˆâ–        | 68.5M/481M [00:02<00:13, 30.5MB/s] 15%|â–ˆâ–        | 71.9M/481M [00:02<00:13, 31.4MB/s] 16%|â–ˆâ–Œ        | 76.0M/481M [00:02<00:13, 29.0MB/s] 17%|â–ˆâ–‹        | 79.8M/481M [00:03<00:12, 31.3MB/s] 17%|â–ˆâ–‹        | 83.2M/481M [00:03<00:14, 27.8MB/s] 18%|â–ˆâ–Š        | 87.0M/481M [00:03<00:12, 30.4MB/s] 19%|â–ˆâ–‰        | 90.3M/481M [00:03<00:14, 27.0MB/s] 20%|â–ˆâ–‰        | 94.0M/481M [00:03<00:13, 29.4MB/s] 20%|â–ˆâ–ˆ        | 97.4M/481M [00:03<00:14, 26.8MB/s] 21%|â–ˆâ–ˆ        | 101M/481M [00:03<00:12, 30.0MB/s]  22%|â–ˆâ–ˆâ–       | 105M/481M [00:04<00:13, 27.1MB/s] 23%|â–ˆâ–ˆâ–Ž       | 109M/481M [00:04<00:12, 30.1MB/s] 23%|â–ˆâ–ˆâ–Ž       | 112M/481M [00:04<00:13, 27.3MB/s] 24%|â–ˆâ–ˆâ–       | 116M/481M [00:04<00:12, 30.3MB/s] 25%|â–ˆâ–ˆâ–       | 120M/481M [00:04<00:12, 28.6MB/s] 26%|â–ˆâ–ˆâ–Œ       | 124M/481M [00:04<00:11, 31.4MB/s] 27%|â–ˆâ–ˆâ–‹       | 128M/481M [00:04<00:12, 29.2MB/s] 27%|â–ˆâ–ˆâ–‹       | 132M/481M [00:04<00:10, 32.1MB/s] 28%|â–ˆâ–ˆâ–Š       | 136M/481M [00:04<00:10, 32.6MB/s] 29%|â–ˆâ–ˆâ–‰       | 140M/481M [00:05<00:10, 31.3MB/s] 30%|â–ˆâ–ˆâ–‰       | 144M/481M [00:05<00:09, 34.2MB/s] 31%|â–ˆâ–ˆâ–ˆ       | 148M/481M [00:05<00:10, 33.3MB/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 151M/481M [00:05<00:10, 32.2MB/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 155M/481M [00:05<00:09, 34.9MB/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 159M/481M [00:05<00:09, 33.5MB/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 163M/481M [00:05<00:09, 32.3MB/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 167M/481M [00:05<00:08, 35.1MB/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 170M/481M [00:06<00:09, 33.6MB/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 174M/481M [00:06<00:09, 33.4MB/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 178M/481M [00:06<00:08, 35.1MB/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 182M/481M [00:06<00:08, 33.6MB/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 186M/481M [00:06<00:08, 33.3MB/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 190M/481M [00:06<00:08, 36.2MB/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 194M/481M [00:06<00:08, 34.3MB/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 198M/481M [00:06<00:08, 34.3MB/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 201M/481M [00:06<00:08, 34.3MB/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 205M/481M [00:07<00:07, 35.5MB/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 209M/481M [00:07<00:08, 33.7MB/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 212M/481M [00:07<00:07, 34.1MB/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 216M/481M [00:07<00:07, 35.1MB/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 220M/481M [00:07<00:07, 35.2MB/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 223M/481M [00:07<00:07, 33.6MB/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 227M/481M [00:07<00:07, 34.6MB/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 231M/481M [00:07<00:07, 35.3MB/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 234M/481M [00:07<00:06, 35.5MB/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 238M/481M [00:07<00:07, 33.9MB/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 242M/481M [00:08<00:06, 34.5MB/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 246M/481M [00:08<00:06, 35.3MB/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249M/481M [00:08<00:06, 35.7MB/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 253M/481M [00:08<00:06, 34.4MB/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256M/481M [00:08<00:06, 33.7MB/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 260M/481M [00:08<00:06, 34.1MB/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 264M/481M [00:08<00:06, 35.5MB/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 267M/481M [00:08<00:05, 36.0MB/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 271M/481M [00:08<00:05, 36.0MB/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 275M/481M [00:09<00:05, 35.2MB/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 278M/481M [00:09<00:05, 34.5MB/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 282M/481M [00:09<00:05, 34.6MB/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 285M/481M [00:09<00:05, 34.8MB/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 289M/481M [00:09<00:05, 34.5MB/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 293M/481M [00:09<00:05, 34.3MB/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 297M/481M [00:09<00:05, 36.1MB/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 300M/481M [00:09<00:05, 35.4MB/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304M/481M [00:09<00:05, 34.6MB/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 307M/481M [00:09<00:05, 34.0MB/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 311M/481M [00:10<00:04, 34.8MB/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 315M/481M [00:10<00:04, 36.0MB/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 319M/481M [00:10<00:04, 35.8MB/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 322M/481M [00:10<00:04, 35.3MB/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 326M/481M [00:10<00:04, 34.8MB/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 329M/481M [00:10<00:04, 35.1MB/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 333M/481M [00:10<00:04, 33.8MB/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 336M/481M [00:10<00:04, 34.0MB/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 340M/481M [00:10<00:04, 33.8MB/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 344M/481M [00:10<00:03, 35.6MB/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 348M/481M [00:11<00:03, 34.6MB/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 351M/481M [00:11<00:03, 34.7MB/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 355M/481M [00:11<00:03, 33.7MB/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 359M/481M [00:11<00:03, 35.5MB/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 363M/481M [00:11<00:03, 36.0MB/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 366M/481M [00:11<00:03, 34.5MB/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 370M/481M [00:11<00:03, 34.1MB/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 373M/481M [00:11<00:03, 34.7MB/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 377M/481M [00:11<00:03, 34.7MB/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 380M/481M [00:12<00:02, 34.3MB/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 384M/481M [00:12<00:02, 35.6MB/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 388M/481M [00:12<00:02, 33.9MB/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 391M/481M [00:12<00:02, 34.4MB/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 395M/481M [00:12<00:02, 33.7MB/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399M/481M [00:12<00:02, 35.9MB/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 403M/481M [00:12<00:02, 34.3MB/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 406M/481M [00:12<00:02, 32.2MB/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 411M/481M [00:12<00:01, 36.1MB/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 414M/481M [00:13<00:01, 34.7MB/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 418M/481M [00:13<00:01, 33.3MB/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 422M/481M [00:13<00:01, 35.0MB/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 425M/481M [00:13<00:01, 34.0MB/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 429M/481M [00:13<00:01, 35.4MB/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 433M/481M [00:13<00:01, 34.1MB/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 437M/481M [00:13<00:01, 33.9MB/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 441M/481M [00:13<00:01, 35.7MB/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 445M/481M [00:13<00:01, 34.4MB/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 449M/481M [00:14<00:00, 35.6MB/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452M/481M [00:14<00:00, 34.8MB/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 456M/481M [00:14<00:00, 35.2MB/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 460M/481M [00:14<00:00, 34.0MB/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464M/481M [00:14<00:00, 35.7MB/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 467M/481M [00:14<00:00, 34.9MB/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 471M/481M [00:14<00:00, 34.6MB/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 474M/481M [00:14<00:00, 33.3MB/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 479M/481M [00:14<00:00, 35.2MB/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 481M/481M [00:14<00:00, 32.2MB/s]
textattack: Unzipping file /root/.cache/textattack/tmp3ouqte7i.zip to /root/.cache/textattack/word_embeddings/paragramcf.
textattack: Successfully saved word_embeddings/paragramcf to cache.
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]Downloading builder script: 4.21kB [00:00, 12.3MB/s]                   2024-01-26 12:55:41.877098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:55:41.888707: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:55:41.891151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:55:41.913486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:55:41.915876: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:55:41.918244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:55:42.126003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:55:42.127709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:55:42.129176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:55:42.130677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0

Downloading readme:   0%|          | 0.00/31.9k [00:00<?, ?B/s]Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31.9k/31.9k [00:00<00:00, 73.8MB/s]
Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]
Downloading data:   0%|          | 0.00/3.11M [00:00<?, ?B/s][A
Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.11M/3.11M [00:00<00:00, 11.0MB/s][ADownloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.11M/3.11M [00:00<00:00, 11.0MB/s]
Downloading data files:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.50it/s]
Downloading data:   0%|          | 0.00/72.8k [00:00<?, ?B/s][A
Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.8k/72.8k [00:00<00:00, 283kB/s][ADownloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.8k/72.8k [00:00<00:00, 283kB/s]
Downloading data files:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.70it/s]
Downloading data:   0%|          | 0.00/148k [00:00<?, ?B/s][A
Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 148k/148k [00:00<00:00, 1.12MB/s][ADownloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 148k/148k [00:00<00:00, 1.12MB/s]
Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.80it/s]Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.41it/s]
Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 2345.37it/s]
Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67349/67349 [00:00<00:00, 2156072.72 examples/s]
Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]Generating validation split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 872/872 [00:00<00:00, 548669.83 examples/s]
Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [00:00<00:00, 724376.67 examples/s]
Map:   0%|          | 0/67349 [00:00<?, ? examples/s]Map:   3%|â–Ž         | 1914/67349 [00:00<00:03, 18985.21 examples/s]Map:   6%|â–Œ         | 3903/67349 [00:00<00:03, 19507.03 examples/s]Map:   9%|â–‰         | 5895/67349 [00:00<00:03, 19688.80 examples/s]Map:  12%|â–ˆâ–        | 7876/67349 [00:00<00:03, 19734.47 examples/s]Map:  15%|â–ˆâ–        | 9883/67349 [00:00<00:02, 19853.10 examples/s]Map:  18%|â–ˆâ–Š        | 11908/67349 [00:00<00:02, 19986.19 examples/s]Map:  21%|â–ˆâ–ˆ        | 13963/67349 [00:00<00:02, 20168.09 examples/s]Map:  24%|â–ˆâ–ˆâ–       | 15996/67349 [00:00<00:02, 20219.05 examples/s]Map:  27%|â–ˆâ–ˆâ–‹       | 18021/67349 [00:00<00:02, 20137.56 examples/s]Map:  30%|â–ˆâ–ˆâ–‰       | 20053/67349 [00:01<00:02, 20191.69 examples/s]Map:  34%|â–ˆâ–ˆâ–ˆâ–      | 23083/67349 [00:01<00:02, 20189.43 examples/s]Map:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25112/67349 [00:01<00:02, 20214.54 examples/s]Map:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27143/67349 [00:01<00:01, 20237.05 examples/s]Map:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29189/67349 [00:01<00:01, 20298.29 examples/s]Map:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31233/67349 [00:01<00:01, 20337.82 examples/s]Map:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33290/67349 [00:01<00:01, 20403.33 examples/s]Map:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35339/67349 [00:01<00:01, 20424.82 examples/s]Map:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 38397/67349 [00:01<00:01, 20407.21 examples/s]Map:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 41427/67349 [00:02<00:01, 20330.49 examples/s]Map:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43466/67349 [00:02<00:01, 20345.15 examples/s]Map:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 46483/67349 [00:02<00:01, 20258.49 examples/s]Map:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49523/67349 [00:02<00:00, 20258.95 examples/s]Map:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 51581/67349 [00:02<00:00, 20334.64 examples/s]Map:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53635/67349 [00:02<00:00, 20384.89 examples/s]Map:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 55681/67349 [00:02<00:00, 20402.18 examples/s]Map:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57759/67349 [00:02<00:00, 20504.27 examples/s]Map:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 60820/67349 [00:03<00:00, 20463.18 examples/s]Map:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63819/67349 [00:03<00:00, 20297.85 examples/s]Map:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 66857/67349 [00:03<00:00, 20279.89 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67349/67349 [00:03<00:00, 20211.77 examples/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 872/872 [00:00<00:00, 18824.41 examples/s]
Map:   0%|          | 0/1821 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1821/1821 [00:00<00:00, 19815.20 examples/s]
Filter:   0%|          | 0/63981 [00:00<?, ? examples/s]Filter:  19%|â–ˆâ–‰        | 12000/63981 [00:00<00:00, 109460.89 examples/s]Filter:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 24000/63981 [00:00<00:00, 111895.97 examples/s]Filter:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36000/63981 [00:00<00:00, 113178.81 examples/s]Filter:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48000/63981 [00:00<00:00, 113927.96 examples/s]Filter:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 60000/63981 [00:00<00:00, 114157.92 examples/s]Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63981/63981 [00:00<00:00, 113224.55 examples/s]
Filter:   0%|          | 0/3368 [00:00<?, ? examples/s]Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3368/3368 [00:00<00:00, 108447.84 examples/s]
Filter:   0%|          | 0/872 [00:00<?, ? examples/s]Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 872/872 [00:00<00:00, 178935.08 examples/s]
Downloading tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]Downloading tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 776/776 [00:00<00:00, 121kB/s]
Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]Downloading tokenizer.model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500k/500k [00:00<00:00, 95.2MB/s]
Downloading tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]Downloading tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.84M/1.84M [00:00<00:00, 23.8MB/s]
Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]Downloading (â€¦)cial_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 414/414 [00:00<00:00, 417kB/s]
Downloading config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]Downloading config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 609/609 [00:00<00:00, 111kB/s]
Downloading (â€¦)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]Downloading (â€¦)fetensors.index.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.8k/26.8k [00:00<00:00, 12.0MB/s]
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]
Downloading (â€¦)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s][A
Downloading (â€¦)of-00002.safetensors:   0%|          | 31.5M/9.98G [00:00<00:41, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:   1%|          | 62.9M/9.98G [00:00<00:40, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:   1%|          | 94.4M/9.98G [00:00<00:39, 250MB/s][A
Downloading (â€¦)of-00002.safetensors:   1%|â–         | 126M/9.98G [00:00<00:39, 252MB/s] [A
Downloading (â€¦)of-00002.safetensors:   2%|â–         | 157M/9.98G [00:00<00:38, 252MB/s][A
Downloading (â€¦)of-00002.safetensors:   2%|â–         | 189M/9.98G [00:00<00:39, 249MB/s][A
Downloading (â€¦)of-00002.safetensors:   2%|â–         | 220M/9.98G [00:00<00:39, 249MB/s][A
Downloading (â€¦)of-00002.safetensors:   3%|â–Ž         | 252M/9.98G [00:01<00:38, 252MB/s][A
Downloading (â€¦)of-00002.safetensors:   3%|â–Ž         | 283M/9.98G [00:01<00:38, 252MB/s][A
Downloading (â€¦)of-00002.safetensors:   3%|â–Ž         | 315M/9.98G [00:01<00:37, 255MB/s][A
Downloading (â€¦)of-00002.safetensors:   3%|â–Ž         | 346M/9.98G [00:01<00:37, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:   4%|â–         | 377M/9.98G [00:01<00:37, 257MB/s][A
Downloading (â€¦)of-00002.safetensors:   4%|â–         | 409M/9.98G [00:01<00:37, 256MB/s][A
Downloading (â€¦)of-00002.safetensors:   4%|â–         | 440M/9.98G [00:01<00:37, 257MB/s][A
Downloading (â€¦)of-00002.safetensors:   5%|â–         | 472M/9.98G [00:01<00:37, 255MB/s][A
Downloading (â€¦)of-00002.safetensors:   5%|â–Œ         | 503M/9.98G [00:01<00:37, 255MB/s][A
Downloading (â€¦)of-00002.safetensors:   5%|â–Œ         | 535M/9.98G [00:02<00:37, 250MB/s][A
Downloading (â€¦)of-00002.safetensors:   6%|â–Œ         | 566M/9.98G [00:02<00:38, 248MB/s][A
Downloading (â€¦)of-00002.safetensors:   6%|â–Œ         | 598M/9.98G [00:02<00:37, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:   6%|â–‹         | 629M/9.98G [00:02<00:38, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:   7%|â–‹         | 661M/9.98G [00:02<00:37, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:   7%|â–‹         | 692M/9.98G [00:02<00:37, 249MB/s][A
Downloading (â€¦)of-00002.safetensors:   7%|â–‹         | 724M/9.98G [00:02<00:37, 250MB/s][A
Downloading (â€¦)of-00002.safetensors:   8%|â–Š         | 755M/9.98G [00:03<00:37, 249MB/s][A
Downloading (â€¦)of-00002.safetensors:   8%|â–Š         | 786M/9.98G [00:03<00:36, 250MB/s][A
Downloading (â€¦)of-00002.safetensors:   8%|â–Š         | 818M/9.98G [00:03<00:36, 251MB/s][A
Downloading (â€¦)of-00002.safetensors:   9%|â–Š         | 849M/9.98G [00:03<00:55, 165MB/s][A
Downloading (â€¦)of-00002.safetensors:   9%|â–‰         | 881M/9.98G [00:03<00:49, 185MB/s][A
Downloading (â€¦)of-00002.safetensors:   9%|â–‰         | 912M/9.98G [00:03<00:44, 204MB/s][A
Downloading (â€¦)of-00002.safetensors:   9%|â–‰         | 944M/9.98G [00:03<00:41, 218MB/s][A
Downloading (â€¦)of-00002.safetensors:  10%|â–‰         | 975M/9.98G [00:04<00:39, 229MB/s][A
Downloading (â€¦)of-00002.safetensors:  10%|â–ˆ         | 1.01G/9.98G [00:04<00:37, 237MB/s][A
Downloading (â€¦)of-00002.safetensors:  10%|â–ˆ         | 1.04G/9.98G [00:04<00:36, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  11%|â–ˆ         | 1.07G/9.98G [00:04<00:35, 249MB/s][A
Downloading (â€¦)of-00002.safetensors:  11%|â–ˆ         | 1.10G/9.98G [00:04<00:35, 253MB/s][A
Downloading (â€¦)of-00002.safetensors:  11%|â–ˆâ–        | 1.13G/9.98G [00:04<00:34, 255MB/s][A
Downloading (â€¦)of-00002.safetensors:  12%|â–ˆâ–        | 1.16G/9.98G [00:04<00:34, 257MB/s][A
Downloading (â€¦)of-00002.safetensors:  12%|â–ˆâ–        | 1.20G/9.98G [00:04<00:33, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  12%|â–ˆâ–        | 1.23G/9.98G [00:05<00:33, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:  13%|â–ˆâ–Ž        | 1.26G/9.98G [00:05<00:34, 256MB/s][A
Downloading (â€¦)of-00002.safetensors:  13%|â–ˆâ–Ž        | 1.29G/9.98G [00:05<00:33, 257MB/s][A
Downloading (â€¦)of-00002.safetensors:  13%|â–ˆâ–Ž        | 1.32G/9.98G [00:05<00:33, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  14%|â–ˆâ–Ž        | 1.35G/9.98G [00:05<00:33, 261MB/s][A
Downloading (â€¦)of-00002.safetensors:  14%|â–ˆâ–        | 1.38G/9.98G [00:05<00:33, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  14%|â–ˆâ–        | 1.42G/9.98G [00:05<00:33, 257MB/s][A
Downloading (â€¦)of-00002.safetensors:  15%|â–ˆâ–        | 1.45G/9.98G [00:05<00:32, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  15%|â–ˆâ–        | 1.48G/9.98G [00:06<00:32, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  15%|â–ˆâ–Œ        | 1.51G/9.98G [00:06<00:32, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  15%|â–ˆâ–Œ        | 1.54G/9.98G [00:06<00:32, 257MB/s][A
Downloading (â€¦)of-00002.safetensors:  16%|â–ˆâ–Œ        | 1.57G/9.98G [00:06<00:32, 255MB/s][A
Downloading (â€¦)of-00002.safetensors:  16%|â–ˆâ–Œ        | 1.60G/9.98G [00:06<00:32, 256MB/s][A
Downloading (â€¦)of-00002.safetensors:  16%|â–ˆâ–‹        | 1.64G/9.98G [00:06<00:32, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:  17%|â–ˆâ–‹        | 1.67G/9.98G [00:06<00:32, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:  17%|â–ˆâ–‹        | 1.70G/9.98G [00:06<00:32, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  17%|â–ˆâ–‹        | 1.73G/9.98G [00:06<00:31, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  18%|â–ˆâ–Š        | 1.76G/9.98G [00:07<00:31, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  18%|â–ˆâ–Š        | 1.79G/9.98G [00:07<00:31, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  18%|â–ˆâ–Š        | 1.82G/9.98G [00:07<00:31, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  19%|â–ˆâ–Š        | 1.86G/9.98G [00:07<00:31, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  19%|â–ˆâ–‰        | 1.89G/9.98G [00:07<00:31, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  19%|â–ˆâ–‰        | 1.92G/9.98G [00:07<00:31, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  20%|â–ˆâ–‰        | 1.95G/9.98G [00:07<00:30, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  20%|â–ˆâ–‰        | 1.98G/9.98G [00:07<00:30, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  20%|â–ˆâ–ˆ        | 2.01G/9.98G [00:08<00:30, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:  20%|â–ˆâ–ˆ        | 2.04G/9.98G [00:08<00:30, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:  21%|â–ˆâ–ˆ        | 2.08G/9.98G [00:08<00:30, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  21%|â–ˆâ–ˆ        | 2.11G/9.98G [00:08<00:30, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  21%|â–ˆâ–ˆâ–       | 2.14G/9.98G [00:08<00:30, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  22%|â–ˆâ–ˆâ–       | 2.17G/9.98G [00:08<00:29, 261MB/s][A
Downloading (â€¦)of-00002.safetensors:  22%|â–ˆâ–ˆâ–       | 2.20G/9.98G [00:08<00:29, 261MB/s][A
Downloading (â€¦)of-00002.safetensors:  22%|â–ˆâ–ˆâ–       | 2.23G/9.98G [00:08<00:29, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  23%|â–ˆâ–ˆâ–Ž       | 2.26G/9.98G [00:09<00:29, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  23%|â–ˆâ–ˆâ–Ž       | 2.30G/9.98G [00:09<00:29, 261MB/s][A
Downloading (â€¦)of-00002.safetensors:  23%|â–ˆâ–ˆâ–Ž       | 2.33G/9.98G [00:09<00:29, 261MB/s][A
Downloading (â€¦)of-00002.safetensors:  24%|â–ˆâ–ˆâ–Ž       | 2.36G/9.98G [00:09<00:29, 262MB/s][A
Downloading (â€¦)of-00002.safetensors:  24%|â–ˆâ–ˆâ–       | 2.39G/9.98G [00:09<00:28, 262MB/s][A
Downloading (â€¦)of-00002.safetensors:  24%|â–ˆâ–ˆâ–       | 2.42G/9.98G [00:09<00:28, 262MB/s][A
Downloading (â€¦)of-00002.safetensors:  25%|â–ˆâ–ˆâ–       | 2.45G/9.98G [00:09<00:28, 262MB/s][A
Downloading (â€¦)of-00002.safetensors:  25%|â–ˆâ–ˆâ–       | 2.49G/9.98G [00:09<00:28, 262MB/s][A
Downloading (â€¦)of-00002.safetensors:  25%|â–ˆâ–ˆâ–Œ       | 2.52G/9.98G [00:10<00:28, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  26%|â–ˆâ–ˆâ–Œ       | 2.55G/9.98G [00:10<00:28, 261MB/s][A
Downloading (â€¦)of-00002.safetensors:  26%|â–ˆâ–ˆâ–Œ       | 2.58G/9.98G [00:10<00:28, 261MB/s][A
Downloading (â€¦)of-00002.safetensors:  26%|â–ˆâ–ˆâ–Œ       | 2.61G/9.98G [00:10<00:28, 256MB/s][A
Downloading (â€¦)of-00002.safetensors:  26%|â–ˆâ–ˆâ–‹       | 2.64G/9.98G [00:10<00:28, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  27%|â–ˆâ–ˆâ–‹       | 2.67G/9.98G [00:10<00:29, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:  27%|â–ˆâ–ˆâ–‹       | 2.71G/9.98G [00:10<00:29, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  27%|â–ˆâ–ˆâ–‹       | 2.74G/9.98G [00:10<00:30, 234MB/s][A
Downloading (â€¦)of-00002.safetensors:  28%|â–ˆâ–ˆâ–Š       | 2.77G/9.98G [00:11<00:31, 228MB/s][A
Downloading (â€¦)of-00002.safetensors:  28%|â–ˆâ–ˆâ–Š       | 2.80G/9.98G [00:11<00:30, 233MB/s][A
Downloading (â€¦)of-00002.safetensors:  28%|â–ˆâ–ˆâ–Š       | 2.83G/9.98G [00:11<00:31, 226MB/s][A
Downloading (â€¦)of-00002.safetensors:  29%|â–ˆâ–ˆâ–Š       | 2.86G/9.98G [00:11<00:32, 222MB/s][A
Downloading (â€¦)of-00002.safetensors:  29%|â–ˆâ–ˆâ–‰       | 2.89G/9.98G [00:11<00:32, 219MB/s][A
Downloading (â€¦)of-00002.safetensors:  29%|â–ˆâ–ˆâ–‰       | 2.93G/9.98G [00:11<00:35, 199MB/s][A
Downloading (â€¦)of-00002.safetensors:  30%|â–ˆâ–ˆâ–‰       | 2.96G/9.98G [00:11<00:34, 204MB/s][A
Downloading (â€¦)of-00002.safetensors:  30%|â–ˆâ–ˆâ–‰       | 2.99G/9.98G [00:12<00:33, 208MB/s][A
Downloading (â€¦)of-00002.safetensors:  30%|â–ˆâ–ˆâ–ˆ       | 3.02G/9.98G [00:12<00:33, 208MB/s][A
Downloading (â€¦)of-00002.safetensors:  31%|â–ˆâ–ˆâ–ˆ       | 3.05G/9.98G [00:12<00:33, 210MB/s][A
Downloading (â€¦)of-00002.safetensors:  31%|â–ˆâ–ˆâ–ˆ       | 3.08G/9.98G [00:12<00:32, 210MB/s][A
Downloading (â€¦)of-00002.safetensors:  31%|â–ˆâ–ˆâ–ˆ       | 3.11G/9.98G [00:12<00:32, 212MB/s][A
Downloading (â€¦)of-00002.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–      | 3.15G/9.98G [00:12<00:32, 211MB/s][A
Downloading (â€¦)of-00002.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–      | 3.18G/9.98G [00:13<00:32, 212MB/s][A
Downloading (â€¦)of-00002.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–      | 3.21G/9.98G [00:13<00:31, 213MB/s][A
Downloading (â€¦)of-00002.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–      | 3.24G/9.98G [00:13<00:31, 213MB/s][A
Downloading (â€¦)of-00002.safetensors:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3.27G/9.98G [00:13<00:31, 212MB/s][A
Downloading (â€¦)of-00002.safetensors:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3.30G/9.98G [00:13<00:31, 213MB/s][A
Downloading (â€¦)of-00002.safetensors:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3.33G/9.98G [00:13<00:29, 222MB/s][A
Downloading (â€¦)of-00002.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 3.37G/9.98G [00:13<00:28, 228MB/s][A
Downloading (â€¦)of-00002.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–      | 3.40G/9.98G [00:13<00:28, 233MB/s][A
Downloading (â€¦)of-00002.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–      | 3.43G/9.98G [00:14<00:27, 237MB/s][A
Downloading (â€¦)of-00002.safetensors:  35%|â–ˆâ–ˆâ–ˆâ–      | 3.46G/9.98G [00:14<00:27, 239MB/s][A
Downloading (â€¦)of-00002.safetensors:  35%|â–ˆâ–ˆâ–ˆâ–      | 3.49G/9.98G [00:14<00:26, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 3.52G/9.98G [00:14<00:26, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 3.55G/9.98G [00:14<00:26, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 3.59G/9.98G [00:14<00:26, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 3.62G/9.98G [00:14<00:26, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3.65G/9.98G [00:15<00:25, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3.68G/9.98G [00:15<00:25, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 3.71G/9.98G [00:15<00:25, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3.74G/9.98G [00:15<00:25, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3.77G/9.98G [00:15<00:25, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3.81G/9.98G [00:15<00:25, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3.84G/9.98G [00:15<00:26, 234MB/s][A
Downloading (â€¦)of-00002.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3.87G/9.98G [00:15<00:26, 234MB/s][A
Downloading (â€¦)of-00002.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3.90G/9.98G [00:16<00:25, 235MB/s][A
Downloading (â€¦)of-00002.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 3.93G/9.98G [00:16<00:25, 236MB/s][A
Downloading (â€¦)of-00002.safetensors:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 3.96G/9.98G [00:16<00:25, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4.00G/9.98G [00:16<00:24, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4.03G/9.98G [00:16<00:24, 246MB/s][A
Downloading (â€¦)of-00002.safetensors:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4.06G/9.98G [00:16<00:23, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4.09G/9.98G [00:16<00:23, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4.12G/9.98G [00:16<00:23, 249MB/s][A
Downloading (â€¦)of-00002.safetensors:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4.15G/9.98G [00:17<00:23, 249MB/s][A
Downloading (â€¦)of-00002.safetensors:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4.18G/9.98G [00:17<00:23, 251MB/s][A
Downloading (â€¦)of-00002.safetensors:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4.22G/9.98G [00:17<00:22, 251MB/s][A
Downloading (â€¦)of-00002.safetensors:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 4.25G/9.98G [00:17<00:22, 250MB/s][A
Downloading (â€¦)of-00002.safetensors:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 4.28G/9.98G [00:17<00:22, 251MB/s][A
Downloading (â€¦)of-00002.safetensors:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 4.31G/9.98G [00:17<00:23, 246MB/s][A
Downloading (â€¦)of-00002.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 4.34G/9.98G [00:17<00:23, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4.37G/9.98G [00:17<00:22, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4.40G/9.98G [00:18<00:22, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4.44G/9.98G [00:18<00:22, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4.47G/9.98G [00:18<00:22, 246MB/s][A
Downloading (â€¦)of-00002.safetensors:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4.50G/9.98G [00:18<00:23, 237MB/s][A
Downloading (â€¦)of-00002.safetensors:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4.53G/9.98G [00:18<00:22, 237MB/s][A
Downloading (â€¦)of-00002.safetensors:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4.56G/9.98G [00:18<00:22, 239MB/s][A
Downloading (â€¦)of-00002.safetensors:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4.59G/9.98G [00:18<00:22, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4.62G/9.98G [00:19<00:22, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4.66G/9.98G [00:19<00:21, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4.69G/9.98G [00:19<00:21, 246MB/s][A
Downloading (â€¦)of-00002.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 4.72G/9.98G [00:19<00:21, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 4.75G/9.98G [00:19<00:21, 248MB/s][A
Downloading (â€¦)of-00002.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 4.78G/9.98G [00:19<00:20, 249MB/s][A
Downloading (â€¦)of-00002.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 4.81G/9.98G [00:19<00:20, 251MB/s][A
Downloading (â€¦)of-00002.safetensors:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 4.84G/9.98G [00:19<00:20, 249MB/s][A
Downloading (â€¦)of-00002.safetensors:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4.88G/9.98G [00:20<00:20, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4.91G/9.98G [00:20<00:21, 239MB/s][A
Downloading (â€¦)of-00002.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4.94G/9.98G [00:20<00:21, 233MB/s][A
Downloading (â€¦)of-00002.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 4.97G/9.98G [00:20<00:22, 227MB/s][A
Downloading (â€¦)of-00002.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5.00G/9.98G [00:20<00:21, 230MB/s][A
Downloading (â€¦)of-00002.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5.03G/9.98G [00:20<00:21, 235MB/s][A
Downloading (â€¦)of-00002.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5.06G/9.98G [00:20<00:20, 239MB/s][A
Downloading (â€¦)of-00002.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5.10G/9.98G [00:20<00:20, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5.13G/9.98G [00:21<00:20, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5.16G/9.98G [00:21<00:19, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5.19G/9.98G [00:21<00:19, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5.22G/9.98G [00:21<00:19, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 5.25G/9.98G [00:21<00:19, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 5.28G/9.98G [00:21<00:29, 161MB/s][A
Downloading (â€¦)of-00002.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 5.32G/9.98G [00:22<00:26, 178MB/s][A
Downloading (â€¦)of-00002.safetensors:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 5.35G/9.98G [00:22<00:23, 194MB/s][A
Downloading (â€¦)of-00002.safetensors:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5.38G/9.98G [00:22<00:22, 207MB/s][A
Downloading (â€¦)of-00002.safetensors:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5.41G/9.98G [00:22<00:21, 217MB/s][A
Downloading (â€¦)of-00002.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5.44G/9.98G [00:22<00:20, 225MB/s][A
Downloading (â€¦)of-00002.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 5.47G/9.98G [00:22<00:19, 229MB/s][A
Downloading (â€¦)of-00002.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5.51G/9.98G [00:22<00:19, 233MB/s][A
Downloading (â€¦)of-00002.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5.54G/9.98G [00:23<00:18, 237MB/s][A
Downloading (â€¦)of-00002.safetensors:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5.57G/9.98G [00:23<00:18, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5.60G/9.98G [00:23<00:18, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5.63G/9.98G [00:23<00:17, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5.66G/9.98G [00:23<00:17, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5.69G/9.98G [00:23<00:17, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 5.73G/9.98G [00:23<00:17, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5.76G/9.98G [00:23<00:17, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5.79G/9.98G [00:24<00:17, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5.82G/9.98G [00:24<00:17, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 5.85G/9.98G [00:24<00:16, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5.88G/9.98G [00:24<00:16, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5.91G/9.98G [00:24<00:16, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5.95G/9.98G [00:24<00:16, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 5.98G/9.98G [00:24<00:16, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6.01G/9.98G [00:24<00:16, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6.04G/9.98G [00:25<00:16, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6.07G/9.98G [00:25<00:15, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6.10G/9.98G [00:25<00:15, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6.13G/9.98G [00:25<00:15, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6.17G/9.98G [00:25<00:15, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6.20G/9.98G [00:25<00:15, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6.23G/9.98G [00:25<00:15, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 6.26G/9.98G [00:25<00:15, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 6.29G/9.98G [00:26<00:15, 237MB/s][A
Downloading (â€¦)of-00002.safetensors:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 6.32G/9.98G [00:26<00:15, 235MB/s][A
Downloading (â€¦)of-00002.safetensors:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 6.35G/9.98G [00:26<00:15, 237MB/s][A
Downloading (â€¦)of-00002.safetensors:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6.39G/9.98G [00:26<00:15, 237MB/s][A
Downloading (â€¦)of-00002.safetensors:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6.42G/9.98G [00:26<00:14, 239MB/s][A
Downloading (â€¦)of-00002.safetensors:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6.45G/9.98G [00:26<00:14, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 6.48G/9.98G [00:26<00:14, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6.51G/9.98G [00:27<00:14, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6.54G/9.98G [00:27<00:14, 238MB/s][A
Downloading (â€¦)of-00002.safetensors:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6.57G/9.98G [00:27<00:14, 238MB/s][A
Downloading (â€¦)of-00002.safetensors:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 6.61G/9.98G [00:27<00:14, 239MB/s][A
Downloading (â€¦)of-00002.safetensors:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6.64G/9.98G [00:27<00:13, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6.67G/9.98G [00:27<00:13, 239MB/s][A
Downloading (â€¦)of-00002.safetensors:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6.70G/9.98G [00:27<00:13, 238MB/s][A
Downloading (â€¦)of-00002.safetensors:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6.73G/9.98G [00:27<00:13, 239MB/s][A
Downloading (â€¦)of-00002.safetensors:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 6.76G/9.98G [00:28<00:13, 238MB/s][A
Downloading (â€¦)of-00002.safetensors:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 6.79G/9.98G [00:28<00:13, 237MB/s][A
Downloading (â€¦)of-00002.safetensors:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 6.83G/9.98G [00:28<00:13, 235MB/s][A
Downloading (â€¦)of-00002.safetensors:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 6.86G/9.98G [00:28<00:13, 236MB/s][A
Downloading (â€¦)of-00002.safetensors:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6.89G/9.98G [00:28<00:12, 239MB/s][A
Downloading (â€¦)of-00002.safetensors:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6.92G/9.98G [00:28<00:12, 237MB/s][A
Downloading (â€¦)of-00002.safetensors:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6.95G/9.98G [00:28<00:12, 238MB/s][A
Downloading (â€¦)of-00002.safetensors:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 6.98G/9.98G [00:29<00:12, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7.01G/9.98G [00:29<00:12, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7.05G/9.98G [00:29<00:11, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7.08G/9.98G [00:29<00:11, 246MB/s][A
Downloading (â€¦)of-00002.safetensors:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7.11G/9.98G [00:29<00:11, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7.14G/9.98G [00:29<00:11, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7.17G/9.98G [00:29<00:11, 246MB/s][A
Downloading (â€¦)of-00002.safetensors:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7.20G/9.98G [00:29<00:11, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 7.24G/9.98G [00:30<00:11, 248MB/s][A
Downloading (â€¦)of-00002.safetensors:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 7.27G/9.98G [00:30<00:11, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 7.30G/9.98G [00:30<00:10, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 7.33G/9.98G [00:30<00:10, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7.36G/9.98G [00:30<00:10, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7.39G/9.98G [00:30<00:10, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7.42G/9.98G [00:30<00:10, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 7.46G/9.98G [00:30<00:10, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 7.49G/9.98G [00:31<00:10, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 7.52G/9.98G [00:31<00:10, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 7.55G/9.98G [00:31<00:10, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 7.58G/9.98G [00:31<00:09, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7.61G/9.98G [00:31<00:09, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7.64G/9.98G [00:31<00:09, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7.68G/9.98G [00:31<00:09, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 7.71G/9.98G [00:32<00:14, 161MB/s][A
Downloading (â€¦)of-00002.safetensors:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7.74G/9.98G [00:32<00:12, 180MB/s][A
Downloading (â€¦)of-00002.safetensors:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7.77G/9.98G [00:32<00:11, 194MB/s][A
Downloading (â€¦)of-00002.safetensors:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7.80G/9.98G [00:32<00:10, 208MB/s][A
Downloading (â€¦)of-00002.safetensors:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7.83G/9.98G [00:32<00:09, 219MB/s][A
Downloading (â€¦)of-00002.safetensors:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7.86G/9.98G [00:32<00:09, 225MB/s][A
Downloading (â€¦)of-00002.safetensors:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7.90G/9.98G [00:32<00:08, 234MB/s][A
Downloading (â€¦)of-00002.safetensors:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7.93G/9.98G [00:33<00:08, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7.96G/9.98G [00:33<00:08, 246MB/s][A
Downloading (â€¦)of-00002.safetensors:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 7.99G/9.98G [00:33<00:08, 248MB/s][A
Downloading (â€¦)of-00002.safetensors:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8.02G/9.98G [00:33<00:07, 251MB/s][A
Downloading (â€¦)of-00002.safetensors:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8.05G/9.98G [00:33<00:07, 253MB/s][A
Downloading (â€¦)of-00002.safetensors:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8.08G/9.98G [00:33<00:07, 254MB/s][A
Downloading (â€¦)of-00002.safetensors:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8.12G/9.98G [00:33<00:07, 254MB/s][A
Downloading (â€¦)of-00002.safetensors:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8.15G/9.98G [00:33<00:07, 230MB/s][A
Downloading (â€¦)of-00002.safetensors:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8.18G/9.98G [00:34<00:07, 231MB/s][A
Downloading (â€¦)of-00002.safetensors:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8.21G/9.98G [00:34<00:07, 237MB/s][A
Downloading (â€¦)of-00002.safetensors:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8.24G/9.98G [00:34<00:07, 236MB/s][A
Downloading (â€¦)of-00002.safetensors:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8.27G/9.98G [00:34<00:07, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8.30G/9.98G [00:34<00:06, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 8.34G/9.98G [00:34<00:06, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8.37G/9.98G [00:34<00:06, 248MB/s][A
Downloading (â€¦)of-00002.safetensors:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8.40G/9.98G [00:35<00:06, 250MB/s][A
Downloading (â€¦)of-00002.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8.43G/9.98G [00:35<00:06, 251MB/s][A
Downloading (â€¦)of-00002.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 8.46G/9.98G [00:35<00:06, 251MB/s][A
Downloading (â€¦)of-00002.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 8.49G/9.98G [00:35<00:05, 249MB/s][A
Downloading (â€¦)of-00002.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 8.52G/9.98G [00:35<00:05, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 8.56G/9.98G [00:35<00:05, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 8.59G/9.98G [00:35<00:05, 248MB/s][A
Downloading (â€¦)of-00002.safetensors:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 8.62G/9.98G [00:35<00:05, 248MB/s][A
Downloading (â€¦)of-00002.safetensors:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 8.65G/9.98G [00:36<00:05, 246MB/s][A
Downloading (â€¦)of-00002.safetensors:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 8.68G/9.98G [00:36<00:05, 248MB/s][A
Downloading (â€¦)of-00002.safetensors:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 8.71G/9.98G [00:36<00:05, 248MB/s][A
Downloading (â€¦)of-00002.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 8.75G/9.98G [00:36<00:04, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 8.78G/9.98G [00:36<00:04, 246MB/s][A
Downloading (â€¦)of-00002.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 8.81G/9.98G [00:36<00:04, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 8.84G/9.98G [00:36<00:04, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8.87G/9.98G [00:36<00:04, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8.90G/9.98G [00:37<00:04, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8.93G/9.98G [00:37<00:04, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8.97G/9.98G [00:37<00:04, 246MB/s][A
Downloading (â€¦)of-00002.safetensors:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9.00G/9.98G [00:37<00:03, 248MB/s][A
Downloading (â€¦)of-00002.safetensors:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9.03G/9.98G [00:37<00:03, 248MB/s][A
Downloading (â€¦)of-00002.safetensors:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9.06G/9.98G [00:37<00:03, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9.09G/9.98G [00:37<00:03, 248MB/s][A
Downloading (â€¦)of-00002.safetensors:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9.12G/9.98G [00:37<00:03, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9.15G/9.98G [00:38<00:03, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9.19G/9.98G [00:38<00:03, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9.22G/9.98G [00:38<00:03, 247MB/s][A
Downloading (â€¦)of-00002.safetensors:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 9.25G/9.98G [00:38<00:02, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 9.28G/9.98G [00:38<00:02, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 9.31G/9.98G [00:38<00:02, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 9.34G/9.98G [00:38<00:02, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9.37G/9.98G [00:38<00:02, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9.41G/9.98G [00:39<00:02, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9.44G/9.98G [00:39<00:02, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 9.47G/9.98G [00:39<00:02, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9.50G/9.98G [00:39<00:01, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9.53G/9.98G [00:39<00:01, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9.56G/9.98G [00:39<00:01, 246MB/s][A
Downloading (â€¦)of-00002.safetensors:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 9.59G/9.98G [00:39<00:01, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 9.63G/9.98G [00:40<00:01, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 9.66G/9.98G [00:40<00:01, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 9.69G/9.98G [00:40<00:01, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 9.72G/9.98G [00:40<00:01, 238MB/s][A
Downloading (â€¦)of-00002.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 9.75G/9.98G [00:40<00:00, 238MB/s][A
Downloading (â€¦)of-00002.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 9.78G/9.98G [00:40<00:00, 238MB/s][A
Downloading (â€¦)of-00002.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 9.81G/9.98G [00:40<00:00, 239MB/s][A
Downloading (â€¦)of-00002.safetensors:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 9.85G/9.98G [00:40<00:00, 237MB/s][A
Downloading (â€¦)of-00002.safetensors:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 9.88G/9.98G [00:41<00:00, 238MB/s][A
Downloading (â€¦)of-00002.safetensors:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 9.91G/9.98G [00:41<00:00, 238MB/s][A
Downloading (â€¦)of-00002.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 9.94G/9.98G [00:41<00:00, 238MB/s][A
Downloading (â€¦)of-00002.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 9.97G/9.98G [00:41<00:00, 238MB/s][ADownloading (â€¦)of-00002.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.98G/9.98G [00:41<00:00, 240MB/s]
Downloading shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:41<00:41, 41.65s/it]
Downloading (â€¦)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s][A
Downloading (â€¦)of-00002.safetensors:   1%|          | 21.0M/3.50G [00:00<00:17, 198MB/s][A
Downloading (â€¦)of-00002.safetensors:   1%|â–         | 52.4M/3.50G [00:00<00:15, 228MB/s][A
Downloading (â€¦)of-00002.safetensors:   2%|â–         | 83.9M/3.50G [00:00<00:14, 236MB/s][A
Downloading (â€¦)of-00002.safetensors:   3%|â–Ž         | 115M/3.50G [00:00<00:23, 145MB/s] [A
Downloading (â€¦)of-00002.safetensors:   4%|â–         | 147M/3.50G [00:00<00:19, 170MB/s][A
Downloading (â€¦)of-00002.safetensors:   5%|â–Œ         | 178M/3.50G [00:00<00:17, 191MB/s][A
Downloading (â€¦)of-00002.safetensors:   6%|â–Œ         | 210M/3.50G [00:01<00:16, 206MB/s][A
Downloading (â€¦)of-00002.safetensors:   7%|â–‹         | 241M/3.50G [00:01<00:15, 215MB/s][A
Downloading (â€¦)of-00002.safetensors:   8%|â–Š         | 273M/3.50G [00:01<00:14, 221MB/s][A
Downloading (â€¦)of-00002.safetensors:   9%|â–Š         | 304M/3.50G [00:01<00:13, 229MB/s][A
Downloading (â€¦)of-00002.safetensors:  10%|â–‰         | 336M/3.50G [00:01<00:13, 233MB/s][A
Downloading (â€¦)of-00002.safetensors:  10%|â–ˆ         | 367M/3.50G [00:01<00:13, 236MB/s][A
Downloading (â€¦)of-00002.safetensors:  11%|â–ˆâ–        | 398M/3.50G [00:01<00:13, 234MB/s][A
Downloading (â€¦)of-00002.safetensors:  12%|â–ˆâ–        | 430M/3.50G [00:02<00:12, 236MB/s][A
Downloading (â€¦)of-00002.safetensors:  13%|â–ˆâ–Ž        | 461M/3.50G [00:02<00:12, 238MB/s][A
Downloading (â€¦)of-00002.safetensors:  14%|â–ˆâ–        | 493M/3.50G [00:02<00:12, 238MB/s][A
Downloading (â€¦)of-00002.safetensors:  15%|â–ˆâ–        | 524M/3.50G [00:02<00:12, 240MB/s][A
Downloading (â€¦)of-00002.safetensors:  16%|â–ˆâ–Œ        | 556M/3.50G [00:02<00:12, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  17%|â–ˆâ–‹        | 587M/3.50G [00:02<00:12, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  18%|â–ˆâ–Š        | 619M/3.50G [00:02<00:11, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  19%|â–ˆâ–Š        | 650M/3.50G [00:02<00:11, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  19%|â–ˆâ–‰        | 682M/3.50G [00:03<00:11, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  20%|â–ˆâ–ˆ        | 713M/3.50G [00:03<00:11, 244MB/s][A
Downloading (â€¦)of-00002.safetensors:  21%|â–ˆâ–ˆâ–       | 744M/3.50G [00:03<00:11, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  22%|â–ˆâ–ˆâ–       | 776M/3.50G [00:03<00:11, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  23%|â–ˆâ–ˆâ–Ž       | 807M/3.50G [00:03<00:11, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  24%|â–ˆâ–ˆâ–       | 839M/3.50G [00:03<00:10, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  25%|â–ˆâ–ˆâ–       | 870M/3.50G [00:03<00:10, 243MB/s][A
Downloading (â€¦)of-00002.safetensors:  26%|â–ˆâ–ˆâ–Œ       | 902M/3.50G [00:03<00:10, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  27%|â–ˆâ–ˆâ–‹       | 933M/3.50G [00:04<00:10, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  28%|â–ˆâ–ˆâ–Š       | 965M/3.50G [00:04<00:10, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  28%|â–ˆâ–ˆâ–Š       | 996M/3.50G [00:04<00:10, 242MB/s][A
Downloading (â€¦)of-00002.safetensors:  29%|â–ˆâ–ˆâ–‰       | 1.03G/3.50G [00:04<00:10, 245MB/s][A
Downloading (â€¦)of-00002.safetensors:  30%|â–ˆâ–ˆâ–ˆ       | 1.06G/3.50G [00:04<00:09, 249MB/s][A
Downloading (â€¦)of-00002.safetensors:  31%|â–ˆâ–ˆâ–ˆ       | 1.09G/3.50G [00:04<00:09, 253MB/s][A
Downloading (â€¦)of-00002.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–      | 1.12G/3.50G [00:04<00:09, 250MB/s][A
Downloading (â€¦)of-00002.safetensors:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1.15G/3.50G [00:04<00:09, 253MB/s][A
Downloading (â€¦)of-00002.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–      | 1.18G/3.50G [00:05<00:08, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:  35%|â–ˆâ–ˆâ–ˆâ–      | 1.22G/3.50G [00:05<00:08, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1.25G/3.50G [00:05<00:08, 261MB/s][A
Downloading (â€¦)of-00002.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.28G/3.50G [00:05<00:08, 251MB/s][A
Downloading (â€¦)of-00002.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1.31G/3.50G [00:05<00:08, 253MB/s][A
Downloading (â€¦)of-00002.safetensors:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1.34G/3.50G [00:05<00:08, 255MB/s][A
Downloading (â€¦)of-00002.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1.37G/3.50G [00:05<00:08, 256MB/s][A
Downloading (â€¦)of-00002.safetensors:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.41G/3.50G [00:05<00:08, 250MB/s][A
Downloading (â€¦)of-00002.safetensors:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1.44G/3.50G [00:06<00:08, 255MB/s][A
Downloading (â€¦)of-00002.safetensors:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.47G/3.50G [00:06<00:07, 255MB/s][A
Downloading (â€¦)of-00002.safetensors:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.50G/3.50G [00:06<00:07, 254MB/s][A
Downloading (â€¦)of-00002.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1.53G/3.50G [00:06<00:07, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.56G/3.50G [00:06<00:07, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1.59G/3.50G [00:06<00:07, 264MB/s][A
Downloading (â€¦)of-00002.safetensors:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.63G/3.50G [00:06<00:06, 270MB/s][A
Downloading (â€¦)of-00002.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1.66G/3.50G [00:06<00:06, 276MB/s][A
Downloading (â€¦)of-00002.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.69G/3.50G [00:06<00:06, 277MB/s][A
Downloading (â€¦)of-00002.safetensors:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1.72G/3.50G [00:07<00:06, 278MB/s][A
Downloading (â€¦)of-00002.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.75G/3.50G [00:07<00:06, 279MB/s][A
Downloading (â€¦)of-00002.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1.78G/3.50G [00:07<00:06, 276MB/s][A
Downloading (â€¦)of-00002.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.81G/3.50G [00:07<00:06, 270MB/s][A
Downloading (â€¦)of-00002.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.85G/3.50G [00:07<00:06, 266MB/s][A
Downloading (â€¦)of-00002.safetensors:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1.88G/3.50G [00:07<00:06, 262MB/s][A
Downloading (â€¦)of-00002.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.91G/3.50G [00:07<00:06, 261MB/s][A
Downloading (â€¦)of-00002.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1.94G/3.50G [00:07<00:05, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1.97G/3.50G [00:08<00:05, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2.00G/3.50G [00:08<00:05, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2.03G/3.50G [00:08<00:05, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.07G/3.50G [00:08<00:05, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2.10G/3.50G [00:08<00:05, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2.13G/3.50G [00:08<00:05, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.16G/3.50G [00:08<00:05, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.19G/3.50G [00:08<00:05, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2.22G/3.50G [00:09<00:04, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2.25G/3.50G [00:09<00:04, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.29G/3.50G [00:09<00:04, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2.32G/3.50G [00:09<00:04, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2.35G/3.50G [00:09<00:04, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2.38G/3.50G [00:09<00:04, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.41G/3.50G [00:09<00:04, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2.44G/3.50G [00:09<00:04, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2.47G/3.50G [00:10<00:03, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.51G/3.50G [00:10<00:03, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.54G/3.50G [00:10<00:03, 259MB/s][A
Downloading (â€¦)of-00002.safetensors:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2.57G/3.50G [00:10<00:03, 262MB/s][A
Downloading (â€¦)of-00002.safetensors:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2.60G/3.50G [00:10<00:03, 261MB/s][A
Downloading (â€¦)of-00002.safetensors:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.63G/3.50G [00:10<00:03, 260MB/s][A
Downloading (â€¦)of-00002.safetensors:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2.66G/3.50G [00:10<00:04, 169MB/s][A
Downloading (â€¦)of-00002.safetensors:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2.69G/3.50G [00:11<00:04, 192MB/s][A
Downloading (â€¦)of-00002.safetensors:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2.73G/3.50G [00:11<00:03, 213MB/s][A
Downloading (â€¦)of-00002.safetensors:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.76G/3.50G [00:11<00:03, 229MB/s][A
Downloading (â€¦)of-00002.safetensors:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2.79G/3.50G [00:11<00:02, 241MB/s][A
Downloading (â€¦)of-00002.safetensors:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2.82G/3.50G [00:11<00:02, 249MB/s][A
Downloading (â€¦)of-00002.safetensors:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.85G/3.50G [00:11<00:02, 254MB/s][A
Downloading (â€¦)of-00002.safetensors:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.88G/3.50G [00:11<00:02, 258MB/s][A
Downloading (â€¦)of-00002.safetensors:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2.92G/3.50G [00:11<00:02, 263MB/s][A
Downloading (â€¦)of-00002.safetensors:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2.95G/3.50G [00:11<00:02, 265MB/s][A
Downloading (â€¦)of-00002.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2.98G/3.50G [00:12<00:01, 263MB/s][A
Downloading (â€¦)of-00002.safetensors:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3.01G/3.50G [00:12<00:01, 264MB/s][A
Downloading (â€¦)of-00002.safetensors:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3.04G/3.50G [00:12<00:01, 265MB/s][A
Downloading (â€¦)of-00002.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.07G/3.50G [00:12<00:01, 267MB/s][A
Downloading (â€¦)of-00002.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3.10G/3.50G [00:12<00:01, 268MB/s][A
Downloading (â€¦)of-00002.safetensors:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3.14G/3.50G [00:12<00:01, 269MB/s][A
Downloading (â€¦)of-00002.safetensors:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3.17G/3.50G [00:12<00:01, 269MB/s][A
Downloading (â€¦)of-00002.safetensors:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.20G/3.50G [00:12<00:01, 270MB/s][A
Downloading (â€¦)of-00002.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.23G/3.50G [00:13<00:00, 271MB/s][A
Downloading (â€¦)of-00002.safetensors:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3.26G/3.50G [00:13<00:00, 271MB/s][A
Downloading (â€¦)of-00002.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.29G/3.50G [00:13<00:00, 271MB/s][A
Downloading (â€¦)of-00002.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3.32G/3.50G [00:13<00:00, 270MB/s][A
Downloading (â€¦)of-00002.safetensors:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3.36G/3.50G [00:13<00:00, 268MB/s][A
Downloading (â€¦)of-00002.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3.39G/3.50G [00:13<00:00, 267MB/s][A
Downloading (â€¦)of-00002.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.42G/3.50G [00:13<00:00, 264MB/s][A
Downloading (â€¦)of-00002.safetensors:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3.45G/3.50G [00:13<00:00, 263MB/s][A
Downloading (â€¦)of-00002.safetensors:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3.48G/3.50G [00:13<00:00, 262MB/s][ADownloading (â€¦)of-00002.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.50G/3.50G [00:14<00:00, 249MB/s]
Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:55<00:00, 25.50s/it]Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:55<00:00, 27.93s/it]
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:15<00:15, 15.66s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:21<00:00,  9.75s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:21<00:00, 10.64s/it]
Downloading generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]Downloading generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 188/188 [00:00<00:00, 28.0kB/s]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 872/872 [00:00<00:00, 8024.33 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 872/872 [00:00<00:00, 7829.20 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-1-shot-8/swap_labels_log.csv
  0%|          | 0/872 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
wandb: - 0.020 MB of 0.020 MB uploadedwandb: \ 0.020 MB of 0.020 MB uploadedwandb: | 0.020 MB of 0.020 MB uploadedwandb: / 0.026 MB of 0.035 MB uploaded (0.005 MB deduped)wandb: - 0.030 MB of 0.035 MB uploaded (0.005 MB deduped)Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 298, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 170, in _attack
    raise e
  File "/src/textattack/textattack/attacker.py", line 168, in _attack
    result = self.attack.attack(example, ground_truth_output)
  File "/src/textattack/textattack/attack.py", line 450, in attack
    result = self._attack(goal_function_result)
  File "/src/textattack/textattack/attack.py", line 398, in _attack
    final_result = self.search_method(initial_result)
  File "/src/textattack/textattack/search_methods/search_method.py", line 36, in __call__
    result = self.perform_search(initial_result)
  File "/src/textattack/textattack/search_methods/beam_search.py", line 40, in perform_search
    results, search_over = self.get_goal_results(potential_next_beam)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 96, in get_results
    model_outputs = self._call_model(attacked_text_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 219, in _call_model
    outputs = self._call_model_uncached(uncached_list)
  File "/src/textattack/textattack/goal_functions/goal_function.py", line 165, in _call_model_uncached
    batch_preds = self.model(batch)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 209, in forward
    input_ids, attention_mask, _  = self.get_updated_input_ids(input_ids, attention_mask, **kwargs)
  File "/mnt/data/mvp/src/models/model_wrapper.py", line 184, in get_updated_input_ids
    input_ids, attention_mask, input_indices = insert_icl_prompts(self, self.tokenizer, self.args.model_type, text_input_list, self.template, self.len_templates, use_all = (self.args.num_template != -2) or self.mode!="train", icl_examples = self.icl_examples)
  File "/mnt/data/mvp/src/utils/model_utils.py", line 294, in insert_icl_prompts
    example = format_template(e, template, model.args.dataset, verbalizer=model.verbalizer)
  File "/mnt/data/mvp/src/utils/dataset.py", line 213, in format_template
    label = example["label"]
KeyError: 'label'
2024-01-26 12:58:54.538020: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 12:58:55.434954: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 12:59:02.802259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:02.813884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:02.816288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:02.837701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:02.840085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:02.842407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:03.062125: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:03.063755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:03.065222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:03.066686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
13+8+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-13-shot-8
2024-01-26 12:59:08.121480: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 12:59:08.989653: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 12:59:16.453536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:16.465529: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:16.467992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:16.487922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:16.490348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:16.492700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:16.704531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:16.706225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:16.707690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:16.709173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
2024-01-26 12:59:21.738099: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 12:59:22.587057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 12:59:30.165584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:30.178393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:30.180844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:30.201519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:30.203942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:30.206304: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:30.417005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:30.418748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:30.420227: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:30.421708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
42+8+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-42-shot-8
2024-01-26 12:59:35.402990: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 12:59:36.246936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 12:59:43.615975: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:43.627837: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:43.630321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:43.650446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:43.652808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:43.655130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:43.866264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:43.869680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:43.871124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:43.872593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
2024-01-26 12:59:48.828316: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 12:59:49.702061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 12:59:57.089398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:57.101776: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:57.104190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:57.124145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:57.126521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:57.128863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:57.342241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:57.343862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:57.345317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 12:59:57.346788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
1+2+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-1-shot-2
2024-01-26 13:00:02.424024: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:00:03.296929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:00:10.703402: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:10.715259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:10.717717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:10.737023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:10.739385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:10.741703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:10.957045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:10.958761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:10.960227: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:10.961706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
2024-01-26 13:00:15.929536: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:00:16.807274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:00:24.255255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:24.267081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:24.269471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:24.290460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:24.292814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:24.295147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:24.516940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:24.518595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:24.520040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:24.521524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
13+2+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-13-shot-2
2024-01-26 13:00:29.326025: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:00:30.177462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:00:37.709440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:37.721150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:37.723589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:37.743868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:37.746252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:37.748675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:37.959687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:37.961334: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:37.962777: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:37.964247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
2024-01-26 13:00:43.030376: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:00:43.897554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:00:51.494372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:51.506139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:51.508544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:51.529202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:51.531574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:51.533910: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:51.743823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:51.745472: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:51.746918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:00:51.748411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
42+2+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-42-shot-2
2024-01-26 13:00:56.715431: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:00:57.578684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:01:05.060446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:05.072178: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:05.074581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:05.095696: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:05.098068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:05.100398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:05.310739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:05.312366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:05.313808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:05.315273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
2024-01-26 13:01:10.321877: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:01:11.197534: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:01:18.742394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:18.751386: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:18.753760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:18.768366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:18.770711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:18.773025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:18.994022: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:18.995649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:18.997107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:18.998578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1489, in dataset_module_factory
    return HubDatasetModuleFactoryWithoutScript(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1048, in get_module
    data_files = DataFilesDict.from_patterns(
  File "/usr/local/lib/python3.8/dist-packages/datasets/data_files.py", line 674, in from_patterns
    DataFilesList.from_patterns(
  File "/usr/local/lib/python3.8/dist-packages/datasets/data_files.py", line 589, in from_patterns
    origin_metadata = _get_origin_metadata(data_files, download_config=download_config)
  File "/usr/local/lib/python3.8/dist-packages/datasets/data_files.py", line 504, in _get_origin_metadata
    return thread_map(
  File "/usr/local/lib/python3.8/dist-packages/tqdm/contrib/concurrent.py", line 69, in thread_map
    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)
  File "/usr/local/lib/python3.8/dist-packages/tqdm/contrib/concurrent.py", line 51, in _executor_map
    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 619, in result_iterator
    yield fs.pop().result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 444, in result
    return self.__get_result()
  File "/usr/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/usr/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/lib/python3.8/dist-packages/datasets/data_files.py", line 484, in _get_single_origin_metadata
    resolved_path = fs.resolve_path(data_file)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_file_system.py", line 165, in resolve_path
    repo_and_revision_exist, err = self._repo_and_revision_exist(repo_type, repo_id, revision)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_file_system.py", line 100, in _repo_and_revision_exist
    self._api.repo_info(repo_id, revision=revision, repo_type=repo_type)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1888, in repo_info
    return method(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue/revision/a3f3ab759b9d7018046ce361f115ef38276d2e1e
1+4+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-1-shot-4
2024-01-26 13:01:25.640244: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:01:26.537478: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:01:34.023528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:34.035636: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:34.038132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:34.057922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:34.060326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:34.062666: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:34.273233: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:34.274907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:34.276394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:34.277907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
2024-01-26 13:01:39.227786: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:01:40.098974: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:01:47.560066: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:47.571550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:47.573936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:47.593886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:47.596312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:47.598637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:47.807868: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:47.809510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:47.810955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:01:47.812423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
13+4+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-13-shot-4
2024-01-26 13:01:52.930845: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:01:53.741236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:02:01.271631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:01.283468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:01.285884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:01.305170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:01.307538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:01.309872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:01.526916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:01.528574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:01.530029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:01.531517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
2024-01-26 13:02:06.630365: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:02:07.505449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:02:15.072332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:15.085084: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:15.087489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:15.106886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:15.109274: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:15.111597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:15.320605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:15.322367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:15.323814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:02:15.325280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:15<00:15, 15.81s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:20<00:00,  9.53s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:20<00:00, 10.47s/it]
Map:   0%|          | 0/872 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 872/872 [00:00<00:00, 9260.29 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-13-shot-4/swap_labels_log.csv
  0%|          | 0/872 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  0%|          | 1/872 [00:00<14:12,  1.02it/s][Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   0%|          | 1/872 [00:01<18:04,  1.24s/it][Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   0%|          | 2/872 [00:01<09:19,  1.55it/s][Succeeded / Failed / Skipped / Total] 0 / 1 / 1 / 2:   0%|          | 2/872 [00:01<09:28,  1.53it/s][Succeeded / Failed / Skipped / Total] 0 / 1 / 1 / 2:   0%|          | 3/872 [00:02<09:56,  1.46it/s][Succeeded / Failed / Skipped / Total] 0 / 2 / 1 / 3:   0%|          | 3/872 [00:02<10:03,  1.44it/s][Succeeded / Failed / Skipped / Total] 0 / 2 / 1 / 3:   0%|          | 4/872 [00:02<10:15,  1.41it/s][Succeeded / Failed / Skipped / Total] 0 / 3 / 1 / 4:   0%|          | 4/872 [00:02<10:20,  1.40it/s][Succeeded / Failed / Skipped / Total] 0 / 3 / 1 / 4:   1%|          | 5/872 [00:03<09:20,  1.55it/s][Succeeded / Failed / Skipped / Total] 1 / 3 / 1 / 5:   1%|          | 5/872 [00:03<09:24,  1.54it/s][Succeeded / Failed / Skipped / Total] 1 / 3 / 1 / 5:   1%|          | 6/872 [00:04<09:38,  1.50it/s][Succeeded / Failed / Skipped / Total] 1 / 4 / 1 / 6:   1%|          | 6/872 [00:04<09:42,  1.49it/s][Succeeded / Failed / Skipped / Total] 1 / 4 / 1 / 6:   1%|          | 7/872 [00:04<09:28,  1.52it/s][Succeeded / Failed / Skipped / Total] 2 / 4 / 1 / 7:   1%|          | 7/872 [00:04<09:31,  1.51it/s][Succeeded / Failed / Skipped / Total] 2 / 4 / 1 / 7:   1%|          | 8/872 [00:04<08:59,  1.60it/s][Succeeded / Failed / Skipped / Total] 3 / 4 / 1 / 8:   1%|          | 8/872 [00:05<09:02,  1.59it/s][Succeeded / Failed / Skipped / Total] 3 / 4 / 1 / 8:   1%|          | 9/872 [00:05<09:00,  1.60it/s][Succeeded / Failed / Skipped / Total] 4 / 4 / 1 / 9:   1%|          | 9/872 [00:05<09:02,  1.59it/s][Succeeded / Failed / Skipped / Total] 4 / 4 / 1 / 9:   1%|          | 10/872 [00:06<09:09,  1.57it/s][Succeeded / Failed / Skipped / Total] 5 / 4 / 1 / 10:   1%|          | 10/872 [00:06<09:11,  1.56it/s][Succeeded / Failed / Skipped / Total] 5 / 4 / 1 / 10:   1%|â–         | 11/872 [00:06<09:07,  1.57it/s][Succeeded / Failed / Skipped / Total] 6 / 4 / 1 / 11:   1%|â–         | 11/872 [00:07<09:09,  1.57it/s][Succeeded / Failed / Skipped / Total] 6 / 4 / 1 / 11:   1%|â–         | 12/872 [00:07<09:09,  1.56it/s][Succeeded / Failed / Skipped / Total] 7 / 4 / 1 / 12:   1%|â–         | 12/872 [00:07<09:11,  1.56it/s][Succeeded / Failed / Skipped / Total] 7 / 4 / 1 / 12:   1%|â–         | 13/872 [00:08<08:53,  1.61it/s][Succeeded / Failed / Skipped / Total] 8 / 4 / 1 / 13:   1%|â–         | 13/872 [00:08<08:55,  1.60it/s][Succeeded / Failed / Skipped / Total] 8 / 4 / 1 / 13:   2%|â–         | 14/872 [00:08<08:54,  1.61it/s][Succeeded / Failed / Skipped / Total] 9 / 4 / 1 / 14:   2%|â–         | 14/872 [00:08<08:55,  1.60it/s][Succeeded / Failed / Skipped / Total] 9 / 4 / 1 / 14:   2%|â–         | 15/872 [00:09<08:54,  1.60it/s][Succeeded / Failed / Skipped / Total] 10 / 4 / 1 / 15:   2%|â–         | 15/872 [00:09<08:56,  1.60it/s][Succeeded / Failed / Skipped / Total] 10 / 4 / 1 / 15:   2%|â–         | 16/872 [00:10<09:02,  1.58it/s][Succeeded / Failed / Skipped / Total] 10 / 5 / 1 / 16:   2%|â–         | 16/872 [00:10<09:03,  1.57it/s][Succeeded / Failed / Skipped / Total] 10 / 5 / 1 / 16:   2%|â–         | 17/872 [00:10<09:01,  1.58it/s][Succeeded / Failed / Skipped / Total] 11 / 5 / 1 / 17:   2%|â–         | 17/872 [00:10<09:02,  1.58it/s][Succeeded / Failed / Skipped / Total] 11 / 5 / 1 / 17:   2%|â–         | 18/872 [00:11<09:09,  1.55it/s][Succeeded / Failed / Skipped / Total] 11 / 6 / 1 / 18:   2%|â–         | 18/872 [00:11<09:10,  1.55it/s][Succeeded / Failed / Skipped / Total] 11 / 6 / 1 / 18:   2%|â–         | 19/872 [00:11<08:58,  1.59it/s][Succeeded / Failed / Skipped / Total] 12 / 6 / 1 / 19:   2%|â–         | 19/872 [00:12<08:59,  1.58it/s][Succeeded / Failed / Skipped / Total] 12 / 6 / 1 / 19:   2%|â–         | 20/872 [00:12<08:57,  1.59it/s][Succeeded / Failed / Skipped / Total] 13 / 6 / 1 / 20:   2%|â–         | 20/872 [00:12<08:58,  1.58it/s][Succeeded / Failed / Skipped / Total] 13 / 6 / 1 / 20:   2%|â–         | 21/872 [00:13<08:49,  1.61it/s][Succeeded / Failed / Skipped / Total] 14 / 6 / 1 / 21:   2%|â–         | 21/872 [00:13<08:50,  1.61it/s][Succeeded / Failed / Skipped / Total] 14 / 6 / 1 / 21:   3%|â–Ž         | 22/872 [00:13<08:40,  1.63it/s][Succeeded / Failed / Skipped / Total] 15 / 6 / 1 / 22:   3%|â–Ž         | 22/872 [00:13<08:40,  1.63it/s][Succeeded / Failed / Skipped / Total] 15 / 6 / 1 / 22:   3%|â–Ž         | 23/872 [00:13<08:31,  1.66it/s][Succeeded / Failed / Skipped / Total] 16 / 6 / 1 / 23:   3%|â–Ž         | 23/872 [00:13<08:32,  1.66it/s][Succeeded / Failed / Skipped / Total] 16 / 6 / 1 / 23:   3%|â–Ž         | 24/872 [00:14<08:36,  1.64it/s][Succeeded / Failed / Skipped / Total] 16 / 7 / 1 / 24:   3%|â–Ž         | 24/872 [00:14<08:37,  1.64it/s][Succeeded / Failed / Skipped / Total] 16 / 7 / 1 / 24:   3%|â–Ž         | 25/872 [00:15<08:40,  1.63it/s][Succeeded / Failed / Skipped / Total] 16 / 8 / 1 / 25:   3%|â–Ž         | 25/872 [00:15<08:41,  1.62it/s][Succeeded / Failed / Skipped / Total] 16 / 8 / 1 / 25:   3%|â–Ž         | 26/872 [00:16<08:41,  1.62it/s][Succeeded / Failed / Skipped / Total] 17 / 8 / 1 / 26:   3%|â–Ž         | 26/872 [00:16<08:42,  1.62it/s][Succeeded / Failed / Skipped / Total] 17 / 8 / 1 / 26:   3%|â–Ž         | 27/872 [00:16<08:34,  1.64it/s][Succeeded / Failed / Skipped / Total] 18 / 8 / 1 / 27:   3%|â–Ž         | 27/872 [00:16<08:35,  1.64it/s][Succeeded / Failed / Skipped / Total] 18 / 8 / 1 / 27:   3%|â–Ž         | 28/872 [00:17<08:35,  1.64it/s][Succeeded / Failed / Skipped / Total] 19 / 8 / 1 / 28:   3%|â–Ž         | 28/872 [00:17<08:36,  1.64it/s][Succeeded / Failed / Skipped / Total] 19 / 8 / 1 / 28:   3%|â–Ž         | 29/872 [00:17<08:34,  1.64it/s][Succeeded / Failed / Skipped / Total] 20 / 8 / 1 / 29:   3%|â–Ž         | 29/872 [00:17<08:35,  1.63it/s][Succeeded / Failed / Skipped / Total] 20 / 8 / 1 / 29:   3%|â–Ž         | 30/872 [00:18<08:37,  1.63it/s][Succeeded / Failed / Skipped / Total] 21 / 8 / 1 / 30:   3%|â–Ž         | 30/872 [00:18<08:38,  1.63it/s][Succeeded / Failed / Skipped / Total] 21 / 8 / 1 / 30:   4%|â–Ž         | 31/872 [00:19<08:42,  1.61it/s][Succeeded / Failed / Skipped / Total] 21 / 9 / 1 / 31:   4%|â–Ž         | 31/872 [00:19<08:42,  1.61it/s][Succeeded / Failed / Skipped / Total] 21 / 9 / 1 / 31:   4%|â–Ž         | 32/872 [00:19<08:44,  1.60it/s][Succeeded / Failed / Skipped / Total] 22 / 9 / 1 / 32:   4%|â–Ž         | 32/872 [00:20<08:45,  1.60it/s][Succeeded / Failed / Skipped / Total] 22 / 9 / 1 / 32:   4%|â–         | 33/872 [00:20<08:47,  1.59it/s][Succeeded / Failed / Skipped / Total] 22 / 10 / 1 / 33:   4%|â–         | 33/872 [00:20<08:47,  1.59it/s][Succeeded / Failed / Skipped / Total] 22 / 10 / 1 / 33:   4%|â–         | 34/872 [00:21<08:41,  1.61it/s][Succeeded / Failed / Skipped / Total] 23 / 10 / 1 / 34:   4%|â–         | 34/872 [00:21<08:42,  1.60it/s][Succeeded / Failed / Skipped / Total] 23 / 10 / 1 / 34:   4%|â–         | 35/872 [00:21<08:41,  1.61it/s][Succeeded / Failed / Skipped / Total] 24 / 10 / 1 / 35:   4%|â–         | 35/872 [00:21<08:42,  1.60it/s][Succeeded / Failed / Skipped / Total] 24 / 10 / 1 / 35:   4%|â–         | 36/872 [00:22<08:35,  1.62it/s][Succeeded / Failed / Skipped / Total] 25 / 10 / 1 / 36:   4%|â–         | 36/872 [00:22<08:36,  1.62it/s][Succeeded / Failed / Skipped / Total] 25 / 10 / 1 / 36:   4%|â–         | 37/872 [00:22<08:39,  1.61it/s][Succeeded / Failed / Skipped / Total] 25 / 11 / 1 / 37:   4%|â–         | 37/872 [00:23<08:39,  1.61it/s][Succeeded / Failed / Skipped / Total] 25 / 11 / 1 / 37:   4%|â–         | 38/872 [00:23<08:34,  1.62it/s][Succeeded / Failed / Skipped / Total] 26 / 11 / 1 / 38:   4%|â–         | 38/872 [00:23<08:35,  1.62it/s][Succeeded / Failed / Skipped / Total] 26 / 11 / 1 / 38:   4%|â–         | 39/872 [00:24<08:37,  1.61it/s][Succeeded / Failed / Skipped / Total] 26 / 12 / 1 / 39:   4%|â–         | 39/872 [00:24<08:37,  1.61it/s][Succeeded / Failed / Skipped / Total] 26 / 12 / 1 / 39:   5%|â–         | 40/872 [00:24<08:39,  1.60it/s][Succeeded / Failed / Skipped / Total] 26 / 13 / 1 / 40:   5%|â–         | 40/872 [00:25<08:40,  1.60it/s][Succeeded / Failed / Skipped / Total] 26 / 13 / 1 / 40:   5%|â–         | 41/872 [00:25<08:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 26 / 14 / 1 / 41:   5%|â–         | 41/872 [00:25<08:43,  1.59it/s][Succeeded / Failed / Skipped / Total] 26 / 14 / 1 / 41:   5%|â–         | 42/872 [00:26<08:44,  1.58it/s][Succeeded / Failed / Skipped / Total] 26 / 15 / 1 / 42:   5%|â–         | 42/872 [00:26<08:45,  1.58it/s][Succeeded / Failed / Skipped / Total] 26 / 15 / 1 / 42:   5%|â–         | 43/872 [00:27<08:47,  1.57it/s][Succeeded / Failed / Skipped / Total] 26 / 16 / 1 / 43:   5%|â–         | 43/872 [00:27<08:47,  1.57it/s][Succeeded / Failed / Skipped / Total] 26 / 16 / 1 / 43:   5%|â–Œ         | 44/872 [00:28<08:48,  1.57it/s][Succeeded / Failed / Skipped / Total] 26 / 17 / 1 / 44:   5%|â–Œ         | 44/872 [00:28<08:49,  1.56it/s][Succeeded / Failed / Skipped / Total] 26 / 17 / 1 / 44:   5%|â–Œ         | 45/872 [00:29<08:56,  1.54it/s][Succeeded / Failed / Skipped / Total] 27 / 17 / 1 / 45:   5%|â–Œ         | 45/872 [00:29<08:56,  1.54it/s][Succeeded / Failed / Skipped / Total] 27 / 17 / 1 / 45:   5%|â–Œ         | 46/872 [00:29<08:54,  1.54it/s][Succeeded / Failed / Skipped / Total] 28 / 17 / 1 / 46:   5%|â–Œ         | 46/872 [00:29<08:55,  1.54it/s][Succeeded / Failed / Skipped / Total] 28 / 17 / 1 / 46:   5%|â–Œ         | 47/872 [00:30<08:54,  1.54it/s][Succeeded / Failed / Skipped / Total] 29 / 17 / 1 / 47:   5%|â–Œ         | 47/872 [00:30<08:54,  1.54it/s][Succeeded / Failed / Skipped / Total] 29 / 17 / 1 / 47:   6%|â–Œ         | 48/872 [00:31<08:52,  1.55it/s][Succeeded / Failed / Skipped / Total] 30 / 17 / 1 / 48:   6%|â–Œ         | 48/872 [00:31<08:53,  1.55it/s][Succeeded / Failed / Skipped / Total] 30 / 17 / 1 / 48:   6%|â–Œ         | 49/872 [00:31<08:53,  1.54it/s][Succeeded / Failed / Skipped / Total] 30 / 18 / 1 / 49:   6%|â–Œ         | 49/872 [00:31<08:54,  1.54it/s][Succeeded / Failed / Skipped / Total] 30 / 18 / 1 / 49:   6%|â–Œ         | 50/872 [00:32<08:53,  1.54it/s][Succeeded / Failed / Skipped / Total] 31 / 18 / 1 / 50:   6%|â–Œ         | 50/872 [00:32<08:53,  1.54it/s][Succeeded / Failed / Skipped / Total] 31 / 18 / 1 / 50:   6%|â–Œ         | 51/872 [00:33<08:52,  1.54it/s][Succeeded / Failed / Skipped / Total] 32 / 18 / 1 / 51:   6%|â–Œ         | 51/872 [00:33<08:53,  1.54it/s][Succeeded / Failed / Skipped / Total] 32 / 18 / 1 / 51:   6%|â–Œ         | 52/872 [00:33<08:52,  1.54it/s][Succeeded / Failed / Skipped / Total] 33 / 18 / 1 / 52:   6%|â–Œ         | 52/872 [00:33<08:52,  1.54it/s][Succeeded / Failed / Skipped / Total] 33 / 18 / 1 / 52:   6%|â–Œ         | 53/872 [00:34<08:53,  1.54it/s][Succeeded / Failed / Skipped / Total] 33 / 19 / 1 / 53:   6%|â–Œ         | 53/872 [00:34<08:53,  1.53it/s][Succeeded / Failed / Skipped / Total] 33 / 19 / 1 / 53:   6%|â–Œ         | 54/872 [00:35<08:54,  1.53it/s][Succeeded / Failed / Skipped / Total] 33 / 20 / 1 / 54:   6%|â–Œ         | 54/872 [00:35<08:55,  1.53it/s][Succeeded / Failed / Skipped / Total] 33 / 20 / 1 / 54:   6%|â–‹         | 55/872 [00:35<08:53,  1.53it/s][Succeeded / Failed / Skipped / Total] 34 / 20 / 1 / 55:   6%|â–‹         | 55/872 [00:35<08:54,  1.53it/s][Succeeded / Failed / Skipped / Total] 34 / 20 / 1 / 55:   6%|â–‹         | 56/872 [00:36<08:54,  1.53it/s][Succeeded / Failed / Skipped / Total] 34 / 21 / 1 / 56:   6%|â–‹         | 56/872 [00:36<08:54,  1.53it/s][Succeeded / Failed / Skipped / Total] 34 / 21 / 1 / 56:   7%|â–‹         | 57/872 [00:37<08:53,  1.53it/s][Succeeded / Failed / Skipped / Total] 35 / 21 / 1 / 57:   7%|â–‹         | 57/872 [00:37<08:54,  1.53it/s][Succeeded / Failed / Skipped / Total] 35 / 21 / 1 / 57:   7%|â–‹         | 58/872 [00:37<08:49,  1.54it/s][Succeeded / Failed / Skipped / Total] 36 / 21 / 1 / 58:   7%|â–‹         | 58/872 [00:37<08:49,  1.54it/s][Succeeded / Failed / Skipped / Total] 36 / 21 / 1 / 58:   7%|â–‹         | 59/872 [00:38<08:48,  1.54it/s][Succeeded / Failed / Skipped / Total] 37 / 21 / 1 / 59:   7%|â–‹         | 59/872 [00:38<08:48,  1.54it/s][Succeeded / Failed / Skipped / Total] 37 / 21 / 1 / 59:   7%|â–‹         | 60/872 [00:39<08:47,  1.54it/s][Succeeded / Failed / Skipped / Total] 38 / 21 / 1 / 60:   7%|â–‹         | 60/872 [00:39<08:48,  1.54it/s][Succeeded / Failed / Skipped / Total] 38 / 21 / 1 / 60:   7%|â–‹         | 61/872 [00:39<08:48,  1.53it/s][Succeeded / Failed / Skipped / Total] 38 / 22 / 1 / 61:   7%|â–‹         | 61/872 [00:39<08:49,  1.53it/s][Succeeded / Failed / Skipped / Total] 38 / 22 / 1 / 61:   7%|â–‹         | 62/872 [00:40<08:48,  1.53it/s][Succeeded / Failed / Skipped / Total] 39 / 22 / 1 / 62:   7%|â–‹         | 62/872 [00:40<08:48,  1.53it/s][Succeeded / Failed / Skipped / Total] 39 / 22 / 1 / 62:   7%|â–‹         | 63/872 [00:41<08:48,  1.53it/s][Succeeded / Failed / Skipped / Total] 39 / 23 / 1 / 63:   7%|â–‹         | 63/872 [00:41<08:49,  1.53it/s][Succeeded / Failed / Skipped / Total] 39 / 23 / 1 / 63:   7%|â–‹         | 64/872 [00:41<08:50,  1.52it/s][Succeeded / Failed / Skipped / Total] 39 / 24 / 1 / 64:   7%|â–‹         | 64/872 [00:42<08:50,  1.52it/s][Succeeded / Failed / Skipped / Total] 39 / 24 / 1 / 64:   7%|â–‹         | 65/872 [00:42<08:49,  1.52it/s][Succeeded / Failed / Skipped / Total] 40 / 24 / 1 / 65:   7%|â–‹         | 65/872 [00:42<08:49,  1.52it/s][Succeeded / Failed / Skipped / Total] 40 / 24 / 1 / 65:   8%|â–Š         | 66/872 [00:43<08:45,  1.53it/s][Succeeded / Failed / Skipped / Total] 41 / 24 / 1 / 66:   8%|â–Š         | 66/872 [00:43<08:45,  1.53it/s][Succeeded / Failed / Skipped / Total] 41 / 24 / 1 / 66:   8%|â–Š         | 67/872 [00:43<08:44,  1.53it/s][Succeeded / Failed / Skipped / Total] 42 / 24 / 1 / 67:   8%|â–Š         | 67/872 [00:43<08:44,  1.53it/s][Succeeded / Failed / Skipped / Total] 42 / 24 / 1 / 67:   8%|â–Š         | 68/872 [00:44<08:44,  1.53it/s][Succeeded / Failed / Skipped / Total] 42 / 25 / 1 / 68:   8%|â–Š         | 68/872 [00:44<08:45,  1.53it/s][Succeeded / Failed / Skipped / Total] 42 / 25 / 1 / 68:   8%|â–Š         | 69/872 [00:45<08:45,  1.53it/s][Succeeded / Failed / Skipped / Total] 42 / 26 / 1 / 69:   8%|â–Š         | 69/872 [00:45<08:45,  1.53it/s][Succeeded / Failed / Skipped / Total] 42 / 26 / 1 / 69:   8%|â–Š         | 70/872 [00:45<08:44,  1.53it/s][Succeeded / Failed / Skipped / Total] 43 / 26 / 1 / 70:   8%|â–Š         | 70/872 [00:45<08:44,  1.53it/s][Succeeded / Failed / Skipped / Total] 43 / 26 / 1 / 70:   8%|â–Š         | 71/872 [00:46<08:41,  1.54it/s][Succeeded / Failed / Skipped / Total] 44 / 26 / 1 / 71:   8%|â–Š         | 71/872 [00:46<08:41,  1.54it/s][Succeeded / Failed / Skipped / Total] 44 / 26 / 1 / 71:   8%|â–Š         | 72/872 [00:47<08:42,  1.53it/s][Succeeded / Failed / Skipped / Total] 44 / 27 / 1 / 72:   8%|â–Š         | 72/872 [00:47<08:42,  1.53it/s][Succeeded / Failed / Skipped / Total] 44 / 27 / 1 / 72:   8%|â–Š         | 73/872 [00:47<08:43,  1.53it/s][Succeeded / Failed / Skipped / Total] 44 / 28 / 1 / 73:   8%|â–Š         | 73/872 [00:47<08:43,  1.53it/s][Succeeded / Failed / Skipped / Total] 44 / 28 / 1 / 73:   8%|â–Š         | 74/872 [00:48<08:42,  1.53it/s][Succeeded / Failed / Skipped / Total] 45 / 28 / 1 / 74:   8%|â–Š         | 74/872 [00:48<08:42,  1.53it/s][Succeeded / Failed / Skipped / Total] 45 / 28 / 1 / 74:   9%|â–Š         | 75/872 [00:49<08:41,  1.53it/s][Succeeded / Failed / Skipped / Total] 46 / 28 / 1 / 75:   9%|â–Š         | 75/872 [00:49<08:41,  1.53it/s][Succeeded / Failed / Skipped / Total] 46 / 28 / 1 / 75:   9%|â–Š         | 76/872 [00:49<08:41,  1.52it/s][Succeeded / Failed / Skipped / Total] 46 / 29 / 1 / 76:   9%|â–Š         | 76/872 [00:49<08:42,  1.52it/s][Succeeded / Failed / Skipped / Total] 46 / 29 / 1 / 76:   9%|â–‰         | 77/872 [00:50<08:38,  1.53it/s][Succeeded / Failed / Skipped / Total] 47 / 29 / 1 / 77:   9%|â–‰         | 77/872 [00:50<08:39,  1.53it/s][Succeeded / Failed / Skipped / Total] 47 / 29 / 1 / 77:   9%|â–‰         | 78/872 [00:50<08:37,  1.53it/s][Succeeded / Failed / Skipped / Total] 48 / 29 / 1 / 78:   9%|â–‰         | 78/872 [00:50<08:38,  1.53it/s][Succeeded / Failed / Skipped / Total] 48 / 29 / 1 / 78:   9%|â–‰         | 79/872 [00:51<08:37,  1.53it/s][Succeeded / Failed / Skipped / Total] 49 / 29 / 1 / 79:   9%|â–‰         | 79/872 [00:51<08:37,  1.53it/s][Succeeded / Failed / Skipped / Total] 49 / 29 / 1 / 79:   9%|â–‰         | 80/872 [00:52<08:37,  1.53it/s][Succeeded / Failed / Skipped / Total] 50 / 29 / 1 / 80:   9%|â–‰         | 80/872 [00:52<08:37,  1.53it/s][Succeeded / Failed / Skipped / Total] 50 / 29 / 1 / 80:   9%|â–‰         | 81/872 [00:52<08:37,  1.53it/s][Succeeded / Failed / Skipped / Total] 50 / 30 / 1 / 81:   9%|â–‰         | 81/872 [00:53<08:37,  1.53it/s][Succeeded / Failed / Skipped / Total] 50 / 30 / 1 / 81:   9%|â–‰         | 82/872 [00:53<08:34,  1.54it/s][Succeeded / Failed / Skipped / Total] 51 / 30 / 1 / 82:   9%|â–‰         | 82/872 [00:53<08:34,  1.53it/s][Succeeded / Failed / Skipped / Total] 51 / 30 / 1 / 82:  10%|â–‰         | 83/872 [00:53<08:31,  1.54it/s][Succeeded / Failed / Skipped / Total] 52 / 30 / 1 / 83:  10%|â–‰         | 83/872 [00:53<08:31,  1.54it/s][Succeeded / Failed / Skipped / Total] 52 / 30 / 1 / 83:  10%|â–‰         | 84/872 [00:54<08:31,  1.54it/s][Succeeded / Failed / Skipped / Total] 53 / 30 / 1 / 84:  10%|â–‰         | 84/872 [00:54<08:31,  1.54it/s][Succeeded / Failed / Skipped / Total] 53 / 30 / 1 / 84:  10%|â–‰         | 85/872 [00:55<08:31,  1.54it/s][Succeeded / Failed / Skipped / Total] 53 / 31 / 1 / 85:  10%|â–‰         | 85/872 [00:55<08:31,  1.54it/s][Succeeded / Failed / Skipped / Total] 53 / 31 / 1 / 85:  10%|â–‰         | 86/872 [00:56<08:32,  1.53it/s][Succeeded / Failed / Skipped / Total] 53 / 32 / 1 / 86:  10%|â–‰         | 86/872 [00:56<08:32,  1.53it/s][Succeeded / Failed / Skipped / Total] 53 / 32 / 1 / 86:  10%|â–‰         | 87/872 [00:56<08:31,  1.53it/s][Succeeded / Failed / Skipped / Total] 54 / 32 / 1 / 87:  10%|â–‰         | 87/872 [00:56<08:31,  1.53it/s][Succeeded / Failed / Skipped / Total] 54 / 32 / 1 / 87:  10%|â–ˆ         | 88/872 [00:57<08:32,  1.53it/s][Succeeded / Failed / Skipped / Total] 54 / 33 / 1 / 88:  10%|â–ˆ         | 88/872 [00:57<08:32,  1.53it/s][Succeeded / Failed / Skipped / Total] 54 / 33 / 1 / 88:  10%|â–ˆ         | 89/872 [00:58<08:31,  1.53it/s][Succeeded / Failed / Skipped / Total] 55 / 33 / 1 / 89:  10%|â–ˆ         | 89/872 [00:58<08:31,  1.53it/s][Succeeded / Failed / Skipped / Total] 55 / 33 / 1 / 89:  10%|â–ˆ         | 90/872 [00:58<08:31,  1.53it/s][Succeeded / Failed / Skipped / Total] 55 / 34 / 1 / 90:  10%|â–ˆ         | 90/872 [00:58<08:32,  1.53it/s][Succeeded / Failed / Skipped / Total] 55 / 34 / 1 / 90:  10%|â–ˆ         | 91/872 [00:59<08:30,  1.53it/s][Succeeded / Failed / Skipped / Total] 56 / 34 / 1 / 91:  10%|â–ˆ         | 91/872 [00:59<08:31,  1.53it/s][Succeeded / Failed / Skipped / Total] 56 / 34 / 1 / 91:  11%|â–ˆ         | 92/872 [01:00<08:31,  1.53it/s][Succeeded / Failed / Skipped / Total] 56 / 35 / 1 / 92:  11%|â–ˆ         | 92/872 [01:00<08:31,  1.52it/s][Succeeded / Failed / Skipped / Total] 56 / 35 / 2 / 93:  11%|â–ˆ         | 93/872 [01:00<08:25,  1.54it/s][Succeeded / Failed / Skipped / Total] 56 / 35 / 2 / 93:  11%|â–ˆ         | 94/872 [01:01<08:25,  1.54it/s][Succeeded / Failed / Skipped / Total] 56 / 36 / 2 / 94:  11%|â–ˆ         | 94/872 [01:01<08:26,  1.54it/s][Succeeded / Failed / Skipped / Total] 56 / 37 / 2 / 95:  11%|â–ˆ         | 95/872 [01:01<08:26,  1.53it/s][Succeeded / Failed / Skipped / Total] 56 / 37 / 2 / 95:  11%|â–ˆ         | 96/872 [01:01<08:21,  1.55it/s][Succeeded / Failed / Skipped / Total] 56 / 37 / 3 / 96:  11%|â–ˆ         | 96/872 [01:02<08:21,  1.55it/s][Succeeded / Failed / Skipped / Total] 57 / 37 / 3 / 97:  11%|â–ˆ         | 97/872 [01:02<08:20,  1.55it/s][Succeeded / Failed / Skipped / Total] 57 / 37 / 3 / 97:  11%|â–ˆ         | 98/872 [01:03<08:20,  1.54it/s][Succeeded / Failed / Skipped / Total] 57 / 38 / 3 / 98:  11%|â–ˆ         | 98/872 [01:03<08:21,  1.54it/s][Succeeded / Failed / Skipped / Total] 58 / 38 / 3 / 99:  11%|â–ˆâ–        | 99/872 [01:04<08:20,  1.54it/s][Succeeded / Failed / Skipped / Total] 58 / 38 / 3 / 99:  11%|â–ˆâ–        | 100/872 [01:04<08:18,  1.55it/s][Succeeded / Failed / Skipped / Total] 59 / 38 / 3 / 100:  11%|â–ˆâ–        | 100/872 [01:04<08:18,  1.55it/s][Succeeded / Failed / Skipped / Total] 59 / 39 / 3 / 101:  12%|â–ˆâ–        | 101/872 [01:05<08:18,  1.55it/s][Succeeded / Failed / Skipped / Total] 59 / 39 / 3 / 101:  12%|â–ˆâ–        | 102/872 [01:05<08:16,  1.55it/s][Succeeded / Failed / Skipped / Total] 60 / 39 / 3 / 102:  12%|â–ˆâ–        | 102/872 [01:05<08:16,  1.55it/s][Succeeded / Failed / Skipped / Total] 61 / 39 / 3 / 103:  12%|â–ˆâ–        | 103/872 [01:06<08:13,  1.56it/s][Succeeded / Failed / Skipped / Total] 61 / 39 / 3 / 103:  12%|â–ˆâ–        | 104/872 [01:06<08:13,  1.56it/s][Succeeded / Failed / Skipped / Total] 61 / 40 / 3 / 104:  12%|â–ˆâ–        | 104/872 [01:06<08:14,  1.55it/s][Succeeded / Failed / Skipped / Total] 62 / 40 / 3 / 105:  12%|â–ˆâ–        | 105/872 [01:07<08:13,  1.55it/s][Succeeded / Failed / Skipped / Total] 62 / 40 / 3 / 105:  12%|â–ˆâ–        | 106/872 [01:08<08:13,  1.55it/s][Succeeded / Failed / Skipped / Total] 63 / 40 / 3 / 106:  12%|â–ˆâ–        | 106/872 [01:08<08:13,  1.55it/s][Succeeded / Failed / Skipped / Total] 63 / 41 / 3 / 107:  12%|â–ˆâ–        | 107/872 [01:09<08:13,  1.55it/s][Succeeded / Failed / Skipped / Total] 63 / 41 / 3 / 107:  12%|â–ˆâ–        | 108/872 [01:09<08:11,  1.56it/s][Succeeded / Failed / Skipped / Total] 64 / 41 / 3 / 108:  12%|â–ˆâ–        | 108/872 [01:09<08:11,  1.56it/s][Succeeded / Failed / Skipped / Total] 65 / 41 / 3 / 109:  12%|â–ˆâ–Ž        | 109/872 [01:10<08:10,  1.56it/s][Succeeded / Failed / Skipped / Total] 65 / 41 / 3 / 109:  13%|â–ˆâ–Ž        | 110/872 [01:10<08:10,  1.55it/s][Succeeded / Failed / Skipped / Total] 65 / 42 / 3 / 110:  13%|â–ˆâ–Ž        | 110/872 [01:10<08:10,  1.55it/s][Succeeded / Failed / Skipped / Total] 66 / 42 / 3 / 111:  13%|â–ˆâ–Ž        | 111/872 [01:11<08:09,  1.55it/s][Succeeded / Failed / Skipped / Total] 66 / 42 / 3 / 111:  13%|â–ˆâ–Ž        | 112/872 [01:11<08:07,  1.56it/s][Succeeded / Failed / Skipped / Total] 67 / 42 / 3 / 112:  13%|â–ˆâ–Ž        | 112/872 [01:11<08:07,  1.56it/s][Succeeded / Failed / Skipped / Total] 67 / 42 / 4 / 113:  13%|â–ˆâ–Ž        | 113/872 [01:11<08:02,  1.57it/s][Succeeded / Failed / Skipped / Total] 67 / 42 / 4 / 113:  13%|â–ˆâ–Ž        | 114/872 [01:12<08:01,  1.57it/s][Succeeded / Failed / Skipped / Total] 68 / 42 / 4 / 114:  13%|â–ˆâ–Ž        | 114/872 [01:12<08:02,  1.57it/s][Succeeded / Failed / Skipped / Total] 68 / 43 / 4 / 115:  13%|â–ˆâ–Ž        | 115/872 [01:13<08:02,  1.57it/s][Succeeded / Failed / Skipped / Total] 68 / 43 / 4 / 115:  13%|â–ˆâ–Ž        | 116/872 [01:13<08:00,  1.57it/s][Succeeded / Failed / Skipped / Total] 69 / 43 / 4 / 116:  13%|â–ˆâ–Ž        | 116/872 [01:13<08:00,  1.57it/s][Succeeded / Failed / Skipped / Total] 69 / 44 / 4 / 117:  13%|â–ˆâ–Ž        | 117/872 [01:14<08:00,  1.57it/s][Succeeded / Failed / Skipped / Total] 69 / 44 / 4 / 117:  14%|â–ˆâ–Ž        | 118/872 [01:15<08:00,  1.57it/s][Succeeded / Failed / Skipped / Total] 69 / 45 / 4 / 118:  14%|â–ˆâ–Ž        | 118/872 [01:15<08:01,  1.57it/s][Succeeded / Failed / Skipped / Total] 70 / 45 / 4 / 119:  14%|â–ˆâ–Ž        | 119/872 [01:15<07:59,  1.57it/s][Succeeded / Failed / Skipped / Total] 70 / 45 / 4 / 119:  14%|â–ˆâ–        | 120/872 [01:16<07:56,  1.58it/s][Succeeded / Failed / Skipped / Total] 71 / 45 / 4 / 120:  14%|â–ˆâ–        | 120/872 [01:16<07:57,  1.58it/s][Succeeded / Failed / Skipped / Total] 71 / 46 / 4 / 121:  14%|â–ˆâ–        | 121/872 [01:16<07:57,  1.57it/s][Succeeded / Failed / Skipped / Total] 71 / 46 / 4 / 121:  14%|â–ˆâ–        | 122/872 [01:16<07:53,  1.59it/s][Succeeded / Failed / Skipped / Total] 71 / 46 / 5 / 122:  14%|â–ˆâ–        | 122/872 [01:16<07:53,  1.58it/s][Succeeded / Failed / Skipped / Total] 71 / 47 / 5 / 123:  14%|â–ˆâ–        | 123/872 [01:17<07:53,  1.58it/s][Succeeded / Failed / Skipped / Total] 71 / 47 / 5 / 123:  14%|â–ˆâ–        | 124/872 [01:18<07:52,  1.58it/s][Succeeded / Failed / Skipped / Total] 72 / 47 / 5 / 124:  14%|â–ˆâ–        | 124/872 [01:18<07:52,  1.58it/s][Succeeded / Failed / Skipped / Total] 73 / 47 / 5 / 125:  14%|â–ˆâ–        | 125/872 [01:19<07:52,  1.58it/s][Succeeded / Failed / Skipped / Total] 73 / 47 / 5 / 125:  14%|â–ˆâ–        | 126/872 [01:19<07:52,  1.58it/s][Succeeded / Failed / Skipped / Total] 73 / 48 / 5 / 126:  14%|â–ˆâ–        | 126/872 [01:19<07:52,  1.58it/s][Succeeded / Failed / Skipped / Total] 74 / 48 / 5 / 127:  15%|â–ˆâ–        | 127/872 [01:20<07:51,  1.58it/s][Succeeded / Failed / Skipped / Total] 74 / 48 / 5 / 127:  15%|â–ˆâ–        | 128/872 [01:20<07:50,  1.58it/s][Succeeded / Failed / Skipped / Total] 75 / 48 / 5 / 128:  15%|â–ˆâ–        | 128/872 [01:20<07:50,  1.58it/s][Succeeded / Failed / Skipped / Total] 75 / 49 / 5 / 129:  15%|â–ˆâ–        | 129/872 [01:21<07:50,  1.58it/s][Succeeded / Failed / Skipped / Total] 75 / 49 / 5 / 129:  15%|â–ˆâ–        | 130/872 [01:22<07:50,  1.58it/s][Succeeded / Failed / Skipped / Total] 75 / 50 / 5 / 130:  15%|â–ˆâ–        | 130/872 [01:22<07:50,  1.58it/s][Succeeded / Failed / Skipped / Total] 76 / 50 / 5 / 131:  15%|â–ˆâ–Œ        | 131/872 [01:23<07:49,  1.58it/s][Succeeded / Failed / Skipped / Total] 76 / 50 / 5 / 131:  15%|â–ˆâ–Œ        | 132/872 [01:23<07:47,  1.58it/s][Succeeded / Failed / Skipped / Total] 77 / 50 / 5 / 132:  15%|â–ˆâ–Œ        | 132/872 [01:23<07:48,  1.58it/s][Succeeded / Failed / Skipped / Total] 77 / 51 / 5 / 133:  15%|â–ˆâ–Œ        | 133/872 [01:24<07:48,  1.58it/s][Succeeded / Failed / Skipped / Total] 77 / 51 / 5 / 133:  15%|â–ˆâ–Œ        | 134/872 [01:24<07:46,  1.58it/s][Succeeded / Failed / Skipped / Total] 78 / 51 / 5 / 134:  15%|â–ˆâ–Œ        | 134/872 [01:24<07:46,  1.58it/s][Succeeded / Failed / Skipped / Total] 79 / 51 / 5 / 135:  15%|â–ˆâ–Œ        | 135/872 [01:25<07:45,  1.58it/s][Succeeded / Failed / Skipped / Total] 79 / 51 / 5 / 135:  16%|â–ˆâ–Œ        | 136/872 [01:25<07:44,  1.59it/s][Succeeded / Failed / Skipped / Total] 80 / 51 / 5 / 136:  16%|â–ˆâ–Œ        | 136/872 [01:25<07:44,  1.59it/s][Succeeded / Failed / Skipped / Total] 81 / 51 / 5 / 137:  16%|â–ˆâ–Œ        | 137/872 [01:26<07:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 81 / 51 / 5 / 137:  16%|â–ˆâ–Œ        | 138/872 [01:26<07:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 82 / 51 / 5 / 138:  16%|â–ˆâ–Œ        | 138/872 [01:26<07:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 82 / 52 / 5 / 139:  16%|â–ˆâ–Œ        | 139/872 [01:27<07:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 82 / 52 / 5 / 139:  16%|â–ˆâ–Œ        | 140/872 [01:28<07:40,  1.59it/s][Succeeded / Failed / Skipped / Total] 83 / 52 / 5 / 140:  16%|â–ˆâ–Œ        | 140/872 [01:28<07:40,  1.59it/s][Succeeded / Failed / Skipped / Total] 84 / 52 / 5 / 141:  16%|â–ˆâ–Œ        | 141/872 [01:28<07:38,  1.59it/s][Succeeded / Failed / Skipped / Total] 84 / 52 / 5 / 141:  16%|â–ˆâ–‹        | 142/872 [01:29<07:37,  1.59it/s][Succeeded / Failed / Skipped / Total] 85 / 52 / 5 / 142:  16%|â–ˆâ–‹        | 142/872 [01:29<07:37,  1.59it/s][Succeeded / Failed / Skipped / Total] 85 / 53 / 5 / 143:  16%|â–ˆâ–‹        | 143/872 [01:29<07:37,  1.59it/s][Succeeded / Failed / Skipped / Total] 85 / 53 / 5 / 143:  17%|â–ˆâ–‹        | 144/872 [01:30<07:37,  1.59it/s][Succeeded / Failed / Skipped / Total] 86 / 53 / 5 / 144:  17%|â–ˆâ–‹        | 144/872 [01:30<07:37,  1.59it/s][Succeeded / Failed / Skipped / Total] 87 / 53 / 5 / 145:  17%|â–ˆâ–‹        | 145/872 [01:31<07:36,  1.59it/s][Succeeded / Failed / Skipped / Total] 87 / 53 / 5 / 145:  17%|â–ˆâ–‹        | 146/872 [01:31<07:36,  1.59it/s][Succeeded / Failed / Skipped / Total] 88 / 53 / 5 / 146:  17%|â–ˆâ–‹        | 146/872 [01:31<07:36,  1.59it/s][Succeeded / Failed / Skipped / Total] 88 / 54 / 5 / 147:  17%|â–ˆâ–‹        | 147/872 [01:32<07:36,  1.59it/s][Succeeded / Failed / Skipped / Total] 88 / 54 / 5 / 147:  17%|â–ˆâ–‹        | 148/872 [01:32<07:34,  1.59it/s][Succeeded / Failed / Skipped / Total] 89 / 54 / 5 / 148:  17%|â–ˆâ–‹        | 148/872 [01:32<07:34,  1.59it/s][Succeeded / Failed / Skipped / Total] 90 / 54 / 5 / 149:  17%|â–ˆâ–‹        | 149/872 [01:33<07:34,  1.59it/s][Succeeded / Failed / Skipped / Total] 90 / 54 / 5 / 149:  17%|â–ˆâ–‹        | 150/872 [01:34<07:34,  1.59it/s][Succeeded / Failed / Skipped / Total] 90 / 55 / 5 / 150:  17%|â–ˆâ–‹        | 150/872 [01:34<07:34,  1.59it/s][Succeeded / Failed / Skipped / Total] 90 / 56 / 5 / 151:  17%|â–ˆâ–‹        | 151/872 [01:35<07:34,  1.59it/s][Succeeded / Failed / Skipped / Total] 90 / 56 / 5 / 151:  17%|â–ˆâ–‹        | 152/872 [01:35<07:34,  1.58it/s][Succeeded / Failed / Skipped / Total] 90 / 57 / 5 / 152:  17%|â–ˆâ–‹        | 152/872 [01:35<07:34,  1.58it/s][Succeeded / Failed / Skipped / Total] 90 / 58 / 5 / 153:  18%|â–ˆâ–Š        | 153/872 [01:36<07:34,  1.58it/s][Succeeded / Failed / Skipped / Total] 90 / 58 / 5 / 153:  18%|â–ˆâ–Š        | 154/872 [01:37<07:33,  1.58it/s][Succeeded / Failed / Skipped / Total] 91 / 58 / 5 / 154:  18%|â–ˆâ–Š        | 154/872 [01:37<07:34,  1.58it/s][Succeeded / Failed / Skipped / Total] 92 / 58 / 5 / 155:  18%|â–ˆâ–Š        | 155/872 [01:37<07:33,  1.58it/s][Succeeded / Failed / Skipped / Total] 92 / 58 / 5 / 155:  18%|â–ˆâ–Š        | 156/872 [01:38<07:32,  1.58it/s][Succeeded / Failed / Skipped / Total] 93 / 58 / 5 / 156:  18%|â–ˆâ–Š        | 156/872 [01:38<07:32,  1.58it/s][Succeeded / Failed / Skipped / Total] 93 / 59 / 5 / 157:  18%|â–ˆâ–Š        | 157/872 [01:39<07:32,  1.58it/s][Succeeded / Failed / Skipped / Total] 93 / 59 / 5 / 157:  18%|â–ˆâ–Š        | 158/872 [01:39<07:31,  1.58it/s][Succeeded / Failed / Skipped / Total] 94 / 59 / 5 / 158:  18%|â–ˆâ–Š        | 158/872 [01:39<07:31,  1.58it/s][Succeeded / Failed / Skipped / Total] 95 / 59 / 5 / 159:  18%|â–ˆâ–Š        | 159/872 [01:40<07:29,  1.59it/s][Succeeded / Failed / Skipped / Total] 95 / 59 / 5 / 159:  18%|â–ˆâ–Š        | 160/872 [01:40<07:28,  1.59it/s][Succeeded / Failed / Skipped / Total] 96 / 59 / 5 / 160:  18%|â–ˆâ–Š        | 160/872 [01:40<07:29,  1.59it/s][Succeeded / Failed / Skipped / Total] 97 / 59 / 5 / 161:  18%|â–ˆâ–Š        | 161/872 [01:41<07:27,  1.59it/s][Succeeded / Failed / Skipped / Total] 97 / 59 / 5 / 161:  19%|â–ˆâ–Š        | 162/872 [01:41<07:25,  1.59it/s][Succeeded / Failed / Skipped / Total] 98 / 59 / 5 / 162:  19%|â–ˆâ–Š        | 162/872 [01:41<07:25,  1.59it/s][Succeeded / Failed / Skipped / Total] 99 / 59 / 5 / 163:  19%|â–ˆâ–Š        | 163/872 [01:42<07:24,  1.60it/s][Succeeded / Failed / Skipped / Total] 99 / 59 / 5 / 163:  19%|â–ˆâ–‰        | 164/872 [01:42<07:22,  1.60it/s][Succeeded / Failed / Skipped / Total] 100 / 59 / 5 / 164:  19%|â–ˆâ–‰        | 164/872 [01:42<07:23,  1.60it/s][Succeeded / Failed / Skipped / Total] 101 / 59 / 5 / 165:  19%|â–ˆâ–‰        | 165/872 [01:43<07:22,  1.60it/s][Succeeded / Failed / Skipped / Total] 101 / 59 / 5 / 165:  19%|â–ˆâ–‰        | 166/872 [01:43<07:20,  1.60it/s][Succeeded / Failed / Skipped / Total] 102 / 59 / 5 / 166:  19%|â–ˆâ–‰        | 166/872 [01:43<07:21,  1.60it/s][Succeeded / Failed / Skipped / Total] 103 / 59 / 5 / 167:  19%|â–ˆâ–‰        | 167/872 [01:44<07:19,  1.60it/s][Succeeded / Failed / Skipped / Total] 103 / 59 / 5 / 167:  19%|â–ˆâ–‰        | 168/872 [01:44<07:18,  1.61it/s][Succeeded / Failed / Skipped / Total] 104 / 59 / 5 / 168:  19%|â–ˆâ–‰        | 168/872 [01:44<07:18,  1.61it/s][Succeeded / Failed / Skipped / Total] 104 / 60 / 5 / 169:  19%|â–ˆâ–‰        | 169/872 [01:45<07:18,  1.60it/s][Succeeded / Failed / Skipped / Total] 104 / 60 / 5 / 169:  19%|â–ˆâ–‰        | 170/872 [01:46<07:17,  1.60it/s][Succeeded / Failed / Skipped / Total] 104 / 61 / 5 / 170:  19%|â–ˆâ–‰        | 170/872 [01:46<07:17,  1.60it/s][Succeeded / Failed / Skipped / Total] 104 / 62 / 5 / 171:  20%|â–ˆâ–‰        | 171/872 [01:46<07:17,  1.60it/s][Succeeded / Failed / Skipped / Total] 104 / 62 / 5 / 171:  20%|â–ˆâ–‰        | 172/872 [01:46<07:14,  1.61it/s][Succeeded / Failed / Skipped / Total] 104 / 62 / 6 / 172:  20%|â–ˆâ–‰        | 172/872 [01:46<07:14,  1.61it/s][Succeeded / Failed / Skipped / Total] 104 / 63 / 6 / 173:  20%|â–ˆâ–‰        | 173/872 [01:47<07:14,  1.61it/s][Succeeded / Failed / Skipped / Total] 104 / 63 / 6 / 173:  20%|â–ˆâ–‰        | 174/872 [01:48<07:13,  1.61it/s][Succeeded / Failed / Skipped / Total] 105 / 63 / 6 / 174:  20%|â–ˆâ–‰        | 174/872 [01:48<07:13,  1.61it/s][Succeeded / Failed / Skipped / Total] 105 / 64 / 6 / 175:  20%|â–ˆâ–ˆ        | 175/872 [01:48<07:13,  1.61it/s][Succeeded / Failed / Skipped / Total] 105 / 64 / 6 / 175:  20%|â–ˆâ–ˆ        | 176/872 [01:49<07:13,  1.61it/s][Succeeded / Failed / Skipped / Total] 105 / 65 / 6 / 176:  20%|â–ˆâ–ˆ        | 176/872 [01:49<07:13,  1.61it/s][Succeeded / Failed / Skipped / Total] 106 / 65 / 6 / 177:  20%|â–ˆâ–ˆ        | 177/872 [01:50<07:12,  1.61it/s][Succeeded / Failed / Skipped / Total] 106 / 65 / 6 / 177:  20%|â–ˆâ–ˆ        | 178/872 [01:50<07:12,  1.61it/s][Succeeded / Failed / Skipped / Total] 107 / 65 / 6 / 178:  20%|â–ˆâ–ˆ        | 178/872 [01:50<07:12,  1.61it/s][Succeeded / Failed / Skipped / Total] 108 / 65 / 6 / 179:  21%|â–ˆâ–ˆ        | 179/872 [01:51<07:11,  1.61it/s][Succeeded / Failed / Skipped / Total] 108 / 65 / 6 / 179:  21%|â–ˆâ–ˆ        | 180/872 [01:52<07:11,  1.60it/s][Succeeded / Failed / Skipped / Total] 108 / 66 / 6 / 180:  21%|â–ˆâ–ˆ        | 180/872 [01:52<07:11,  1.60it/s][Succeeded / Failed / Skipped / Total] 109 / 66 / 6 / 181:  21%|â–ˆâ–ˆ        | 181/872 [01:52<07:10,  1.61it/s][Succeeded / Failed / Skipped / Total] 109 / 66 / 6 / 181:  21%|â–ˆâ–ˆ        | 182/872 [01:53<07:09,  1.61it/s][Succeeded / Failed / Skipped / Total] 110 / 66 / 6 / 182:  21%|â–ˆâ–ˆ        | 182/872 [01:53<07:09,  1.61it/s][Succeeded / Failed / Skipped / Total] 111 / 66 / 6 / 183:  21%|â–ˆâ–ˆ        | 183/872 [01:53<07:08,  1.61it/s][Succeeded / Failed / Skipped / Total] 111 / 66 / 6 / 183:  21%|â–ˆâ–ˆ        | 184/872 [01:53<07:05,  1.62it/s][Succeeded / Failed / Skipped / Total] 111 / 66 / 7 / 184:  21%|â–ˆâ–ˆ        | 184/872 [01:53<07:05,  1.62it/s][Succeeded / Failed / Skipped / Total] 112 / 66 / 7 / 185:  21%|â–ˆâ–ˆ        | 185/872 [01:54<07:04,  1.62it/s][Succeeded / Failed / Skipped / Total] 112 / 66 / 7 / 185:  21%|â–ˆâ–ˆâ–       | 186/872 [01:55<07:04,  1.62it/s][Succeeded / Failed / Skipped / Total] 112 / 67 / 7 / 186:  21%|â–ˆâ–ˆâ–       | 186/872 [01:55<07:04,  1.62it/s][Succeeded / Failed / Skipped / Total] 112 / 68 / 7 / 187:  21%|â–ˆâ–ˆâ–       | 187/872 [01:55<07:04,  1.61it/s][Succeeded / Failed / Skipped / Total] 112 / 68 / 7 / 187:  22%|â–ˆâ–ˆâ–       | 188/872 [01:56<07:04,  1.61it/s][Succeeded / Failed / Skipped / Total] 112 / 69 / 7 / 188:  22%|â–ˆâ–ˆâ–       | 188/872 [01:56<07:04,  1.61it/s][Succeeded / Failed / Skipped / Total] 113 / 69 / 7 / 189:  22%|â–ˆâ–ˆâ–       | 189/872 [01:57<07:03,  1.61it/s][Succeeded / Failed / Skipped / Total] 113 / 69 / 7 / 189:  22%|â–ˆâ–ˆâ–       | 190/872 [01:57<07:03,  1.61it/s][Succeeded / Failed / Skipped / Total] 114 / 69 / 7 / 190:  22%|â–ˆâ–ˆâ–       | 190/872 [01:57<07:03,  1.61it/s][Succeeded / Failed / Skipped / Total] 115 / 69 / 7 / 191:  22%|â–ˆâ–ˆâ–       | 191/872 [01:58<07:02,  1.61it/s][Succeeded / Failed / Skipped / Total] 115 / 69 / 7 / 191:  22%|â–ˆâ–ˆâ–       | 192/872 [01:59<07:02,  1.61it/s][Succeeded / Failed / Skipped / Total] 115 / 70 / 7 / 192:  22%|â–ˆâ–ˆâ–       | 192/872 [01:59<07:02,  1.61it/s][Succeeded / Failed / Skipped / Total] 115 / 71 / 7 / 193:  22%|â–ˆâ–ˆâ–       | 193/872 [02:00<07:02,  1.61it/s][Succeeded / Failed / Skipped / Total] 115 / 71 / 7 / 193:  22%|â–ˆâ–ˆâ–       | 194/872 [02:00<07:02,  1.61it/s][Succeeded / Failed / Skipped / Total] 116 / 71 / 7 / 194:  22%|â–ˆâ–ˆâ–       | 194/872 [02:00<07:02,  1.61it/s][Succeeded / Failed / Skipped / Total] 117 / 71 / 7 / 195:  22%|â–ˆâ–ˆâ–       | 195/872 [02:01<07:01,  1.61it/s][Succeeded / Failed / Skipped / Total] 117 / 71 / 7 / 195:  22%|â–ˆâ–ˆâ–       | 196/872 [02:02<07:01,  1.60it/s][Succeeded / Failed / Skipped / Total] 117 / 72 / 7 / 196:  22%|â–ˆâ–ˆâ–       | 196/872 [02:02<07:01,  1.60it/s][Succeeded / Failed / Skipped / Total] 118 / 72 / 7 / 197:  23%|â–ˆâ–ˆâ–Ž       | 197/872 [02:02<07:00,  1.60it/s][Succeeded / Failed / Skipped / Total] 118 / 72 / 7 / 197:  23%|â–ˆâ–ˆâ–Ž       | 198/872 [02:03<06:59,  1.61it/s][Succeeded / Failed / Skipped / Total] 119 / 72 / 7 / 198:  23%|â–ˆâ–ˆâ–Ž       | 198/872 [02:03<06:59,  1.61it/s][Succeeded / Failed / Skipped / Total] 119 / 73 / 7 / 199:  23%|â–ˆâ–ˆâ–Ž       | 199/872 [02:04<06:59,  1.60it/s][Succeeded / Failed / Skipped / Total] 119 / 73 / 7 / 199:  23%|â–ˆâ–ˆâ–Ž       | 200/872 [02:04<06:57,  1.61it/s][Succeeded / Failed / Skipped / Total] 119 / 73 / 8 / 200:  23%|â–ˆâ–ˆâ–Ž       | 200/872 [02:04<06:57,  1.61it/s][Succeeded / Failed / Skipped / Total] 119 / 74 / 8 / 201:  23%|â–ˆâ–ˆâ–Ž       | 201/872 [02:04<06:57,  1.61it/s][Succeeded / Failed / Skipped / Total] 119 / 74 / 8 / 201:  23%|â–ˆâ–ˆâ–Ž       | 202/872 [02:05<06:56,  1.61it/s][Succeeded / Failed / Skipped / Total] 120 / 74 / 8 / 202:  23%|â–ˆâ–ˆâ–Ž       | 202/872 [02:05<06:56,  1.61it/s][Succeeded / Failed / Skipped / Total] 121 / 74 / 8 / 203:  23%|â–ˆâ–ˆâ–Ž       | 203/872 [02:06<06:55,  1.61it/s][Succeeded / Failed / Skipped / Total] 121 / 74 / 8 / 203:  23%|â–ˆâ–ˆâ–Ž       | 204/872 [02:06<06:54,  1.61it/s][Succeeded / Failed / Skipped / Total] 122 / 74 / 8 / 204:  23%|â–ˆâ–ˆâ–Ž       | 204/872 [02:06<06:54,  1.61it/s][Succeeded / Failed / Skipped / Total] 123 / 74 / 8 / 205:  24%|â–ˆâ–ˆâ–Ž       | 205/872 [02:07<06:54,  1.61it/s][Succeeded / Failed / Skipped / Total] 123 / 74 / 8 / 205:  24%|â–ˆâ–ˆâ–Ž       | 206/872 [02:08<06:54,  1.61it/s][Succeeded / Failed / Skipped / Total] 123 / 75 / 8 / 206:  24%|â–ˆâ–ˆâ–Ž       | 206/872 [02:08<06:54,  1.61it/s][Succeeded / Failed / Skipped / Total] 123 / 76 / 8 / 207:  24%|â–ˆâ–ˆâ–Ž       | 207/872 [02:08<06:53,  1.61it/s][Succeeded / Failed / Skipped / Total] 123 / 76 / 8 / 207:  24%|â–ˆâ–ˆâ–       | 208/872 [02:09<06:53,  1.61it/s][Succeeded / Failed / Skipped / Total] 123 / 77 / 8 / 208:  24%|â–ˆâ–ˆâ–       | 208/872 [02:09<06:53,  1.60it/s][Succeeded / Failed / Skipped / Total] 124 / 77 / 8 / 209:  24%|â–ˆâ–ˆâ–       | 209/872 [02:10<06:52,  1.61it/s][Succeeded / Failed / Skipped / Total] 124 / 77 / 8 / 209:  24%|â–ˆâ–ˆâ–       | 210/872 [02:10<06:51,  1.61it/s][Succeeded / Failed / Skipped / Total] 125 / 77 / 8 / 210:  24%|â–ˆâ–ˆâ–       | 210/872 [02:10<06:51,  1.61it/s][Succeeded / Failed / Skipped / Total] 125 / 78 / 8 / 211:  24%|â–ˆâ–ˆâ–       | 211/872 [02:11<06:52,  1.60it/s][Succeeded / Failed / Skipped / Total] 125 / 78 / 8 / 211:  24%|â–ˆâ–ˆâ–       | 212/872 [02:11<06:49,  1.61it/s][Succeeded / Failed / Skipped / Total] 125 / 78 / 9 / 212:  24%|â–ˆâ–ˆâ–       | 212/872 [02:11<06:49,  1.61it/s][Succeeded / Failed / Skipped / Total] 126 / 78 / 9 / 213:  24%|â–ˆâ–ˆâ–       | 213/872 [02:12<06:49,  1.61it/s][Succeeded / Failed / Skipped / Total] 126 / 78 / 9 / 213:  25%|â–ˆâ–ˆâ–       | 214/872 [02:12<06:48,  1.61it/s][Succeeded / Failed / Skipped / Total] 127 / 78 / 9 / 214:  25%|â–ˆâ–ˆâ–       | 214/872 [02:12<06:48,  1.61it/s][Succeeded / Failed / Skipped / Total] 128 / 78 / 9 / 215:  25%|â–ˆâ–ˆâ–       | 215/872 [02:13<06:48,  1.61it/s][Succeeded / Failed / Skipped / Total] 128 / 78 / 9 / 215:  25%|â–ˆâ–ˆâ–       | 216/872 [02:14<06:48,  1.61it/s][Succeeded / Failed / Skipped / Total] 128 / 79 / 9 / 216:  25%|â–ˆâ–ˆâ–       | 216/872 [02:14<06:48,  1.61it/s][Succeeded / Failed / Skipped / Total] 128 / 80 / 9 / 217:  25%|â–ˆâ–ˆâ–       | 217/872 [02:15<06:48,  1.61it/s][Succeeded / Failed / Skipped / Total] 128 / 80 / 9 / 217:  25%|â–ˆâ–ˆâ–Œ       | 218/872 [02:15<06:45,  1.61it/s][Succeeded / Failed / Skipped / Total] 128 / 80 / 10 / 218:  25%|â–ˆâ–ˆâ–Œ       | 218/872 [02:15<06:45,  1.61it/s][Succeeded / Failed / Skipped / Total] 129 / 80 / 10 / 219:  25%|â–ˆâ–ˆâ–Œ       | 219/872 [02:15<06:44,  1.61it/s][Succeeded / Failed / Skipped / Total] 129 / 80 / 10 / 219:  25%|â–ˆâ–ˆâ–Œ       | 220/872 [02:16<06:44,  1.61it/s][Succeeded / Failed / Skipped / Total] 129 / 81 / 10 / 220:  25%|â–ˆâ–ˆâ–Œ       | 220/872 [02:16<06:44,  1.61it/s][Succeeded / Failed / Skipped / Total] 129 / 82 / 10 / 221:  25%|â–ˆâ–ˆâ–Œ       | 221/872 [02:17<06:44,  1.61it/s][Succeeded / Failed / Skipped / Total] 129 / 82 / 10 / 221:  25%|â–ˆâ–ˆâ–Œ       | 222/872 [02:17<06:43,  1.61it/s][Succeeded / Failed / Skipped / Total] 130 / 82 / 10 / 222:  25%|â–ˆâ–ˆâ–Œ       | 222/872 [02:17<06:43,  1.61it/s][Succeeded / Failed / Skipped / Total] 130 / 83 / 10 / 223:  26%|â–ˆâ–ˆâ–Œ       | 223/872 [02:18<06:43,  1.61it/s][Succeeded / Failed / Skipped / Total] 130 / 83 / 10 / 223:  26%|â–ˆâ–ˆâ–Œ       | 224/872 [02:19<06:43,  1.61it/s][Succeeded / Failed / Skipped / Total] 131 / 83 / 10 / 224:  26%|â–ˆâ–ˆâ–Œ       | 224/872 [02:19<06:43,  1.61it/s][Succeeded / Failed / Skipped / Total] 131 / 83 / 11 / 225:  26%|â–ˆâ–ˆâ–Œ       | 225/872 [02:19<06:41,  1.61it/s][Succeeded / Failed / Skipped / Total] 131 / 83 / 11 / 225:  26%|â–ˆâ–ˆâ–Œ       | 226/872 [02:20<06:40,  1.61it/s][Succeeded / Failed / Skipped / Total] 132 / 83 / 11 / 226:  26%|â–ˆâ–ˆâ–Œ       | 226/872 [02:20<06:40,  1.61it/s][Succeeded / Failed / Skipped / Total] 133 / 83 / 11 / 227:  26%|â–ˆâ–ˆâ–Œ       | 227/872 [02:20<06:39,  1.62it/s][Succeeded / Failed / Skipped / Total] 133 / 83 / 11 / 227:  26%|â–ˆâ–ˆâ–Œ       | 228/872 [02:21<06:39,  1.61it/s][Succeeded / Failed / Skipped / Total] 133 / 84 / 11 / 228:  26%|â–ˆâ–ˆâ–Œ       | 228/872 [02:21<06:39,  1.61it/s][Succeeded / Failed / Skipped / Total] 133 / 85 / 11 / 229:  26%|â–ˆâ–ˆâ–‹       | 229/872 [02:22<06:38,  1.61it/s][Succeeded / Failed / Skipped / Total] 133 / 85 / 11 / 229:  26%|â–ˆâ–ˆâ–‹       | 230/872 [02:22<06:38,  1.61it/s][Succeeded / Failed / Skipped / Total] 134 / 85 / 11 / 230:  26%|â–ˆâ–ˆâ–‹       | 230/872 [02:22<06:38,  1.61it/s][Succeeded / Failed / Skipped / Total] 134 / 85 / 12 / 231:  26%|â–ˆâ–ˆâ–‹       | 231/872 [02:22<06:36,  1.62it/s][Succeeded / Failed / Skipped / Total] 134 / 85 / 12 / 231:  27%|â–ˆâ–ˆâ–‹       | 232/872 [02:23<06:36,  1.62it/s][Succeeded / Failed / Skipped / Total] 134 / 86 / 12 / 232:  27%|â–ˆâ–ˆâ–‹       | 232/872 [02:23<06:36,  1.62it/s][Succeeded / Failed / Skipped / Total] 135 / 86 / 12 / 233:  27%|â–ˆâ–ˆâ–‹       | 233/872 [02:24<06:35,  1.62it/s][Succeeded / Failed / Skipped / Total] 135 / 86 / 12 / 233:  27%|â–ˆâ–ˆâ–‹       | 234/872 [02:24<06:33,  1.62it/s][Succeeded / Failed / Skipped / Total] 136 / 86 / 12 / 234:  27%|â–ˆâ–ˆâ–‹       | 234/872 [02:24<06:33,  1.62it/s][Succeeded / Failed / Skipped / Total] 136 / 87 / 12 / 235:  27%|â–ˆâ–ˆâ–‹       | 235/872 [02:25<06:33,  1.62it/s][Succeeded / Failed / Skipped / Total] 136 / 87 / 12 / 235:  27%|â–ˆâ–ˆâ–‹       | 236/872 [02:26<06:33,  1.62it/s][Succeeded / Failed / Skipped / Total] 136 / 88 / 12 / 236:  27%|â–ˆâ–ˆâ–‹       | 236/872 [02:26<06:33,  1.62it/s][Succeeded / Failed / Skipped / Total] 136 / 89 / 12 / 237:  27%|â–ˆâ–ˆâ–‹       | 237/872 [02:26<06:33,  1.61it/s][Succeeded / Failed / Skipped / Total] 136 / 89 / 12 / 237:  27%|â–ˆâ–ˆâ–‹       | 238/872 [02:27<06:32,  1.61it/s][Succeeded / Failed / Skipped / Total] 137 / 89 / 12 / 238:  27%|â–ˆâ–ˆâ–‹       | 238/872 [02:27<06:33,  1.61it/s][Succeeded / Failed / Skipped / Total] 138 / 89 / 12 / 239:  27%|â–ˆâ–ˆâ–‹       | 239/872 [02:27<06:31,  1.62it/s][Succeeded / Failed / Skipped / Total] 138 / 89 / 12 / 239:  28%|â–ˆâ–ˆâ–Š       | 240/872 [02:28<06:31,  1.61it/s][Succeeded / Failed / Skipped / Total] 138 / 90 / 12 / 240:  28%|â–ˆâ–ˆâ–Š       | 240/872 [02:28<06:31,  1.61it/s][Succeeded / Failed / Skipped / Total] 138 / 91 / 12 / 241:  28%|â–ˆâ–ˆâ–Š       | 241/872 [02:29<06:31,  1.61it/s][Succeeded / Failed / Skipped / Total] 138 / 91 / 12 / 241:  28%|â–ˆâ–ˆâ–Š       | 242/872 [02:29<06:30,  1.61it/s][Succeeded / Failed / Skipped / Total] 139 / 91 / 12 / 242:  28%|â–ˆâ–ˆâ–Š       | 242/872 [02:29<06:30,  1.61it/s][Succeeded / Failed / Skipped / Total] 140 / 91 / 12 / 243:  28%|â–ˆâ–ˆâ–Š       | 243/872 [02:30<06:29,  1.62it/s][Succeeded / Failed / Skipped / Total] 140 / 91 / 12 / 243:  28%|â–ˆâ–ˆâ–Š       | 244/872 [02:30<06:28,  1.62it/s][Succeeded / Failed / Skipped / Total] 141 / 91 / 12 / 244:  28%|â–ˆâ–ˆâ–Š       | 244/872 [02:30<06:28,  1.62it/s][Succeeded / Failed / Skipped / Total] 141 / 92 / 12 / 245:  28%|â–ˆâ–ˆâ–Š       | 245/872 [02:31<06:28,  1.61it/s][Succeeded / Failed / Skipped / Total] 141 / 92 / 12 / 245:  28%|â–ˆâ–ˆâ–Š       | 246/872 [02:32<06:28,  1.61it/s][Succeeded / Failed / Skipped / Total] 141 / 93 / 12 / 246:  28%|â–ˆâ–ˆâ–Š       | 246/872 [02:32<06:28,  1.61it/s][Succeeded / Failed / Skipped / Total] 141 / 94 / 12 / 247:  28%|â–ˆâ–ˆâ–Š       | 247/872 [02:33<06:28,  1.61it/s][Succeeded / Failed / Skipped / Total] 141 / 94 / 12 / 247:  28%|â–ˆâ–ˆâ–Š       | 248/872 [02:34<06:27,  1.61it/s][Succeeded / Failed / Skipped / Total] 142 / 94 / 12 / 248:  28%|â–ˆâ–ˆâ–Š       | 248/872 [02:34<06:27,  1.61it/s][Succeeded / Failed / Skipped / Total] 143 / 94 / 12 / 249:  29%|â–ˆâ–ˆâ–Š       | 249/872 [02:34<06:27,  1.61it/s][Succeeded / Failed / Skipped / Total] 143 / 94 / 12 / 249:  29%|â–ˆâ–ˆâ–Š       | 250/872 [02:35<06:26,  1.61it/s][Succeeded / Failed / Skipped / Total] 144 / 94 / 12 / 250:  29%|â–ˆâ–ˆâ–Š       | 250/872 [02:35<06:26,  1.61it/s][Succeeded / Failed / Skipped / Total] 144 / 95 / 12 / 251:  29%|â–ˆâ–ˆâ–‰       | 251/872 [02:36<06:26,  1.61it/s][Succeeded / Failed / Skipped / Total] 144 / 95 / 12 / 251:  29%|â–ˆâ–ˆâ–‰       | 252/872 [02:36<06:25,  1.61it/s][Succeeded / Failed / Skipped / Total] 145 / 95 / 12 / 252:  29%|â–ˆâ–ˆâ–‰       | 252/872 [02:36<06:25,  1.61it/s][Succeeded / Failed / Skipped / Total] 145 / 96 / 12 / 253:  29%|â–ˆâ–ˆâ–‰       | 253/872 [02:37<06:25,  1.61it/s][Succeeded / Failed / Skipped / Total] 145 / 96 / 12 / 253:  29%|â–ˆâ–ˆâ–‰       | 254/872 [02:37<06:24,  1.61it/s][Succeeded / Failed / Skipped / Total] 146 / 96 / 12 / 254:  29%|â–ˆâ–ˆâ–‰       | 254/872 [02:38<06:24,  1.61it/s][Succeeded / Failed / Skipped / Total] 147 / 96 / 12 / 255:  29%|â–ˆâ–ˆâ–‰       | 255/872 [02:38<06:23,  1.61it/s][Succeeded / Failed / Skipped / Total] 147 / 96 / 12 / 255:  29%|â–ˆâ–ˆâ–‰       | 256/872 [02:39<06:22,  1.61it/s][Succeeded / Failed / Skipped / Total] 148 / 96 / 12 / 256:  29%|â–ˆâ–ˆâ–‰       | 256/872 [02:39<06:22,  1.61it/s][Succeeded / Failed / Skipped / Total] 149 / 96 / 12 / 257:  29%|â–ˆâ–ˆâ–‰       | 257/872 [02:39<06:22,  1.61it/s][Succeeded / Failed / Skipped / Total] 149 / 96 / 12 / 257:  30%|â–ˆâ–ˆâ–‰       | 258/872 [02:40<06:21,  1.61it/s][Succeeded / Failed / Skipped / Total] 150 / 96 / 12 / 258:  30%|â–ˆâ–ˆâ–‰       | 258/872 [02:40<06:21,  1.61it/s][Succeeded / Failed / Skipped / Total] 151 / 96 / 12 / 259:  30%|â–ˆâ–ˆâ–‰       | 259/872 [02:40<06:20,  1.61it/s][Succeeded / Failed / Skipped / Total] 151 / 96 / 12 / 259:  30%|â–ˆâ–ˆâ–‰       | 260/872 [02:41<06:20,  1.61it/s][Succeeded / Failed / Skipped / Total] 151 / 97 / 12 / 260:  30%|â–ˆâ–ˆâ–‰       | 260/872 [02:41<06:20,  1.61it/s][Succeeded / Failed / Skipped / Total] 151 / 97 / 13 / 261:  30%|â–ˆâ–ˆâ–‰       | 261/872 [02:41<06:18,  1.61it/s][Succeeded / Failed / Skipped / Total] 151 / 97 / 13 / 261:  30%|â–ˆâ–ˆâ–ˆ       | 262/872 [02:42<06:18,  1.61it/s][Succeeded / Failed / Skipped / Total] 151 / 98 / 13 / 262:  30%|â–ˆâ–ˆâ–ˆ       | 262/872 [02:42<06:18,  1.61it/s][Succeeded / Failed / Skipped / Total] 152 / 98 / 13 / 263:  30%|â–ˆâ–ˆâ–ˆ       | 263/872 [02:43<06:17,  1.61it/s][Succeeded / Failed / Skipped / Total] 152 / 98 / 13 / 263:  30%|â–ˆâ–ˆâ–ˆ       | 264/872 [02:43<06:17,  1.61it/s][Succeeded / Failed / Skipped / Total] 152 / 99 / 13 / 264:  30%|â–ˆâ–ˆâ–ˆ       | 264/872 [02:43<06:17,  1.61it/s][Succeeded / Failed / Skipped / Total] 153 / 99 / 13 / 265:  30%|â–ˆâ–ˆâ–ˆ       | 265/872 [02:44<06:16,  1.61it/s][Succeeded / Failed / Skipped / Total] 153 / 99 / 13 / 265:  31%|â–ˆâ–ˆâ–ˆ       | 266/872 [02:44<06:15,  1.61it/s][Succeeded / Failed / Skipped / Total] 154 / 99 / 13 / 266:  31%|â–ˆâ–ˆâ–ˆ       | 266/872 [02:45<06:15,  1.61it/s][Succeeded / Failed / Skipped / Total] 154 / 100 / 13 / 267:  31%|â–ˆâ–ˆâ–ˆ       | 267/872 [02:45<06:15,  1.61it/s][Succeeded / Failed / Skipped / Total] 154 / 100 / 13 / 267:  31%|â–ˆâ–ˆâ–ˆ       | 268/872 [02:46<06:14,  1.61it/s][Succeeded / Failed / Skipped / Total] 155 / 100 / 13 / 268:  31%|â–ˆâ–ˆâ–ˆ       | 268/872 [02:46<06:14,  1.61it/s][Succeeded / Failed / Skipped / Total] 156 / 100 / 13 / 269:  31%|â–ˆâ–ˆâ–ˆ       | 269/872 [02:46<06:14,  1.61it/s][Succeeded / Failed / Skipped / Total] 156 / 100 / 13 / 269:  31%|â–ˆâ–ˆâ–ˆ       | 270/872 [02:47<06:13,  1.61it/s][Succeeded / Failed / Skipped / Total] 157 / 100 / 13 / 270:  31%|â–ˆâ–ˆâ–ˆ       | 270/872 [02:47<06:13,  1.61it/s][Succeeded / Failed / Skipped / Total] 158 / 100 / 13 / 271:  31%|â–ˆâ–ˆâ–ˆ       | 271/872 [02:48<06:13,  1.61it/s][Succeeded / Failed / Skipped / Total] 158 / 100 / 13 / 271:  31%|â–ˆâ–ˆâ–ˆ       | 272/872 [02:48<06:11,  1.62it/s][Succeeded / Failed / Skipped / Total] 158 / 100 / 14 / 272:  31%|â–ˆâ–ˆâ–ˆ       | 272/872 [02:48<06:11,  1.62it/s][Succeeded / Failed / Skipped / Total] 159 / 100 / 14 / 273:  31%|â–ˆâ–ˆâ–ˆâ–      | 273/872 [02:48<06:10,  1.62it/s][Succeeded / Failed / Skipped / Total] 159 / 100 / 14 / 273:  31%|â–ˆâ–ˆâ–ˆâ–      | 274/872 [02:49<06:09,  1.62it/s][Succeeded / Failed / Skipped / Total] 160 / 100 / 14 / 274:  31%|â–ˆâ–ˆâ–ˆâ–      | 274/872 [02:49<06:09,  1.62it/s][Succeeded / Failed / Skipped / Total] 161 / 100 / 14 / 275:  32%|â–ˆâ–ˆâ–ˆâ–      | 275/872 [02:49<06:08,  1.62it/s][Succeeded / Failed / Skipped / Total] 161 / 100 / 14 / 275:  32%|â–ˆâ–ˆâ–ˆâ–      | 276/872 [02:50<06:08,  1.62it/s][Succeeded / Failed / Skipped / Total] 161 / 101 / 14 / 276:  32%|â–ˆâ–ˆâ–ˆâ–      | 276/872 [02:50<06:08,  1.62it/s][Succeeded / Failed / Skipped / Total] 162 / 101 / 14 / 277:  32%|â–ˆâ–ˆâ–ˆâ–      | 277/872 [02:51<06:07,  1.62it/s][Succeeded / Failed / Skipped / Total] 162 / 101 / 14 / 277:  32%|â–ˆâ–ˆâ–ˆâ–      | 278/872 [02:51<06:07,  1.62it/s][Succeeded / Failed / Skipped / Total] 163 / 101 / 14 / 278:  32%|â–ˆâ–ˆâ–ˆâ–      | 278/872 [02:51<06:07,  1.62it/s][Succeeded / Failed / Skipped / Total] 164 / 101 / 14 / 279:  32%|â–ˆâ–ˆâ–ˆâ–      | 279/872 [02:52<06:06,  1.62it/s][Succeeded / Failed / Skipped / Total] 164 / 101 / 14 / 279:  32%|â–ˆâ–ˆâ–ˆâ–      | 280/872 [02:52<06:05,  1.62it/s][Succeeded / Failed / Skipped / Total] 165 / 101 / 14 / 280:  32%|â–ˆâ–ˆâ–ˆâ–      | 280/872 [02:52<06:05,  1.62it/s][Succeeded / Failed / Skipped / Total] 166 / 101 / 14 / 281:  32%|â–ˆâ–ˆâ–ˆâ–      | 281/872 [02:53<06:05,  1.62it/s][Succeeded / Failed / Skipped / Total] 166 / 101 / 14 / 281:  32%|â–ˆâ–ˆâ–ˆâ–      | 282/872 [02:54<06:04,  1.62it/s][Succeeded / Failed / Skipped / Total] 167 / 101 / 14 / 282:  32%|â–ˆâ–ˆâ–ˆâ–      | 282/872 [02:54<06:04,  1.62it/s][Succeeded / Failed / Skipped / Total] 167 / 101 / 15 / 283:  32%|â–ˆâ–ˆâ–ˆâ–      | 283/872 [02:54<06:02,  1.62it/s][Succeeded / Failed / Skipped / Total] 167 / 101 / 15 / 283:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 284/872 [02:54<06:01,  1.63it/s][Succeeded / Failed / Skipped / Total] 168 / 101 / 15 / 284:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 284/872 [02:54<06:01,  1.63it/s][Succeeded / Failed / Skipped / Total] 169 / 101 / 15 / 285:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 285/872 [02:55<06:01,  1.62it/s][Succeeded / Failed / Skipped / Total] 169 / 101 / 15 / 285:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 286/872 [02:55<06:00,  1.63it/s][Succeeded / Failed / Skipped / Total] 170 / 101 / 15 / 286:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 286/872 [02:55<06:00,  1.63it/s][Succeeded / Failed / Skipped / Total] 171 / 101 / 15 / 287:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 287/872 [02:56<05:59,  1.63it/s][Succeeded / Failed / Skipped / Total] 171 / 101 / 15 / 287:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 288/872 [02:57<05:59,  1.62it/s][Succeeded / Failed / Skipped / Total] 171 / 102 / 15 / 288:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 288/872 [02:57<05:59,  1.62it/s][Succeeded / Failed / Skipped / Total] 171 / 103 / 15 / 289:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 289/872 [02:58<05:59,  1.62it/s][Succeeded / Failed / Skipped / Total] 171 / 103 / 15 / 289:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 290/872 [02:58<05:59,  1.62it/s][Succeeded / Failed / Skipped / Total] 171 / 104 / 15 / 290:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 290/872 [02:58<05:59,  1.62it/s][Succeeded / Failed / Skipped / Total] 171 / 105 / 15 / 291:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 291/872 [02:59<05:58,  1.62it/s][Succeeded / Failed / Skipped / Total] 171 / 105 / 15 / 291:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 292/872 [03:00<05:57,  1.62it/s][Succeeded / Failed / Skipped / Total] 172 / 105 / 15 / 292:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 292/872 [03:00<05:57,  1.62it/s][Succeeded / Failed / Skipped / Total] 173 / 105 / 15 / 293:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 293/872 [03:00<05:56,  1.62it/s][Succeeded / Failed / Skipped / Total] 173 / 105 / 15 / 293:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 294/872 [03:01<05:56,  1.62it/s][Succeeded / Failed / Skipped / Total] 173 / 106 / 15 / 294:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 294/872 [03:01<05:56,  1.62it/s][Succeeded / Failed / Skipped / Total] 173 / 107 / 15 / 295:  34%|â–ˆâ–ˆâ–ˆâ–      | 295/872 [03:02<05:56,  1.62it/s][Succeeded / Failed / Skipped / Total] 173 / 107 / 15 / 295:  34%|â–ˆâ–ˆâ–ˆâ–      | 296/872 [03:03<05:56,  1.62it/s][Succeeded / Failed / Skipped / Total] 173 / 108 / 15 / 296:  34%|â–ˆâ–ˆâ–ˆâ–      | 296/872 [03:03<05:56,  1.62it/s][Succeeded / Failed / Skipped / Total] 174 / 108 / 15 / 297:  34%|â–ˆâ–ˆâ–ˆâ–      | 297/872 [03:03<05:55,  1.62it/s][Succeeded / Failed / Skipped / Total] 174 / 108 / 15 / 297:  34%|â–ˆâ–ˆâ–ˆâ–      | 298/872 [03:04<05:54,  1.62it/s][Succeeded / Failed / Skipped / Total] 174 / 109 / 15 / 298:  34%|â–ˆâ–ˆâ–ˆâ–      | 298/872 [03:04<05:54,  1.62it/s][Succeeded / Failed / Skipped / Total] 175 / 109 / 15 / 299:  34%|â–ˆâ–ˆâ–ˆâ–      | 299/872 [03:04<05:53,  1.62it/s][Succeeded / Failed / Skipped / Total] 175 / 109 / 15 / 299:  34%|â–ˆâ–ˆâ–ˆâ–      | 300/872 [03:05<05:53,  1.62it/s][Succeeded / Failed / Skipped / Total] 175 / 110 / 15 / 300:  34%|â–ˆâ–ˆâ–ˆâ–      | 300/872 [03:05<05:53,  1.62it/s][Succeeded / Failed / Skipped / Total] 175 / 111 / 15 / 301:  35%|â–ˆâ–ˆâ–ˆâ–      | 301/872 [03:06<05:53,  1.62it/s][Succeeded / Failed / Skipped / Total] 175 / 111 / 15 / 301:  35%|â–ˆâ–ˆâ–ˆâ–      | 302/872 [03:06<05:52,  1.62it/s][Succeeded / Failed / Skipped / Total] 176 / 111 / 15 / 302:  35%|â–ˆâ–ˆâ–ˆâ–      | 302/872 [03:06<05:52,  1.62it/s][Succeeded / Failed / Skipped / Total] 176 / 112 / 15 / 303:  35%|â–ˆâ–ˆâ–ˆâ–      | 303/872 [03:07<05:52,  1.62it/s][Succeeded / Failed / Skipped / Total] 176 / 112 / 15 / 303:  35%|â–ˆâ–ˆâ–ˆâ–      | 304/872 [03:08<05:51,  1.62it/s][Succeeded / Failed / Skipped / Total] 176 / 113 / 15 / 304:  35%|â–ˆâ–ˆâ–ˆâ–      | 304/872 [03:08<05:51,  1.62it/s][Succeeded / Failed / Skipped / Total] 176 / 114 / 15 / 305:  35%|â–ˆâ–ˆâ–ˆâ–      | 305/872 [03:09<05:51,  1.61it/s][Succeeded / Failed / Skipped / Total] 176 / 114 / 15 / 305:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 306/872 [03:09<05:50,  1.61it/s][Succeeded / Failed / Skipped / Total] 177 / 114 / 15 / 306:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 306/872 [03:09<05:50,  1.61it/s][Succeeded / Failed / Skipped / Total] 177 / 115 / 15 / 307:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 307/872 [03:10<05:50,  1.61it/s][Succeeded / Failed / Skipped / Total] 177 / 115 / 15 / 307:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 308/872 [03:11<05:50,  1.61it/s][Succeeded / Failed / Skipped / Total] 177 / 116 / 15 / 308:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 308/872 [03:11<05:50,  1.61it/s][Succeeded / Failed / Skipped / Total] 177 / 116 / 16 / 309:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 309/872 [03:11<05:48,  1.62it/s][Succeeded / Failed / Skipped / Total] 177 / 116 / 16 / 309:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 310/872 [03:11<05:47,  1.62it/s][Succeeded / Failed / Skipped / Total] 178 / 116 / 16 / 310:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 310/872 [03:11<05:47,  1.62it/s][Succeeded / Failed / Skipped / Total] 179 / 116 / 16 / 311:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 311/872 [03:12<05:47,  1.61it/s][Succeeded / Failed / Skipped / Total] 179 / 116 / 16 / 311:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 312/872 [03:13<05:46,  1.61it/s][Succeeded / Failed / Skipped / Total] 179 / 117 / 16 / 312:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 312/872 [03:13<05:46,  1.61it/s][Succeeded / Failed / Skipped / Total] 180 / 117 / 16 / 313:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 313/872 [03:13<05:45,  1.62it/s][Succeeded / Failed / Skipped / Total] 180 / 117 / 16 / 313:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 314/872 [03:14<05:45,  1.61it/s][Succeeded / Failed / Skipped / Total] 180 / 118 / 16 / 314:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 314/872 [03:14<05:45,  1.61it/s][Succeeded / Failed / Skipped / Total] 180 / 119 / 16 / 315:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 315/872 [03:15<05:45,  1.61it/s][Succeeded / Failed / Skipped / Total] 180 / 119 / 16 / 315:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 316/872 [03:15<05:44,  1.61it/s][Succeeded / Failed / Skipped / Total] 181 / 119 / 16 / 316:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 316/872 [03:15<05:44,  1.61it/s][Succeeded / Failed / Skipped / Total] 181 / 120 / 16 / 317:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 317/872 [03:16<05:44,  1.61it/s][Succeeded / Failed / Skipped / Total] 181 / 120 / 16 / 317:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 318/872 [03:17<05:44,  1.61it/s][Succeeded / Failed / Skipped / Total] 181 / 121 / 16 / 318:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 318/872 [03:17<05:44,  1.61it/s][Succeeded / Failed / Skipped / Total] 182 / 121 / 16 / 319:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 319/872 [03:17<05:43,  1.61it/s][Succeeded / Failed / Skipped / Total] 182 / 121 / 16 / 319:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 320/872 [03:18<05:42,  1.61it/s][Succeeded / Failed / Skipped / Total] 183 / 121 / 16 / 320:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 320/872 [03:18<05:42,  1.61it/s][Succeeded / Failed / Skipped / Total] 183 / 122 / 16 / 321:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 321/872 [03:19<05:42,  1.61it/s][Succeeded / Failed / Skipped / Total] 183 / 122 / 16 / 321:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 322/872 [03:19<05:40,  1.62it/s][Succeeded / Failed / Skipped / Total] 183 / 122 / 17 / 322:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 322/872 [03:19<05:40,  1.62it/s][Succeeded / Failed / Skipped / Total] 184 / 122 / 17 / 323:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 323/872 [03:19<05:39,  1.62it/s][Succeeded / Failed / Skipped / Total] 184 / 122 / 17 / 323:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 324/872 [03:20<05:38,  1.62it/s][Succeeded / Failed / Skipped / Total] 185 / 122 / 17 / 324:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 324/872 [03:20<05:38,  1.62it/s][Succeeded / Failed / Skipped / Total] 186 / 122 / 17 / 325:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 325/872 [03:21<05:38,  1.62it/s][Succeeded / Failed / Skipped / Total] 186 / 122 / 17 / 325:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 326/872 [03:21<05:37,  1.62it/s][Succeeded / Failed / Skipped / Total] 186 / 123 / 17 / 326:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 326/872 [03:21<05:38,  1.62it/s][Succeeded / Failed / Skipped / Total] 186 / 124 / 17 / 327:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 327/872 [03:22<05:37,  1.61it/s][Succeeded / Failed / Skipped / Total] 186 / 124 / 17 / 327:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 328/872 [03:23<05:37,  1.61it/s][Succeeded / Failed / Skipped / Total] 187 / 124 / 17 / 328:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 328/872 [03:23<05:37,  1.61it/s][Succeeded / Failed / Skipped / Total] 188 / 124 / 17 / 329:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 329/872 [03:23<05:36,  1.61it/s][Succeeded / Failed / Skipped / Total] 188 / 124 / 17 / 329:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 330/872 [03:24<05:35,  1.61it/s][Succeeded / Failed / Skipped / Total] 189 / 124 / 17 / 330:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 330/872 [03:24<05:35,  1.61it/s][Succeeded / Failed / Skipped / Total] 190 / 124 / 17 / 331:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 331/872 [03:24<05:34,  1.62it/s][Succeeded / Failed / Skipped / Total] 190 / 124 / 17 / 331:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 332/872 [03:25<05:34,  1.62it/s][Succeeded / Failed / Skipped / Total] 191 / 124 / 17 / 332:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 332/872 [03:25<05:34,  1.62it/s][Succeeded / Failed / Skipped / Total] 192 / 124 / 17 / 333:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 333/872 [03:26<05:33,  1.61it/s][Succeeded / Failed / Skipped / Total] 192 / 124 / 17 / 333:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 334/872 [03:26<05:33,  1.61it/s][Succeeded / Failed / Skipped / Total] 193 / 124 / 17 / 334:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 334/872 [03:26<05:33,  1.61it/s][Succeeded / Failed / Skipped / Total] 193 / 125 / 17 / 335:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 335/872 [03:27<05:32,  1.61it/s][Succeeded / Failed / Skipped / Total] 193 / 125 / 17 / 335:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 336/872 [03:28<05:32,  1.61it/s][Succeeded / Failed / Skipped / Total] 194 / 125 / 17 / 336:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 336/872 [03:28<05:32,  1.61it/s][Succeeded / Failed / Skipped / Total] 194 / 126 / 17 / 337:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 337/872 [03:29<05:32,  1.61it/s][Succeeded / Failed / Skipped / Total] 194 / 126 / 17 / 337:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 338/872 [03:29<05:31,  1.61it/s][Succeeded / Failed / Skipped / Total] 195 / 126 / 17 / 338:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 338/872 [03:29<05:31,  1.61it/s][Succeeded / Failed / Skipped / Total] 196 / 126 / 17 / 339:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 339/872 [03:30<05:30,  1.61it/s][Succeeded / Failed / Skipped / Total] 196 / 126 / 17 / 339:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 340/872 [03:31<05:30,  1.61it/s][Succeeded / Failed / Skipped / Total] 196 / 127 / 17 / 340:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 340/872 [03:31<05:30,  1.61it/s][Succeeded / Failed / Skipped / Total] 197 / 127 / 17 / 341:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 341/872 [03:31<05:29,  1.61it/s][Succeeded / Failed / Skipped / Total] 197 / 127 / 17 / 341:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 342/872 [03:32<05:29,  1.61it/s][Succeeded / Failed / Skipped / Total] 197 / 128 / 17 / 342:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 342/872 [03:32<05:29,  1.61it/s][Succeeded / Failed / Skipped / Total] 198 / 128 / 17 / 343:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 343/872 [03:33<05:28,  1.61it/s][Succeeded / Failed / Skipped / Total] 198 / 128 / 17 / 343:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 344/872 [03:33<05:28,  1.61it/s][Succeeded / Failed / Skipped / Total] 199 / 128 / 17 / 344:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 344/872 [03:33<05:28,  1.61it/s][Succeeded / Failed / Skipped / Total] 199 / 129 / 17 / 345:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 345/872 [03:34<05:27,  1.61it/s][Succeeded / Failed / Skipped / Total] 199 / 129 / 17 / 345:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 346/872 [03:35<05:27,  1.61it/s][Succeeded / Failed / Skipped / Total] 199 / 130 / 17 / 346:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 346/872 [03:35<05:27,  1.61it/s][Succeeded / Failed / Skipped / Total] 200 / 130 / 17 / 347:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 347/872 [03:36<05:26,  1.61it/s][Succeeded / Failed / Skipped / Total] 200 / 130 / 17 / 347:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 348/872 [03:36<05:26,  1.61it/s][Succeeded / Failed / Skipped / Total] 201 / 130 / 17 / 348:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 348/872 [03:36<05:26,  1.61it/s][Succeeded / Failed / Skipped / Total] 202 / 130 / 17 / 349:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 349/872 [03:37<05:25,  1.61it/s][Succeeded / Failed / Skipped / Total] 202 / 130 / 17 / 349:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 350/872 [03:37<05:25,  1.61it/s][Succeeded / Failed / Skipped / Total] 203 / 130 / 17 / 350:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 350/872 [03:37<05:25,  1.61it/s][Succeeded / Failed / Skipped / Total] 204 / 130 / 17 / 351:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 351/872 [03:38<05:24,  1.61it/s][Succeeded / Failed / Skipped / Total] 204 / 130 / 17 / 351:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 352/872 [03:39<05:24,  1.60it/s][Succeeded / Failed / Skipped / Total] 204 / 131 / 17 / 352:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 352/872 [03:39<05:24,  1.60it/s][Succeeded / Failed / Skipped / Total] 204 / 132 / 17 / 353:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 353/872 [03:40<05:23,  1.60it/s][Succeeded / Failed / Skipped / Total] 204 / 132 / 17 / 353:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 354/872 [03:40<05:23,  1.60it/s][Succeeded / Failed / Skipped / Total] 204 / 133 / 17 / 354:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 354/872 [03:40<05:23,  1.60it/s][Succeeded / Failed / Skipped / Total] 204 / 134 / 17 / 355:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 355/872 [03:41<05:22,  1.60it/s][Succeeded / Failed / Skipped / Total] 204 / 134 / 17 / 355:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 356/872 [03:42<05:21,  1.60it/s][Succeeded / Failed / Skipped / Total] 205 / 134 / 17 / 356:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 356/872 [03:42<05:22,  1.60it/s][Succeeded / Failed / Skipped / Total] 206 / 134 / 17 / 357:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 357/872 [03:42<05:21,  1.60it/s][Succeeded / Failed / Skipped / Total] 206 / 134 / 17 / 357:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 358/872 [03:43<05:20,  1.61it/s][Succeeded / Failed / Skipped / Total] 207 / 134 / 17 / 358:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 358/872 [03:43<05:20,  1.60it/s][Succeeded / Failed / Skipped / Total] 208 / 134 / 17 / 359:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 359/872 [03:43<05:19,  1.60it/s][Succeeded / Failed / Skipped / Total] 208 / 134 / 17 / 359:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 360/872 [03:44<05:19,  1.60it/s][Succeeded / Failed / Skipped / Total] 208 / 135 / 17 / 360:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 360/872 [03:44<05:19,  1.60it/s][Succeeded / Failed / Skipped / Total] 208 / 136 / 17 / 361:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 361/872 [03:45<05:18,  1.60it/s][Succeeded / Failed / Skipped / Total] 208 / 136 / 17 / 361:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 362/872 [03:45<05:18,  1.60it/s][Succeeded / Failed / Skipped / Total] 209 / 136 / 17 / 362:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 362/872 [03:46<05:18,  1.60it/s][Succeeded / Failed / Skipped / Total] 209 / 137 / 17 / 363:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 363/872 [03:46<05:18,  1.60it/s][Succeeded / Failed / Skipped / Total] 209 / 137 / 17 / 363:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 364/872 [03:47<05:17,  1.60it/s][Succeeded / Failed / Skipped / Total] 210 / 137 / 17 / 364:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 364/872 [03:47<05:17,  1.60it/s][Succeeded / Failed / Skipped / Total] 211 / 137 / 17 / 365:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 365/872 [03:47<05:16,  1.60it/s][Succeeded / Failed / Skipped / Total] 211 / 137 / 17 / 365:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 366/872 [03:48<05:15,  1.60it/s][Succeeded / Failed / Skipped / Total] 212 / 137 / 17 / 366:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 366/872 [03:48<05:15,  1.60it/s][Succeeded / Failed / Skipped / Total] 212 / 138 / 17 / 367:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 367/872 [03:49<05:15,  1.60it/s][Succeeded / Failed / Skipped / Total] 212 / 138 / 17 / 367:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 368/872 [03:49<05:14,  1.60it/s][Succeeded / Failed / Skipped / Total] 212 / 139 / 17 / 368:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 368/872 [03:49<05:14,  1.60it/s][Succeeded / Failed / Skipped / Total] 213 / 139 / 17 / 369:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 369/872 [03:50<05:14,  1.60it/s][Succeeded / Failed / Skipped / Total] 213 / 139 / 17 / 369:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 370/872 [03:51<05:13,  1.60it/s][Succeeded / Failed / Skipped / Total] 213 / 140 / 17 / 370:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 370/872 [03:51<05:13,  1.60it/s][Succeeded / Failed / Skipped / Total] 214 / 140 / 17 / 371:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 371/872 [03:51<05:13,  1.60it/s][Succeeded / Failed / Skipped / Total] 214 / 140 / 17 / 371:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 372/872 [03:52<05:12,  1.60it/s][Succeeded / Failed / Skipped / Total] 214 / 141 / 17 / 372:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 372/872 [03:52<05:12,  1.60it/s][Succeeded / Failed / Skipped / Total] 214 / 142 / 17 / 373:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 373/872 [03:53<05:12,  1.60it/s][Succeeded / Failed / Skipped / Total] 214 / 142 / 17 / 373:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 374/872 [03:54<05:11,  1.60it/s][Succeeded / Failed / Skipped / Total] 215 / 142 / 17 / 374:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 374/872 [03:54<05:11,  1.60it/s][Succeeded / Failed / Skipped / Total] 216 / 142 / 17 / 375:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 375/872 [03:54<05:11,  1.60it/s][Succeeded / Failed / Skipped / Total] 216 / 142 / 17 / 375:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 376/872 [03:55<05:10,  1.60it/s][Succeeded / Failed / Skipped / Total] 216 / 143 / 17 / 376:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 376/872 [03:55<05:10,  1.60it/s][Succeeded / Failed / Skipped / Total] 217 / 143 / 17 / 377:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 377/872 [03:55<05:09,  1.60it/s][Succeeded / Failed / Skipped / Total] 217 / 143 / 17 / 377:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 378/872 [03:56<05:08,  1.60it/s][Succeeded / Failed / Skipped / Total] 218 / 143 / 17 / 378:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 378/872 [03:56<05:08,  1.60it/s][Succeeded / Failed / Skipped / Total] 219 / 143 / 17 / 379:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 379/872 [03:56<05:08,  1.60it/s][Succeeded / Failed / Skipped / Total] 219 / 143 / 17 / 379:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 380/872 [03:57<05:07,  1.60it/s][Succeeded / Failed / Skipped / Total] 220 / 143 / 17 / 380:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 380/872 [03:57<05:07,  1.60it/s][Succeeded / Failed / Skipped / Total] 221 / 143 / 17 / 381:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 381/872 [03:58<05:06,  1.60it/s][Succeeded / Failed / Skipped / Total] 221 / 143 / 17 / 381:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 382/872 [03:58<05:06,  1.60it/s][Succeeded / Failed / Skipped / Total] 221 / 144 / 17 / 382:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 382/872 [03:58<05:06,  1.60it/s][Succeeded / Failed / Skipped / Total] 222 / 144 / 17 / 383:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 383/872 [03:59<05:05,  1.60it/s][Succeeded / Failed / Skipped / Total] 222 / 144 / 17 / 383:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 384/872 [04:00<05:05,  1.60it/s][Succeeded / Failed / Skipped / Total] 222 / 145 / 17 / 384:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 384/872 [04:00<05:05,  1.60it/s][Succeeded / Failed / Skipped / Total] 223 / 145 / 17 / 385:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 385/872 [04:00<05:04,  1.60it/s][Succeeded / Failed / Skipped / Total] 223 / 145 / 17 / 385:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 386/872 [04:00<05:02,  1.60it/s][Succeeded / Failed / Skipped / Total] 223 / 145 / 18 / 386:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 386/872 [04:00<05:02,  1.60it/s][Succeeded / Failed / Skipped / Total] 223 / 146 / 18 / 387:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 387/872 [04:01<05:02,  1.60it/s][Succeeded / Failed / Skipped / Total] 223 / 146 / 18 / 387:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 388/872 [04:02<05:02,  1.60it/s][Succeeded / Failed / Skipped / Total] 223 / 147 / 18 / 388:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 388/872 [04:02<05:02,  1.60it/s][Succeeded / Failed / Skipped / Total] 224 / 147 / 18 / 389:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 389/872 [04:02<05:01,  1.60it/s][Succeeded / Failed / Skipped / Total] 224 / 147 / 18 / 389:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 390/872 [04:03<05:00,  1.60it/s][Succeeded / Failed / Skipped / Total] 225 / 147 / 18 / 390:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 390/872 [04:03<05:00,  1.60it/s][Succeeded / Failed / Skipped / Total] 226 / 147 / 18 / 391:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 391/872 [04:03<04:59,  1.60it/s][Succeeded / Failed / Skipped / Total] 226 / 147 / 18 / 391:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 392/872 [04:04<04:59,  1.60it/s][Succeeded / Failed / Skipped / Total] 227 / 147 / 18 / 392:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 392/872 [04:04<04:59,  1.60it/s][Succeeded / Failed / Skipped / Total] 228 / 147 / 18 / 393:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 393/872 [04:04<04:58,  1.60it/s][Succeeded / Failed / Skipped / Total] 228 / 147 / 18 / 393:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 394/872 [04:05<04:58,  1.60it/s][Succeeded / Failed / Skipped / Total] 228 / 148 / 18 / 394:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 394/872 [04:05<04:58,  1.60it/s][Succeeded / Failed / Skipped / Total] 228 / 149 / 18 / 395:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 395/872 [04:06<04:57,  1.60it/s][Succeeded / Failed / Skipped / Total] 228 / 149 / 18 / 395:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 396/872 [04:07<04:57,  1.60it/s][Succeeded / Failed / Skipped / Total] 229 / 149 / 18 / 396:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 396/872 [04:07<04:57,  1.60it/s][Succeeded / Failed / Skipped / Total] 229 / 150 / 18 / 397:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 397/872 [04:07<04:56,  1.60it/s][Succeeded / Failed / Skipped / Total] 229 / 150 / 18 / 397:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 398/872 [04:08<04:56,  1.60it/s][Succeeded / Failed / Skipped / Total] 229 / 151 / 18 / 398:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 398/872 [04:08<04:56,  1.60it/s][Succeeded / Failed / Skipped / Total] 230 / 151 / 18 / 399:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 399/872 [04:09<04:55,  1.60it/s][Succeeded / Failed / Skipped / Total] 230 / 151 / 18 / 399:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 400/872 [04:09<04:54,  1.60it/s][Succeeded / Failed / Skipped / Total] 230 / 151 / 19 / 400:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 400/872 [04:09<04:54,  1.60it/s][Succeeded / Failed / Skipped / Total] 231 / 151 / 19 / 401:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 401/872 [04:10<04:53,  1.60it/s][Succeeded / Failed / Skipped / Total] 231 / 151 / 19 / 401:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 402/872 [04:10<04:53,  1.60it/s][Succeeded / Failed / Skipped / Total] 231 / 152 / 19 / 402:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 402/872 [04:10<04:53,  1.60it/s][Succeeded / Failed / Skipped / Total] 232 / 152 / 19 / 403:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 403/872 [04:11<04:52,  1.60it/s][Succeeded / Failed / Skipped / Total] 232 / 152 / 19 / 403:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 404/872 [04:11<04:51,  1.60it/s][Succeeded / Failed / Skipped / Total] 233 / 152 / 19 / 404:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 404/872 [04:11<04:51,  1.60it/s][Succeeded / Failed / Skipped / Total] 233 / 153 / 19 / 405:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 405/872 [04:12<04:51,  1.60it/s][Succeeded / Failed / Skipped / Total] 233 / 153 / 19 / 405:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 406/872 [04:13<04:50,  1.60it/s][Succeeded / Failed / Skipped / Total] 234 / 153 / 19 / 406:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 406/872 [04:13<04:50,  1.60it/s][Succeeded / Failed / Skipped / Total] 234 / 154 / 19 / 407:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 407/872 [04:14<04:50,  1.60it/s][Succeeded / Failed / Skipped / Total] 234 / 154 / 19 / 407:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 408/872 [04:14<04:49,  1.60it/s][Succeeded / Failed / Skipped / Total] 235 / 154 / 19 / 408:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 408/872 [04:14<04:49,  1.60it/s][Succeeded / Failed / Skipped / Total] 236 / 154 / 19 / 409:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 409/872 [04:15<04:48,  1.60it/s][Succeeded / Failed / Skipped / Total] 236 / 154 / 19 / 409:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 410/872 [04:15<04:48,  1.60it/s][Succeeded / Failed / Skipped / Total] 237 / 154 / 19 / 410:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 410/872 [04:15<04:48,  1.60it/s][Succeeded / Failed / Skipped / Total] 237 / 155 / 19 / 411:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 411/872 [04:16<04:47,  1.60it/s][Succeeded / Failed / Skipped / Total] 237 / 155 / 19 / 411:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 412/872 [04:17<04:47,  1.60it/s][Succeeded / Failed / Skipped / Total] 238 / 155 / 19 / 412:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 412/872 [04:17<04:47,  1.60it/s][Succeeded / Failed / Skipped / Total] 239 / 155 / 19 / 413:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 413/872 [04:17<04:46,  1.60it/s][Succeeded / Failed / Skipped / Total] 239 / 155 / 19 / 413:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 414/872 [04:17<04:45,  1.61it/s][Succeeded / Failed / Skipped / Total] 240 / 155 / 19 / 414:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 414/872 [04:17<04:45,  1.60it/s][Succeeded / Failed / Skipped / Total] 241 / 155 / 19 / 415:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 415/872 [04:18<04:44,  1.60it/s][Succeeded / Failed / Skipped / Total] 241 / 155 / 19 / 415:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 416/872 [04:19<04:44,  1.60it/s][Succeeded / Failed / Skipped / Total] 242 / 155 / 19 / 416:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 416/872 [04:19<04:44,  1.60it/s][Succeeded / Failed / Skipped / Total] 243 / 155 / 19 / 417:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 417/872 [04:19<04:43,  1.60it/s][Succeeded / Failed / Skipped / Total] 243 / 155 / 19 / 417:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 418/872 [04:20<04:43,  1.60it/s][Succeeded / Failed / Skipped / Total] 243 / 156 / 19 / 418:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 418/872 [04:20<04:43,  1.60it/s][Succeeded / Failed / Skipped / Total] 243 / 157 / 19 / 419:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 419/872 [04:21<04:42,  1.60it/s][Succeeded / Failed / Skipped / Total] 243 / 157 / 19 / 419:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 420/872 [04:22<04:42,  1.60it/s][Succeeded / Failed / Skipped / Total] 244 / 157 / 19 / 420:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 420/872 [04:22<04:42,  1.60it/s][Succeeded / Failed / Skipped / Total] 245 / 157 / 19 / 421:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 421/872 [04:22<04:41,  1.60it/s][Succeeded / Failed / Skipped / Total] 245 / 157 / 19 / 421:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 422/872 [04:23<04:41,  1.60it/s][Succeeded / Failed / Skipped / Total] 245 / 158 / 19 / 422:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 422/872 [04:23<04:41,  1.60it/s][Succeeded / Failed / Skipped / Total] 246 / 158 / 19 / 423:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 423/872 [04:24<04:40,  1.60it/s][Succeeded / Failed / Skipped / Total] 246 / 158 / 19 / 423:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 424/872 [04:24<04:39,  1.60it/s][Succeeded / Failed / Skipped / Total] 246 / 158 / 20 / 424:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 424/872 [04:24<04:39,  1.60it/s][Succeeded / Failed / Skipped / Total] 246 / 159 / 20 / 425:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 425/872 [04:25<04:39,  1.60it/s][Succeeded / Failed / Skipped / Total] 246 / 159 / 20 / 425:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 426/872 [04:26<04:38,  1.60it/s][Succeeded / Failed / Skipped / Total] 246 / 160 / 20 / 426:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 426/872 [04:26<04:38,  1.60it/s][Succeeded / Failed / Skipped / Total] 246 / 161 / 20 / 427:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 427/872 [04:26<04:38,  1.60it/s][Succeeded / Failed / Skipped / Total] 246 / 161 / 20 / 427:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 428/872 [04:27<04:37,  1.60it/s][Succeeded / Failed / Skipped / Total] 246 / 162 / 20 / 428:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 428/872 [04:27<04:37,  1.60it/s][Succeeded / Failed / Skipped / Total] 246 / 163 / 20 / 429:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 429/872 [04:28<04:37,  1.60it/s][Succeeded / Failed / Skipped / Total] 246 / 163 / 20 / 429:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 430/872 [04:29<04:36,  1.60it/s][Succeeded / Failed / Skipped / Total] 247 / 163 / 20 / 430:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 430/872 [04:29<04:36,  1.60it/s][Succeeded / Failed / Skipped / Total] 247 / 164 / 20 / 431:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 431/872 [04:30<04:36,  1.60it/s][Succeeded / Failed / Skipped / Total] 247 / 164 / 20 / 431:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 432/872 [04:30<04:35,  1.60it/s][Succeeded / Failed / Skipped / Total] 248 / 164 / 20 / 432:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 432/872 [04:30<04:35,  1.60it/s][Succeeded / Failed / Skipped / Total] 249 / 164 / 20 / 433:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 433/872 [04:30<04:34,  1.60it/s][Succeeded / Failed / Skipped / Total] 249 / 164 / 20 / 433:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 434/872 [04:31<04:34,  1.60it/s][Succeeded / Failed / Skipped / Total] 249 / 165 / 20 / 434:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 434/872 [04:31<04:34,  1.60it/s][Succeeded / Failed / Skipped / Total] 250 / 165 / 20 / 435:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 435/872 [04:32<04:33,  1.60it/s][Succeeded / Failed / Skipped / Total] 250 / 165 / 20 / 435:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 436/872 [04:32<04:32,  1.60it/s][Succeeded / Failed / Skipped / Total] 250 / 166 / 20 / 436:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 436/872 [04:32<04:32,  1.60it/s][Succeeded / Failed / Skipped / Total] 251 / 166 / 20 / 437:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 437/872 [04:33<04:32,  1.60it/s][Succeeded / Failed / Skipped / Total] 251 / 166 / 20 / 437:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 438/872 [04:34<04:31,  1.60it/s][Succeeded / Failed / Skipped / Total] 251 / 167 / 20 / 438:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 438/872 [04:34<04:31,  1.60it/s][Succeeded / Failed / Skipped / Total] 251 / 168 / 20 / 439:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 439/872 [04:35<04:31,  1.60it/s][Succeeded / Failed / Skipped / Total] 251 / 168 / 20 / 439:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 440/872 [04:35<04:30,  1.59it/s][Succeeded / Failed / Skipped / Total] 251 / 169 / 20 / 440:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 440/872 [04:35<04:30,  1.59it/s][Succeeded / Failed / Skipped / Total] 252 / 169 / 20 / 441:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 441/872 [04:36<04:30,  1.59it/s][Succeeded / Failed / Skipped / Total] 252 / 169 / 20 / 441:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 442/872 [04:37<04:30,  1.59it/s][Succeeded / Failed / Skipped / Total] 253 / 169 / 20 / 442:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 442/872 [04:37<04:30,  1.59it/s][Succeeded / Failed / Skipped / Total] 254 / 169 / 20 / 443:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 443/872 [04:38<04:29,  1.59it/s][Succeeded / Failed / Skipped / Total] 254 / 169 / 20 / 443:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 444/872 [04:39<04:29,  1.59it/s][Succeeded / Failed / Skipped / Total] 254 / 170 / 20 / 444:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 444/872 [04:39<04:29,  1.59it/s][Succeeded / Failed / Skipped / Total] 255 / 170 / 20 / 445:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 445/872 [04:39<04:28,  1.59it/s][Succeeded / Failed / Skipped / Total] 255 / 170 / 20 / 445:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 446/872 [04:40<04:27,  1.59it/s][Succeeded / Failed / Skipped / Total] 256 / 170 / 20 / 446:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 446/872 [04:40<04:28,  1.59it/s][Succeeded / Failed / Skipped / Total] 257 / 170 / 20 / 447:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 447/872 [04:41<04:27,  1.59it/s][Succeeded / Failed / Skipped / Total] 257 / 170 / 20 / 447:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 448/872 [04:41<04:26,  1.59it/s][Succeeded / Failed / Skipped / Total] 258 / 170 / 20 / 448:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 448/872 [04:41<04:26,  1.59it/s][Succeeded / Failed / Skipped / Total] 259 / 170 / 20 / 449:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 449/872 [04:42<04:26,  1.59it/s][Succeeded / Failed / Skipped / Total] 259 / 170 / 20 / 449:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 450/872 [04:42<04:25,  1.59it/s][Succeeded / Failed / Skipped / Total] 260 / 170 / 20 / 450:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 450/872 [04:42<04:25,  1.59it/s][Succeeded / Failed / Skipped / Total] 260 / 171 / 20 / 451:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 451/872 [04:43<04:24,  1.59it/s][Succeeded / Failed / Skipped / Total] 260 / 171 / 20 / 451:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 452/872 [04:44<04:24,  1.59it/s][Succeeded / Failed / Skipped / Total] 260 / 172 / 20 / 452:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 452/872 [04:44<04:24,  1.59it/s][Succeeded / Failed / Skipped / Total] 261 / 172 / 20 / 453:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 453/872 [04:45<04:23,  1.59it/s][Succeeded / Failed / Skipped / Total] 261 / 172 / 20 / 453:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 454/872 [04:45<04:23,  1.59it/s][Succeeded / Failed / Skipped / Total] 261 / 173 / 20 / 454:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 454/872 [04:45<04:23,  1.59it/s][Succeeded / Failed / Skipped / Total] 262 / 173 / 20 / 455:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 455/872 [04:46<04:22,  1.59it/s][Succeeded / Failed / Skipped / Total] 262 / 173 / 20 / 455:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 456/872 [04:47<04:22,  1.59it/s][Succeeded / Failed / Skipped / Total] 262 / 174 / 20 / 456:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 456/872 [04:47<04:22,  1.59it/s][Succeeded / Failed / Skipped / Total] 263 / 174 / 20 / 457:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 457/872 [04:48<04:21,  1.59it/s][Succeeded / Failed / Skipped / Total] 263 / 174 / 20 / 457:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 458/872 [04:48<04:21,  1.59it/s][Succeeded / Failed / Skipped / Total] 263 / 175 / 20 / 458:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 458/872 [04:48<04:21,  1.59it/s][Succeeded / Failed / Skipped / Total] 263 / 176 / 20 / 459:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 459/872 [04:49<04:20,  1.58it/s][Succeeded / Failed / Skipped / Total] 263 / 176 / 20 / 459:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 460/872 [04:50<04:20,  1.58it/s][Succeeded / Failed / Skipped / Total] 263 / 177 / 20 / 460:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 460/872 [04:50<04:20,  1.58it/s][Succeeded / Failed / Skipped / Total] 263 / 178 / 20 / 461:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 461/872 [04:51<04:19,  1.58it/s][Succeeded / Failed / Skipped / Total] 263 / 178 / 20 / 461:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 462/872 [04:51<04:19,  1.58it/s][Succeeded / Failed / Skipped / Total] 264 / 178 / 20 / 462:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 462/872 [04:51<04:19,  1.58it/s][Succeeded / Failed / Skipped / Total] 265 / 178 / 20 / 463:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 463/872 [04:52<04:18,  1.58it/s][Succeeded / Failed / Skipped / Total] 265 / 178 / 20 / 463:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 464/872 [04:53<04:17,  1.58it/s][Succeeded / Failed / Skipped / Total] 266 / 178 / 20 / 464:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 464/872 [04:53<04:17,  1.58it/s][Succeeded / Failed / Skipped / Total] 266 / 178 / 21 / 465:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 465/872 [04:53<04:16,  1.59it/s][Succeeded / Failed / Skipped / Total] 266 / 178 / 21 / 465:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 466/872 [04:53<04:15,  1.59it/s][Succeeded / Failed / Skipped / Total] 267 / 178 / 21 / 466:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 466/872 [04:53<04:15,  1.59it/s][Succeeded / Failed / Skipped / Total] 267 / 179 / 21 / 467:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 467/872 [04:54<04:15,  1.59it/s][Succeeded / Failed / Skipped / Total] 267 / 179 / 21 / 467:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 468/872 [04:55<04:14,  1.58it/s][Succeeded / Failed / Skipped / Total] 267 / 180 / 21 / 468:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 468/872 [04:55<04:14,  1.58it/s][Succeeded / Failed / Skipped / Total] 268 / 180 / 21 / 469:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 469/872 [04:55<04:14,  1.58it/s][Succeeded / Failed / Skipped / Total] 268 / 180 / 21 / 469:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 470/872 [04:56<04:13,  1.58it/s][Succeeded / Failed / Skipped / Total] 269 / 180 / 21 / 470:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 470/872 [04:56<04:13,  1.58it/s][Succeeded / Failed / Skipped / Total] 270 / 180 / 21 / 471:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 471/872 [04:57<04:13,  1.58it/s][Succeeded / Failed / Skipped / Total] 270 / 180 / 21 / 471:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 472/872 [04:57<04:12,  1.58it/s][Succeeded / Failed / Skipped / Total] 271 / 180 / 21 / 472:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 472/872 [04:57<04:12,  1.58it/s][Succeeded / Failed / Skipped / Total] 272 / 180 / 21 / 473:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 473/872 [04:58<04:11,  1.58it/s][Succeeded / Failed / Skipped / Total] 272 / 180 / 21 / 473:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 474/872 [04:59<04:11,  1.58it/s][Succeeded / Failed / Skipped / Total] 272 / 181 / 21 / 474:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 474/872 [04:59<04:11,  1.58it/s][Succeeded / Failed / Skipped / Total] 273 / 181 / 21 / 475:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 475/872 [04:59<04:10,  1.58it/s][Succeeded / Failed / Skipped / Total] 273 / 181 / 21 / 475:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 476/872 [05:00<04:10,  1.58it/s][Succeeded / Failed / Skipped / Total] 273 / 182 / 21 / 476:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 476/872 [05:00<04:10,  1.58it/s][Succeeded / Failed / Skipped / Total] 274 / 182 / 21 / 477:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 477/872 [05:01<04:09,  1.58it/s][Succeeded / Failed / Skipped / Total] 274 / 182 / 21 / 477:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 478/872 [05:01<04:08,  1.59it/s][Succeeded / Failed / Skipped / Total] 275 / 182 / 21 / 478:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 478/872 [05:01<04:08,  1.58it/s][Succeeded / Failed / Skipped / Total] 276 / 182 / 21 / 479:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 479/872 [05:02<04:07,  1.59it/s][Succeeded / Failed / Skipped / Total] 276 / 182 / 21 / 479:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 480/872 [05:02<04:07,  1.59it/s][Succeeded / Failed / Skipped / Total] 276 / 183 / 21 / 480:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 480/872 [05:02<04:07,  1.59it/s][Succeeded / Failed / Skipped / Total] 276 / 184 / 21 / 481:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 481/872 [05:03<04:06,  1.58it/s][Succeeded / Failed / Skipped / Total] 276 / 184 / 21 / 481:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 482/872 [05:03<04:05,  1.59it/s][Succeeded / Failed / Skipped / Total] 276 / 184 / 22 / 482:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 482/872 [05:03<04:05,  1.59it/s][Succeeded / Failed / Skipped / Total] 276 / 185 / 22 / 483:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 483/872 [05:04<04:05,  1.59it/s][Succeeded / Failed / Skipped / Total] 276 / 185 / 22 / 483:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 484/872 [05:05<04:04,  1.59it/s][Succeeded / Failed / Skipped / Total] 277 / 185 / 22 / 484:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 484/872 [05:05<04:04,  1.59it/s][Succeeded / Failed / Skipped / Total] 277 / 186 / 22 / 485:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 485/872 [05:06<04:04,  1.58it/s][Succeeded / Failed / Skipped / Total] 277 / 186 / 22 / 485:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 486/872 [05:06<04:03,  1.58it/s][Succeeded / Failed / Skipped / Total] 277 / 187 / 22 / 486:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 486/872 [05:06<04:03,  1.58it/s][Succeeded / Failed / Skipped / Total] 278 / 187 / 22 / 487:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 487/872 [05:07<04:03,  1.58it/s][Succeeded / Failed / Skipped / Total] 278 / 187 / 22 / 487:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 488/872 [05:07<04:02,  1.58it/s][Succeeded / Failed / Skipped / Total] 279 / 187 / 22 / 488:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 488/872 [05:07<04:02,  1.58it/s][Succeeded / Failed / Skipped / Total] 279 / 188 / 22 / 489:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 489/872 [05:08<04:01,  1.58it/s][Succeeded / Failed / Skipped / Total] 279 / 188 / 22 / 489:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 490/872 [05:09<04:01,  1.58it/s][Succeeded / Failed / Skipped / Total] 280 / 188 / 22 / 490:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 490/872 [05:09<04:01,  1.58it/s][Succeeded / Failed / Skipped / Total] 281 / 188 / 22 / 491:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 491/872 [05:09<04:00,  1.58it/s][Succeeded / Failed / Skipped / Total] 281 / 188 / 22 / 491:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 492/872 [05:10<03:59,  1.58it/s][Succeeded / Failed / Skipped / Total] 282 / 188 / 22 / 492:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 492/872 [05:10<03:59,  1.58it/s][Succeeded / Failed / Skipped / Total] 282 / 189 / 22 / 493:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 493/872 [05:11<03:59,  1.58it/s][Succeeded / Failed / Skipped / Total] 282 / 189 / 22 / 493:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 494/872 [05:11<03:58,  1.58it/s][Succeeded / Failed / Skipped / Total] 283 / 189 / 22 / 494:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 494/872 [05:11<03:58,  1.58it/s][Succeeded / Failed / Skipped / Total] 284 / 189 / 22 / 495:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 495/872 [05:12<03:57,  1.58it/s][Succeeded / Failed / Skipped / Total] 284 / 189 / 22 / 495:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 496/872 [05:12<03:57,  1.58it/s][Succeeded / Failed / Skipped / Total] 285 / 189 / 22 / 496:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 496/872 [05:12<03:57,  1.58it/s][Succeeded / Failed / Skipped / Total] 286 / 189 / 22 / 497:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 497/872 [05:13<03:56,  1.58it/s][Succeeded / Failed / Skipped / Total] 286 / 189 / 22 / 497:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 498/872 [05:14<03:55,  1.58it/s][Succeeded / Failed / Skipped / Total] 287 / 189 / 22 / 498:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 498/872 [05:14<03:56,  1.58it/s][Succeeded / Failed / Skipped / Total] 287 / 190 / 22 / 499:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 499/872 [05:15<03:55,  1.58it/s][Succeeded / Failed / Skipped / Total] 287 / 190 / 22 / 499:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 500/872 [05:15<03:54,  1.58it/s][Succeeded / Failed / Skipped / Total] 288 / 190 / 22 / 500:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 500/872 [05:15<03:54,  1.58it/s][Succeeded / Failed / Skipped / Total] 289 / 190 / 22 / 501:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 501/872 [05:16<03:54,  1.58it/s][Succeeded / Failed / Skipped / Total] 289 / 190 / 22 / 501:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 502/872 [05:16<03:53,  1.59it/s][Succeeded / Failed / Skipped / Total] 289 / 190 / 23 / 502:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 502/872 [05:16<03:53,  1.59it/s][Succeeded / Failed / Skipped / Total] 290 / 190 / 23 / 503:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 503/872 [05:16<03:52,  1.59it/s][Succeeded / Failed / Skipped / Total] 290 / 190 / 23 / 503:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 504/872 [05:17<03:51,  1.59it/s][Succeeded / Failed / Skipped / Total] 291 / 190 / 23 / 504:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 504/872 [05:17<03:51,  1.59it/s][Succeeded / Failed / Skipped / Total] 291 / 191 / 23 / 505:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 505/872 [05:18<03:51,  1.59it/s][Succeeded / Failed / Skipped / Total] 291 / 191 / 23 / 505:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 506/872 [05:19<03:50,  1.59it/s][Succeeded / Failed / Skipped / Total] 291 / 192 / 23 / 506:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 506/872 [05:19<03:50,  1.59it/s][Succeeded / Failed / Skipped / Total] 291 / 193 / 23 / 507:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 507/872 [05:19<03:50,  1.59it/s][Succeeded / Failed / Skipped / Total] 291 / 193 / 23 / 507:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 508/872 [05:20<03:49,  1.59it/s][Succeeded / Failed / Skipped / Total] 292 / 193 / 23 / 508:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 508/872 [05:20<03:49,  1.59it/s][Succeeded / Failed / Skipped / Total] 292 / 194 / 23 / 509:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 509/872 [05:21<03:49,  1.58it/s][Succeeded / Failed / Skipped / Total] 292 / 194 / 23 / 509:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 510/872 [05:21<03:48,  1.59it/s][Succeeded / Failed / Skipped / Total] 292 / 194 / 24 / 510:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 510/872 [05:21<03:48,  1.59it/s][Succeeded / Failed / Skipped / Total] 293 / 194 / 24 / 511:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 511/872 [05:22<03:47,  1.59it/s][Succeeded / Failed / Skipped / Total] 293 / 194 / 24 / 511:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 512/872 [05:22<03:46,  1.59it/s][Succeeded / Failed / Skipped / Total] 293 / 195 / 24 / 512:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 512/872 [05:22<03:47,  1.59it/s][Succeeded / Failed / Skipped / Total] 294 / 195 / 24 / 513:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 513/872 [05:23<03:46,  1.59it/s][Succeeded / Failed / Skipped / Total] 294 / 195 / 24 / 513:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 514/872 [05:23<03:45,  1.59it/s][Succeeded / Failed / Skipped / Total] 294 / 195 / 25 / 514:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 514/872 [05:23<03:45,  1.59it/s][Succeeded / Failed / Skipped / Total] 294 / 196 / 25 / 515:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 515/872 [05:24<03:44,  1.59it/s][Succeeded / Failed / Skipped / Total] 294 / 196 / 25 / 515:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 516/872 [05:24<03:44,  1.59it/s][Succeeded / Failed / Skipped / Total] 295 / 196 / 25 / 516:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 516/872 [05:24<03:44,  1.59it/s][Succeeded / Failed / Skipped / Total] 296 / 196 / 25 / 517:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 517/872 [05:25<03:43,  1.59it/s][Succeeded / Failed / Skipped / Total] 296 / 196 / 25 / 517:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 518/872 [05:25<03:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 297 / 196 / 25 / 518:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 518/872 [05:25<03:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 297 / 197 / 25 / 519:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 519/872 [05:26<03:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 297 / 197 / 25 / 519:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 520/872 [05:26<03:41,  1.59it/s][Succeeded / Failed / Skipped / Total] 297 / 197 / 26 / 520:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 520/872 [05:26<03:41,  1.59it/s][Succeeded / Failed / Skipped / Total] 298 / 197 / 26 / 521:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 521/872 [05:27<03:40,  1.59it/s][Succeeded / Failed / Skipped / Total] 298 / 197 / 26 / 521:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 522/872 [05:28<03:40,  1.59it/s][Succeeded / Failed / Skipped / Total] 299 / 197 / 26 / 522:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 522/872 [05:28<03:40,  1.59it/s][Succeeded / Failed / Skipped / Total] 300 / 197 / 26 / 523:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 523/872 [05:28<03:39,  1.59it/s][Succeeded / Failed / Skipped / Total] 300 / 197 / 26 / 523:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 524/872 [05:29<03:38,  1.59it/s][Succeeded / Failed / Skipped / Total] 300 / 198 / 26 / 524:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 524/872 [05:29<03:38,  1.59it/s][Succeeded / Failed / Skipped / Total] 300 / 199 / 26 / 525:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 525/872 [05:30<03:38,  1.59it/s][Succeeded / Failed / Skipped / Total] 300 / 199 / 26 / 525:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 526/872 [05:31<03:37,  1.59it/s][Succeeded / Failed / Skipped / Total] 300 / 200 / 26 / 526:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 526/872 [05:31<03:37,  1.59it/s][Succeeded / Failed / Skipped / Total] 301 / 200 / 26 / 527:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 527/872 [05:31<03:37,  1.59it/s][Succeeded / Failed / Skipped / Total] 301 / 200 / 26 / 527:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 528/872 [05:32<03:36,  1.59it/s][Succeeded / Failed / Skipped / Total] 302 / 200 / 26 / 528:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 528/872 [05:32<03:36,  1.59it/s][Succeeded / Failed / Skipped / Total] 302 / 201 / 26 / 529:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 529/872 [05:33<03:35,  1.59it/s][Succeeded / Failed / Skipped / Total] 302 / 201 / 26 / 529:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 530/872 [05:33<03:35,  1.59it/s][Succeeded / Failed / Skipped / Total] 303 / 201 / 26 / 530:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 530/872 [05:33<03:35,  1.59it/s][Succeeded / Failed / Skipped / Total] 303 / 202 / 26 / 531:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 531/872 [05:34<03:34,  1.59it/s][Succeeded / Failed / Skipped / Total] 303 / 202 / 26 / 531:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 532/872 [05:35<03:34,  1.59it/s][Succeeded / Failed / Skipped / Total] 304 / 202 / 26 / 532:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 532/872 [05:35<03:34,  1.59it/s][Succeeded / Failed / Skipped / Total] 305 / 202 / 26 / 533:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 533/872 [05:35<03:33,  1.59it/s][Succeeded / Failed / Skipped / Total] 305 / 202 / 26 / 533:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 534/872 [05:36<03:33,  1.59it/s][Succeeded / Failed / Skipped / Total] 305 / 203 / 26 / 534:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 534/872 [05:36<03:33,  1.59it/s][Succeeded / Failed / Skipped / Total] 305 / 204 / 26 / 535:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 535/872 [05:37<03:32,  1.59it/s][Succeeded / Failed / Skipped / Total] 305 / 204 / 26 / 535:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 536/872 [05:38<03:31,  1.59it/s][Succeeded / Failed / Skipped / Total] 305 / 205 / 26 / 536:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 536/872 [05:38<03:31,  1.58it/s][Succeeded / Failed / Skipped / Total] 306 / 205 / 26 / 537:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 537/872 [05:38<03:31,  1.59it/s][Succeeded / Failed / Skipped / Total] 306 / 205 / 26 / 537:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 538/872 [05:39<03:30,  1.59it/s][Succeeded / Failed / Skipped / Total] 306 / 206 / 26 / 538:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 538/872 [05:39<03:30,  1.59it/s][Succeeded / Failed / Skipped / Total] 307 / 206 / 26 / 539:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 539/872 [05:40<03:30,  1.58it/s][Succeeded / Failed / Skipped / Total] 307 / 206 / 26 / 539:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 540/872 [05:40<03:29,  1.59it/s][Succeeded / Failed / Skipped / Total] 308 / 206 / 26 / 540:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 540/872 [05:40<03:29,  1.58it/s][Succeeded / Failed / Skipped / Total] 308 / 207 / 26 / 541:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 541/872 [05:41<03:28,  1.58it/s][Succeeded / Failed / Skipped / Total] 308 / 207 / 26 / 541:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 542/872 [05:42<03:28,  1.58it/s][Succeeded / Failed / Skipped / Total] 308 / 208 / 26 / 542:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 542/872 [05:42<03:28,  1.58it/s][Succeeded / Failed / Skipped / Total] 309 / 208 / 26 / 543:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 543/872 [05:42<03:27,  1.58it/s][Succeeded / Failed / Skipped / Total] 309 / 208 / 26 / 543:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 544/872 [05:43<03:27,  1.58it/s][Succeeded / Failed / Skipped / Total] 310 / 208 / 26 / 544:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 544/872 [05:43<03:27,  1.58it/s][Succeeded / Failed / Skipped / Total] 311 / 208 / 26 / 545:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 545/872 [05:44<03:26,  1.58it/s][Succeeded / Failed / Skipped / Total] 311 / 208 / 26 / 545:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 546/872 [05:44<03:25,  1.59it/s][Succeeded / Failed / Skipped / Total] 312 / 208 / 26 / 546:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 546/872 [05:44<03:25,  1.59it/s][Succeeded / Failed / Skipped / Total] 313 / 208 / 26 / 547:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 547/872 [05:45<03:25,  1.58it/s][Succeeded / Failed / Skipped / Total] 313 / 208 / 26 / 547:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 548/872 [05:45<03:24,  1.59it/s][Succeeded / Failed / Skipped / Total] 313 / 208 / 27 / 548:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 548/872 [05:45<03:24,  1.59it/s][Succeeded / Failed / Skipped / Total] 313 / 208 / 28 / 549:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 549/872 [05:45<03:23,  1.59it/s][Succeeded / Failed / Skipped / Total] 313 / 208 / 28 / 549:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 550/872 [05:45<03:22,  1.59it/s][Succeeded / Failed / Skipped / Total] 314 / 208 / 28 / 550:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 550/872 [05:45<03:22,  1.59it/s][Succeeded / Failed / Skipped / Total] 315 / 208 / 28 / 551:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 551/872 [05:46<03:21,  1.59it/s][Succeeded / Failed / Skipped / Total] 315 / 208 / 28 / 551:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 552/872 [05:47<03:21,  1.59it/s][Succeeded / Failed / Skipped / Total] 316 / 208 / 28 / 552:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 552/872 [05:47<03:21,  1.59it/s][Succeeded / Failed / Skipped / Total] 317 / 208 / 28 / 553:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 553/872 [05:47<03:20,  1.59it/s][Succeeded / Failed / Skipped / Total] 317 / 208 / 28 / 553:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 554/872 [05:48<03:19,  1.59it/s][Succeeded / Failed / Skipped / Total] 318 / 208 / 28 / 554:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 554/872 [05:48<03:19,  1.59it/s][Succeeded / Failed / Skipped / Total] 319 / 208 / 28 / 555:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 555/872 [05:48<03:19,  1.59it/s][Succeeded / Failed / Skipped / Total] 319 / 208 / 28 / 555:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 556/872 [05:49<03:18,  1.59it/s][Succeeded / Failed / Skipped / Total] 320 / 208 / 28 / 556:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 556/872 [05:49<03:18,  1.59it/s][Succeeded / Failed / Skipped / Total] 321 / 208 / 28 / 557:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 557/872 [05:50<03:18,  1.59it/s][Succeeded / Failed / Skipped / Total] 321 / 208 / 28 / 557:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 558/872 [05:51<03:17,  1.59it/s][Succeeded / Failed / Skipped / Total] 321 / 209 / 28 / 558:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 558/872 [05:51<03:17,  1.59it/s][Succeeded / Failed / Skipped / Total] 322 / 209 / 28 / 559:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 559/872 [05:51<03:16,  1.59it/s][Succeeded / Failed / Skipped / Total] 322 / 209 / 28 / 559:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 560/872 [05:52<03:16,  1.59it/s][Succeeded / Failed / Skipped / Total] 323 / 209 / 28 / 560:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 560/872 [05:52<03:16,  1.59it/s][Succeeded / Failed / Skipped / Total] 324 / 209 / 28 / 561:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 561/872 [05:52<03:15,  1.59it/s][Succeeded / Failed / Skipped / Total] 324 / 209 / 28 / 561:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 562/872 [05:53<03:14,  1.59it/s][Succeeded / Failed / Skipped / Total] 325 / 209 / 28 / 562:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 562/872 [05:53<03:14,  1.59it/s][Succeeded / Failed / Skipped / Total] 326 / 209 / 28 / 563:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 563/872 [05:53<03:14,  1.59it/s][Succeeded / Failed / Skipped / Total] 326 / 209 / 28 / 563:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 564/872 [05:54<03:13,  1.59it/s][Succeeded / Failed / Skipped / Total] 326 / 210 / 28 / 564:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 564/872 [05:54<03:13,  1.59it/s][Succeeded / Failed / Skipped / Total] 327 / 210 / 28 / 565:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 565/872 [05:55<03:13,  1.59it/s][Succeeded / Failed / Skipped / Total] 327 / 210 / 28 / 565:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 566/872 [05:55<03:12,  1.59it/s][Succeeded / Failed / Skipped / Total] 328 / 210 / 28 / 566:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 566/872 [05:55<03:12,  1.59it/s][Succeeded / Failed / Skipped / Total] 329 / 210 / 28 / 567:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 567/872 [05:56<03:11,  1.59it/s][Succeeded / Failed / Skipped / Total] 329 / 210 / 28 / 567:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 568/872 [05:57<03:11,  1.59it/s][Succeeded / Failed / Skipped / Total] 329 / 211 / 28 / 568:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 568/872 [05:57<03:11,  1.59it/s][Succeeded / Failed / Skipped / Total] 330 / 211 / 28 / 569:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 569/872 [05:57<03:10,  1.59it/s][Succeeded / Failed / Skipped / Total] 330 / 211 / 28 / 569:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 570/872 [05:58<03:10,  1.59it/s][Succeeded / Failed / Skipped / Total] 330 / 212 / 28 / 570:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 570/872 [05:58<03:10,  1.59it/s][Succeeded / Failed / Skipped / Total] 330 / 213 / 28 / 571:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 571/872 [05:59<03:09,  1.59it/s][Succeeded / Failed / Skipped / Total] 330 / 213 / 28 / 571:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 572/872 [05:59<03:08,  1.59it/s][Succeeded / Failed / Skipped / Total] 331 / 213 / 28 / 572:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 572/872 [05:59<03:08,  1.59it/s][Succeeded / Failed / Skipped / Total] 332 / 213 / 28 / 573:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 573/872 [06:00<03:08,  1.59it/s][Succeeded / Failed / Skipped / Total] 332 / 213 / 28 / 573:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 574/872 [06:01<03:07,  1.59it/s][Succeeded / Failed / Skipped / Total] 332 / 214 / 28 / 574:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 574/872 [06:01<03:07,  1.59it/s][Succeeded / Failed / Skipped / Total] 333 / 214 / 28 / 575:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 575/872 [06:02<03:06,  1.59it/s][Succeeded / Failed / Skipped / Total] 333 / 214 / 28 / 575:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 576/872 [06:02<03:06,  1.59it/s][Succeeded / Failed / Skipped / Total] 334 / 214 / 28 / 576:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 576/872 [06:02<03:06,  1.59it/s][Succeeded / Failed / Skipped / Total] 335 / 214 / 28 / 577:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 577/872 [06:03<03:05,  1.59it/s][Succeeded / Failed / Skipped / Total] 335 / 214 / 28 / 577:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 578/872 [06:03<03:05,  1.59it/s][Succeeded / Failed / Skipped / Total] 335 / 215 / 28 / 578:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 578/872 [06:03<03:05,  1.59it/s][Succeeded / Failed / Skipped / Total] 336 / 215 / 28 / 579:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 579/872 [06:04<03:04,  1.59it/s][Succeeded / Failed / Skipped / Total] 336 / 215 / 28 / 579:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 580/872 [06:04<03:03,  1.59it/s][Succeeded / Failed / Skipped / Total] 337 / 215 / 28 / 580:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 580/872 [06:04<03:03,  1.59it/s][Succeeded / Failed / Skipped / Total] 338 / 215 / 28 / 581:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 581/872 [06:05<03:02,  1.59it/s][Succeeded / Failed / Skipped / Total] 338 / 215 / 28 / 581:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 582/872 [06:05<03:02,  1.59it/s][Succeeded / Failed / Skipped / Total] 339 / 215 / 28 / 582:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 582/872 [06:05<03:02,  1.59it/s][Succeeded / Failed / Skipped / Total] 340 / 215 / 28 / 583:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 583/872 [06:06<03:01,  1.59it/s][Succeeded / Failed / Skipped / Total] 340 / 215 / 28 / 583:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 584/872 [06:07<03:01,  1.59it/s][Succeeded / Failed / Skipped / Total] 341 / 215 / 28 / 584:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 584/872 [06:07<03:01,  1.59it/s][Succeeded / Failed / Skipped / Total] 342 / 215 / 28 / 585:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 585/872 [06:07<03:00,  1.59it/s][Succeeded / Failed / Skipped / Total] 342 / 215 / 28 / 585:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 586/872 [06:08<02:59,  1.59it/s][Succeeded / Failed / Skipped / Total] 343 / 215 / 28 / 586:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 586/872 [06:08<02:59,  1.59it/s][Succeeded / Failed / Skipped / Total] 344 / 215 / 28 / 587:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 587/872 [06:08<02:59,  1.59it/s][Succeeded / Failed / Skipped / Total] 344 / 215 / 28 / 587:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 588/872 [06:09<02:58,  1.59it/s][Succeeded / Failed / Skipped / Total] 345 / 215 / 28 / 588:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 588/872 [06:09<02:58,  1.59it/s][Succeeded / Failed / Skipped / Total] 345 / 216 / 28 / 589:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 589/872 [06:10<02:58,  1.59it/s][Succeeded / Failed / Skipped / Total] 345 / 216 / 28 / 589:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 590/872 [06:11<02:57,  1.59it/s][Succeeded / Failed / Skipped / Total] 346 / 216 / 28 / 590:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 590/872 [06:11<02:57,  1.59it/s][Succeeded / Failed / Skipped / Total] 347 / 216 / 28 / 591:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 591/872 [06:11<02:56,  1.59it/s][Succeeded / Failed / Skipped / Total] 347 / 216 / 28 / 591:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 592/872 [06:12<02:56,  1.59it/s][Succeeded / Failed / Skipped / Total] 348 / 216 / 28 / 592:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 592/872 [06:12<02:56,  1.59it/s][Succeeded / Failed / Skipped / Total] 349 / 216 / 28 / 593:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 593/872 [06:12<02:55,  1.59it/s][Succeeded / Failed / Skipped / Total] 349 / 216 / 28 / 593:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 594/872 [06:13<02:54,  1.59it/s][Succeeded / Failed / Skipped / Total] 349 / 217 / 28 / 594:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 594/872 [06:13<02:54,  1.59it/s][Succeeded / Failed / Skipped / Total] 349 / 218 / 28 / 595:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 595/872 [06:14<02:54,  1.59it/s][Succeeded / Failed / Skipped / Total] 349 / 218 / 28 / 595:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 596/872 [06:15<02:53,  1.59it/s][Succeeded / Failed / Skipped / Total] 350 / 218 / 28 / 596:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 596/872 [06:15<02:53,  1.59it/s][Succeeded / Failed / Skipped / Total] 351 / 218 / 28 / 597:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 597/872 [06:15<02:53,  1.59it/s][Succeeded / Failed / Skipped / Total] 351 / 218 / 28 / 597:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 598/872 [06:16<02:52,  1.59it/s][Succeeded / Failed / Skipped / Total] 352 / 218 / 28 / 598:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 598/872 [06:16<02:52,  1.59it/s][Succeeded / Failed / Skipped / Total] 353 / 218 / 28 / 599:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 599/872 [06:16<02:51,  1.59it/s][Succeeded / Failed / Skipped / Total] 353 / 218 / 28 / 599:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 600/872 [06:17<02:51,  1.59it/s][Succeeded / Failed / Skipped / Total] 354 / 218 / 28 / 600:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 600/872 [06:17<02:51,  1.59it/s][Succeeded / Failed / Skipped / Total] 355 / 218 / 28 / 601:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 601/872 [06:18<02:50,  1.59it/s][Succeeded / Failed / Skipped / Total] 355 / 218 / 28 / 601:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 602/872 [06:18<02:49,  1.59it/s][Succeeded / Failed / Skipped / Total] 356 / 218 / 28 / 602:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 602/872 [06:18<02:49,  1.59it/s][Succeeded / Failed / Skipped / Total] 356 / 219 / 28 / 603:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 603/872 [06:19<02:49,  1.59it/s][Succeeded / Failed / Skipped / Total] 356 / 219 / 28 / 603:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 604/872 [06:20<02:48,  1.59it/s][Succeeded / Failed / Skipped / Total] 356 / 220 / 28 / 604:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 604/872 [06:20<02:48,  1.59it/s][Succeeded / Failed / Skipped / Total] 357 / 220 / 28 / 605:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 605/872 [06:20<02:47,  1.59it/s][Succeeded / Failed / Skipped / Total] 357 / 220 / 28 / 605:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 606/872 [06:21<02:47,  1.59it/s][Succeeded / Failed / Skipped / Total] 357 / 221 / 28 / 606:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 606/872 [06:21<02:47,  1.59it/s][Succeeded / Failed / Skipped / Total] 358 / 221 / 28 / 607:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 607/872 [06:22<02:46,  1.59it/s][Succeeded / Failed / Skipped / Total] 358 / 221 / 28 / 607:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 608/872 [06:22<02:46,  1.59it/s][Succeeded / Failed / Skipped / Total] 358 / 222 / 28 / 608:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 608/872 [06:22<02:46,  1.59it/s][Succeeded / Failed / Skipped / Total] 358 / 223 / 28 / 609:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 609/872 [06:23<02:45,  1.59it/s][Succeeded / Failed / Skipped / Total] 358 / 223 / 28 / 609:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 610/872 [06:24<02:45,  1.59it/s][Succeeded / Failed / Skipped / Total] 358 / 224 / 28 / 610:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 610/872 [06:24<02:45,  1.59it/s][Succeeded / Failed / Skipped / Total] 359 / 224 / 28 / 611:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 611/872 [06:24<02:44,  1.59it/s][Succeeded / Failed / Skipped / Total] 359 / 224 / 28 / 611:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 612/872 [06:25<02:43,  1.59it/s][Succeeded / Failed / Skipped / Total] 359 / 225 / 28 / 612:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 612/872 [06:25<02:43,  1.59it/s][Succeeded / Failed / Skipped / Total] 360 / 225 / 28 / 613:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 613/872 [06:26<02:43,  1.59it/s][Succeeded / Failed / Skipped / Total] 360 / 225 / 28 / 613:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 614/872 [06:27<02:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 360 / 226 / 28 / 614:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 614/872 [06:27<02:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 361 / 226 / 28 / 615:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 615/872 [06:27<02:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 361 / 226 / 28 / 615:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 616/872 [06:28<02:41,  1.59it/s][Succeeded / Failed / Skipped / Total] 362 / 226 / 28 / 616:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 616/872 [06:28<02:41,  1.59it/s][Succeeded / Failed / Skipped / Total] 362 / 227 / 28 / 617:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 617/872 [06:29<02:40,  1.59it/s][Succeeded / Failed / Skipped / Total] 362 / 227 / 28 / 617:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 618/872 [06:29<02:40,  1.59it/s][Succeeded / Failed / Skipped / Total] 363 / 227 / 28 / 618:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 618/872 [06:29<02:40,  1.59it/s][Succeeded / Failed / Skipped / Total] 364 / 227 / 28 / 619:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 619/872 [06:29<02:39,  1.59it/s][Succeeded / Failed / Skipped / Total] 364 / 227 / 28 / 619:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 620/872 [06:30<02:38,  1.59it/s][Succeeded / Failed / Skipped / Total] 365 / 227 / 28 / 620:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 620/872 [06:30<02:38,  1.59it/s][Succeeded / Failed / Skipped / Total] 366 / 227 / 28 / 621:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 621/872 [06:31<02:38,  1.59it/s][Succeeded / Failed / Skipped / Total] 366 / 227 / 28 / 621:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 622/872 [06:32<02:37,  1.59it/s][Succeeded / Failed / Skipped / Total] 366 / 228 / 28 / 622:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 622/872 [06:32<02:37,  1.59it/s][Succeeded / Failed / Skipped / Total] 366 / 229 / 28 / 623:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 623/872 [06:32<02:37,  1.59it/s][Succeeded / Failed / Skipped / Total] 366 / 229 / 28 / 623:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 624/872 [06:33<02:36,  1.59it/s][Succeeded / Failed / Skipped / Total] 367 / 229 / 28 / 624:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 624/872 [06:33<02:36,  1.59it/s][Succeeded / Failed / Skipped / Total] 367 / 230 / 28 / 625:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 625/872 [06:34<02:35,  1.59it/s][Succeeded / Failed / Skipped / Total] 367 / 230 / 28 / 625:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 626/872 [06:34<02:35,  1.59it/s][Succeeded / Failed / Skipped / Total] 368 / 230 / 28 / 626:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 626/872 [06:34<02:35,  1.59it/s][Succeeded / Failed / Skipped / Total] 368 / 231 / 28 / 627:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 627/872 [06:35<02:34,  1.58it/s][Succeeded / Failed / Skipped / Total] 368 / 231 / 28 / 627:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 628/872 [06:36<02:33,  1.58it/s][Succeeded / Failed / Skipped / Total] 369 / 231 / 28 / 628:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 628/872 [06:36<02:33,  1.58it/s][Succeeded / Failed / Skipped / Total] 369 / 232 / 28 / 629:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 629/872 [06:37<02:33,  1.58it/s][Succeeded / Failed / Skipped / Total] 369 / 232 / 28 / 629:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 630/872 [06:37<02:32,  1.58it/s][Succeeded / Failed / Skipped / Total] 370 / 232 / 28 / 630:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 630/872 [06:37<02:32,  1.58it/s][Succeeded / Failed / Skipped / Total] 371 / 232 / 28 / 631:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 631/872 [06:38<02:32,  1.58it/s][Succeeded / Failed / Skipped / Total] 371 / 232 / 28 / 631:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 632/872 [06:38<02:31,  1.58it/s][Succeeded / Failed / Skipped / Total] 372 / 232 / 28 / 632:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 632/872 [06:38<02:31,  1.58it/s][Succeeded / Failed / Skipped / Total] 373 / 232 / 28 / 633:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 633/872 [06:39<02:30,  1.58it/s][Succeeded / Failed / Skipped / Total] 373 / 232 / 28 / 633:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 634/872 [06:40<02:30,  1.58it/s][Succeeded / Failed / Skipped / Total] 373 / 233 / 28 / 634:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 634/872 [06:40<02:30,  1.58it/s][Succeeded / Failed / Skipped / Total] 373 / 234 / 28 / 635:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 635/872 [06:41<02:29,  1.58it/s][Succeeded / Failed / Skipped / Total] 373 / 234 / 28 / 635:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 636/872 [06:41<02:28,  1.58it/s][Succeeded / Failed / Skipped / Total] 374 / 234 / 28 / 636:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 636/872 [06:41<02:29,  1.58it/s][Succeeded / Failed / Skipped / Total] 374 / 235 / 28 / 637:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 637/872 [06:42<02:28,  1.58it/s][Succeeded / Failed / Skipped / Total] 374 / 235 / 28 / 637:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 638/872 [06:42<02:27,  1.58it/s][Succeeded / Failed / Skipped / Total] 375 / 235 / 28 / 638:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 638/872 [06:42<02:27,  1.58it/s][Succeeded / Failed / Skipped / Total] 376 / 235 / 28 / 639:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 639/872 [06:43<02:27,  1.58it/s][Succeeded / Failed / Skipped / Total] 376 / 235 / 28 / 639:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 640/872 [06:44<02:26,  1.58it/s][Succeeded / Failed / Skipped / Total] 377 / 235 / 28 / 640:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 640/872 [06:44<02:26,  1.58it/s][Succeeded / Failed / Skipped / Total] 377 / 236 / 28 / 641:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 641/872 [06:44<02:25,  1.58it/s][Succeeded / Failed / Skipped / Total] 377 / 236 / 28 / 641:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 642/872 [06:45<02:25,  1.58it/s][Succeeded / Failed / Skipped / Total] 377 / 237 / 28 / 642:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 642/872 [06:45<02:25,  1.58it/s][Succeeded / Failed / Skipped / Total] 378 / 237 / 28 / 643:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 643/872 [06:46<02:24,  1.58it/s][Succeeded / Failed / Skipped / Total] 378 / 237 / 28 / 643:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 644/872 [06:47<02:24,  1.58it/s][Succeeded / Failed / Skipped / Total] 379 / 237 / 28 / 644:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 644/872 [06:47<02:24,  1.58it/s][Succeeded / Failed / Skipped / Total] 379 / 238 / 28 / 645:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 645/872 [06:47<02:23,  1.58it/s][Succeeded / Failed / Skipped / Total] 379 / 238 / 28 / 645:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 646/872 [06:48<02:22,  1.58it/s][Succeeded / Failed / Skipped / Total] 379 / 238 / 29 / 646:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 646/872 [06:48<02:22,  1.58it/s][Succeeded / Failed / Skipped / Total] 380 / 238 / 29 / 647:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 647/872 [06:48<02:22,  1.58it/s][Succeeded / Failed / Skipped / Total] 380 / 238 / 29 / 647:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 648/872 [06:49<02:21,  1.58it/s][Succeeded / Failed / Skipped / Total] 381 / 238 / 29 / 648:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 648/872 [06:49<02:21,  1.58it/s][Succeeded / Failed / Skipped / Total] 381 / 239 / 29 / 649:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 649/872 [06:49<02:20,  1.58it/s][Succeeded / Failed / Skipped / Total] 381 / 239 / 29 / 649:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 650/872 [06:50<02:20,  1.58it/s][Succeeded / Failed / Skipped / Total] 382 / 239 / 29 / 650:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 650/872 [06:50<02:20,  1.58it/s][Succeeded / Failed / Skipped / Total] 383 / 239 / 29 / 651:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 651/872 [06:51<02:19,  1.58it/s][Succeeded / Failed / Skipped / Total] 383 / 239 / 29 / 651:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 652/872 [06:51<02:18,  1.58it/s][Succeeded / Failed / Skipped / Total] 384 / 239 / 29 / 652:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 652/872 [06:51<02:18,  1.58it/s][Succeeded / Failed / Skipped / Total] 385 / 239 / 29 / 653:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 653/872 [06:52<02:18,  1.58it/s][Succeeded / Failed / Skipped / Total] 385 / 239 / 29 / 653:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 654/872 [06:53<02:17,  1.58it/s][Succeeded / Failed / Skipped / Total] 386 / 239 / 29 / 654:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 654/872 [06:53<02:17,  1.58it/s][Succeeded / Failed / Skipped / Total] 387 / 239 / 29 / 655:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 655/872 [06:53<02:17,  1.58it/s][Succeeded / Failed / Skipped / Total] 387 / 239 / 29 / 655:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 656/872 [06:54<02:16,  1.58it/s][Succeeded / Failed / Skipped / Total] 388 / 239 / 29 / 656:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 656/872 [06:54<02:16,  1.58it/s][Succeeded / Failed / Skipped / Total] 388 / 239 / 30 / 657:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 657/872 [06:54<02:15,  1.58it/s][Succeeded / Failed / Skipped / Total] 388 / 239 / 30 / 657:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 658/872 [06:54<02:14,  1.59it/s][Succeeded / Failed / Skipped / Total] 389 / 239 / 30 / 658:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 658/872 [06:55<02:14,  1.59it/s][Succeeded / Failed / Skipped / Total] 389 / 240 / 30 / 659:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 659/872 [06:55<02:14,  1.58it/s][Succeeded / Failed / Skipped / Total] 389 / 240 / 30 / 659:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 660/872 [06:56<02:13,  1.59it/s][Succeeded / Failed / Skipped / Total] 390 / 240 / 30 / 660:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 660/872 [06:56<02:13,  1.59it/s][Succeeded / Failed / Skipped / Total] 390 / 241 / 30 / 661:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 661/872 [06:57<02:13,  1.58it/s][Succeeded / Failed / Skipped / Total] 390 / 241 / 30 / 661:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 662/872 [06:57<02:12,  1.59it/s][Succeeded / Failed / Skipped / Total] 391 / 241 / 30 / 662:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 662/872 [06:57<02:12,  1.59it/s][Succeeded / Failed / Skipped / Total] 392 / 241 / 30 / 663:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 663/872 [06:58<02:11,  1.59it/s][Succeeded / Failed / Skipped / Total] 392 / 241 / 30 / 663:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 664/872 [06:58<02:11,  1.59it/s][Succeeded / Failed / Skipped / Total] 393 / 241 / 30 / 664:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 664/872 [06:58<02:11,  1.59it/s][Succeeded / Failed / Skipped / Total] 393 / 242 / 30 / 665:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 665/872 [06:59<02:10,  1.58it/s][Succeeded / Failed / Skipped / Total] 393 / 242 / 30 / 665:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 666/872 [07:00<02:10,  1.58it/s][Succeeded / Failed / Skipped / Total] 394 / 242 / 30 / 666:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 666/872 [07:00<02:10,  1.58it/s][Succeeded / Failed / Skipped / Total] 394 / 243 / 30 / 667:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 667/872 [07:01<02:09,  1.58it/s][Succeeded / Failed / Skipped / Total] 394 / 243 / 30 / 667:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 668/872 [07:01<02:08,  1.59it/s][Succeeded / Failed / Skipped / Total] 394 / 243 / 31 / 668:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 668/872 [07:01<02:08,  1.59it/s][Succeeded / Failed / Skipped / Total] 395 / 243 / 31 / 669:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 669/872 [07:01<02:08,  1.59it/s][Succeeded / Failed / Skipped / Total] 395 / 243 / 31 / 669:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 670/872 [07:02<02:07,  1.59it/s][Succeeded / Failed / Skipped / Total] 396 / 243 / 31 / 670:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 670/872 [07:02<02:07,  1.59it/s][Succeeded / Failed / Skipped / Total] 397 / 243 / 31 / 671:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 671/872 [07:03<02:06,  1.59it/s][Succeeded / Failed / Skipped / Total] 397 / 243 / 31 / 671:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 672/872 [07:03<02:06,  1.59it/s][Succeeded / Failed / Skipped / Total] 397 / 244 / 31 / 672:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 672/872 [07:03<02:06,  1.59it/s][Succeeded / Failed / Skipped / Total] 398 / 244 / 31 / 673:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 673/872 [07:04<02:05,  1.59it/s][Succeeded / Failed / Skipped / Total] 398 / 244 / 31 / 673:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 674/872 [07:05<02:04,  1.59it/s][Succeeded / Failed / Skipped / Total] 398 / 245 / 31 / 674:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 674/872 [07:05<02:04,  1.59it/s][Succeeded / Failed / Skipped / Total] 398 / 246 / 31 / 675:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 675/872 [07:06<02:04,  1.58it/s][Succeeded / Failed / Skipped / Total] 398 / 246 / 31 / 675:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 676/872 [07:06<02:03,  1.59it/s][Succeeded / Failed / Skipped / Total] 398 / 246 / 32 / 676:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 676/872 [07:06<02:03,  1.59it/s][Succeeded / Failed / Skipped / Total] 399 / 246 / 32 / 677:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 677/872 [07:06<02:02,  1.59it/s][Succeeded / Failed / Skipped / Total] 399 / 246 / 32 / 677:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 678/872 [07:07<02:02,  1.59it/s][Succeeded / Failed / Skipped / Total] 399 / 247 / 32 / 678:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 678/872 [07:07<02:02,  1.59it/s][Succeeded / Failed / Skipped / Total] 400 / 247 / 32 / 679:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 679/872 [07:08<02:01,  1.59it/s][Succeeded / Failed / Skipped / Total] 400 / 247 / 32 / 679:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 680/872 [07:09<02:01,  1.58it/s][Succeeded / Failed / Skipped / Total] 400 / 248 / 32 / 680:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 680/872 [07:09<02:01,  1.58it/s][Succeeded / Failed / Skipped / Total] 401 / 248 / 32 / 681:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 681/872 [07:09<02:00,  1.58it/s][Succeeded / Failed / Skipped / Total] 401 / 248 / 32 / 681:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 682/872 [07:10<01:59,  1.58it/s][Succeeded / Failed / Skipped / Total] 402 / 248 / 32 / 682:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 682/872 [07:10<01:59,  1.58it/s][Succeeded / Failed / Skipped / Total] 403 / 248 / 32 / 683:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 683/872 [07:11<01:59,  1.58it/s][Succeeded / Failed / Skipped / Total] 403 / 248 / 32 / 683:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 684/872 [07:11<01:58,  1.58it/s][Succeeded / Failed / Skipped / Total] 404 / 248 / 32 / 684:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 684/872 [07:11<01:58,  1.58it/s][Succeeded / Failed / Skipped / Total] 404 / 249 / 32 / 685:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 685/872 [07:12<01:58,  1.58it/s][Succeeded / Failed / Skipped / Total] 404 / 249 / 32 / 685:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 686/872 [07:13<01:57,  1.58it/s][Succeeded / Failed / Skipped / Total] 405 / 249 / 32 / 686:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 686/872 [07:13<01:57,  1.58it/s][Succeeded / Failed / Skipped / Total] 406 / 249 / 32 / 687:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 687/872 [07:13<01:56,  1.58it/s][Succeeded / Failed / Skipped / Total] 406 / 249 / 32 / 687:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 688/872 [07:14<01:56,  1.58it/s][Succeeded / Failed / Skipped / Total] 407 / 249 / 32 / 688:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 688/872 [07:14<01:56,  1.58it/s][Succeeded / Failed / Skipped / Total] 408 / 249 / 32 / 689:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 689/872 [07:14<01:55,  1.58it/s][Succeeded / Failed / Skipped / Total] 408 / 249 / 32 / 689:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 690/872 [07:15<01:54,  1.58it/s][Succeeded / Failed / Skipped / Total] 409 / 249 / 32 / 690:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 690/872 [07:15<01:54,  1.58it/s][Succeeded / Failed / Skipped / Total] 410 / 249 / 32 / 691:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 691/872 [07:16<01:54,  1.58it/s][Succeeded / Failed / Skipped / Total] 410 / 249 / 32 / 691:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 692/872 [07:17<01:53,  1.58it/s][Succeeded / Failed / Skipped / Total] 410 / 250 / 32 / 692:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 692/872 [07:17<01:53,  1.58it/s][Succeeded / Failed / Skipped / Total] 410 / 250 / 33 / 693:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 693/872 [07:17<01:52,  1.58it/s][Succeeded / Failed / Skipped / Total] 410 / 250 / 33 / 693:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 694/872 [07:17<01:52,  1.58it/s][Succeeded / Failed / Skipped / Total] 411 / 250 / 33 / 694:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 694/872 [07:17<01:52,  1.58it/s][Succeeded / Failed / Skipped / Total] 412 / 250 / 33 / 695:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 695/872 [07:18<01:51,  1.59it/s][Succeeded / Failed / Skipped / Total] 412 / 250 / 33 / 695:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 696/872 [07:18<01:50,  1.59it/s][Succeeded / Failed / Skipped / Total] 413 / 250 / 33 / 696:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 696/872 [07:18<01:50,  1.59it/s][Succeeded / Failed / Skipped / Total] 413 / 251 / 33 / 697:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 697/872 [07:19<01:50,  1.59it/s][Succeeded / Failed / Skipped / Total] 413 / 251 / 33 / 697:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 698/872 [07:20<01:49,  1.59it/s][Succeeded / Failed / Skipped / Total] 414 / 251 / 33 / 698:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 698/872 [07:20<01:49,  1.59it/s][Succeeded / Failed / Skipped / Total] 414 / 252 / 33 / 699:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 699/872 [07:21<01:49,  1.58it/s][Succeeded / Failed / Skipped / Total] 414 / 252 / 33 / 699:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 700/872 [07:21<01:48,  1.59it/s][Succeeded / Failed / Skipped / Total] 414 / 252 / 34 / 700:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 700/872 [07:21<01:48,  1.59it/s][Succeeded / Failed / Skipped / Total] 415 / 252 / 34 / 701:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 701/872 [07:21<01:47,  1.59it/s][Succeeded / Failed / Skipped / Total] 415 / 252 / 34 / 701:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 702/872 [07:22<01:47,  1.59it/s][Succeeded / Failed / Skipped / Total] 416 / 252 / 34 / 702:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 702/872 [07:22<01:47,  1.59it/s][Succeeded / Failed / Skipped / Total] 417 / 252 / 34 / 703:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 703/872 [07:22<01:46,  1.59it/s][Succeeded / Failed / Skipped / Total] 417 / 252 / 34 / 703:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 704/872 [07:23<01:45,  1.59it/s][Succeeded / Failed / Skipped / Total] 418 / 252 / 34 / 704:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 704/872 [07:23<01:45,  1.59it/s][Succeeded / Failed / Skipped / Total] 419 / 252 / 34 / 705:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 705/872 [07:24<01:45,  1.59it/s][Succeeded / Failed / Skipped / Total] 419 / 252 / 34 / 705:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 706/872 [07:24<01:44,  1.59it/s][Succeeded / Failed / Skipped / Total] 420 / 252 / 34 / 706:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 706/872 [07:24<01:44,  1.59it/s][Succeeded / Failed / Skipped / Total] 421 / 252 / 34 / 707:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 707/872 [07:25<01:43,  1.59it/s][Succeeded / Failed / Skipped / Total] 421 / 252 / 34 / 707:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 708/872 [07:25<01:43,  1.59it/s][Succeeded / Failed / Skipped / Total] 422 / 252 / 34 / 708:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 708/872 [07:25<01:43,  1.59it/s][Succeeded / Failed / Skipped / Total] 422 / 253 / 34 / 709:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 709/872 [07:26<01:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 422 / 253 / 34 / 709:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 710/872 [07:27<01:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 423 / 253 / 34 / 710:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 710/872 [07:27<01:42,  1.59it/s][Succeeded / Failed / Skipped / Total] 424 / 253 / 34 / 711:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 711/872 [07:27<01:41,  1.59it/s][Succeeded / Failed / Skipped / Total] 424 / 253 / 34 / 711:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 712/872 [07:28<01:40,  1.59it/s][Succeeded / Failed / Skipped / Total] 425 / 253 / 34 / 712:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 712/872 [07:28<01:40,  1.59it/s][Succeeded / Failed / Skipped / Total] 426 / 253 / 34 / 713:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 713/872 [07:28<01:40,  1.59it/s][Succeeded / Failed / Skipped / Total] 426 / 253 / 34 / 713:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 714/872 [07:29<01:39,  1.59it/s][Succeeded / Failed / Skipped / Total] 427 / 253 / 34 / 714:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 714/872 [07:29<01:39,  1.59it/s][Succeeded / Failed / Skipped / Total] 427 / 254 / 34 / 715:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 715/872 [07:30<01:38,  1.59it/s][Succeeded / Failed / Skipped / Total] 427 / 254 / 34 / 715:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 716/872 [07:30<01:38,  1.59it/s][Succeeded / Failed / Skipped / Total] 428 / 254 / 34 / 716:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 716/872 [07:30<01:38,  1.59it/s][Succeeded / Failed / Skipped / Total] 429 / 254 / 34 / 717:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 717/872 [07:31<01:37,  1.59it/s][Succeeded / Failed / Skipped / Total] 429 / 254 / 34 / 717:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 718/872 [07:31<01:36,  1.59it/s][Succeeded / Failed / Skipped / Total] 429 / 255 / 34 / 718:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 718/872 [07:32<01:36,  1.59it/s][Succeeded / Failed / Skipped / Total] 429 / 256 / 34 / 719:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 719/872 [07:32<01:36,  1.59it/s][Succeeded / Failed / Skipped / Total] 429 / 256 / 34 / 719:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 720/872 [07:33<01:35,  1.59it/s][Succeeded / Failed / Skipped / Total] 430 / 256 / 34 / 720:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 720/872 [07:33<01:35,  1.59it/s][Succeeded / Failed / Skipped / Total] 430 / 257 / 34 / 721:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 721/872 [07:34<01:35,  1.59it/s][Succeeded / Failed / Skipped / Total] 430 / 257 / 34 / 721:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 722/872 [07:35<01:34,  1.59it/s][Succeeded / Failed / Skipped / Total] 430 / 258 / 34 / 722:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 722/872 [07:35<01:34,  1.59it/s][Succeeded / Failed / Skipped / Total] 431 / 258 / 34 / 723:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 723/872 [07:35<01:33,  1.59it/s][Succeeded / Failed / Skipped / Total] 431 / 258 / 34 / 723:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 724/872 [07:36<01:33,  1.59it/s][Succeeded / Failed / Skipped / Total] 431 / 259 / 34 / 724:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 724/872 [07:36<01:33,  1.59it/s][Succeeded / Failed / Skipped / Total] 432 / 259 / 34 / 725:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 725/872 [07:37<01:32,  1.59it/s][Succeeded / Failed / Skipped / Total] 432 / 259 / 34 / 725:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 726/872 [07:37<01:32,  1.59it/s][Succeeded / Failed / Skipped / Total] 433 / 259 / 34 / 726:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 726/872 [07:37<01:32,  1.59it/s][Succeeded / Failed / Skipped / Total] 433 / 260 / 34 / 727:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 727/872 [07:38<01:31,  1.59it/s][Succeeded / Failed / Skipped / Total] 433 / 260 / 34 / 727:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 728/872 [07:39<01:30,  1.59it/s][Succeeded / Failed / Skipped / Total] 434 / 260 / 34 / 728:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 728/872 [07:39<01:30,  1.59it/s][Succeeded / Failed / Skipped / Total] 435 / 260 / 34 / 729:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 729/872 [07:39<01:30,  1.59it/s][Succeeded / Failed / Skipped / Total] 435 / 260 / 34 / 729:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 730/872 [07:40<01:29,  1.58it/s][Succeeded / Failed / Skipped / Total] 435 / 261 / 34 / 730:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 730/872 [07:40<01:29,  1.58it/s][Succeeded / Failed / Skipped / Total] 436 / 261 / 34 / 731:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 731/872 [07:41<01:29,  1.58it/s][Succeeded / Failed / Skipped / Total] 436 / 261 / 34 / 731:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 732/872 [07:41<01:28,  1.59it/s][Succeeded / Failed / Skipped / Total] 437 / 261 / 34 / 732:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 732/872 [07:41<01:28,  1.58it/s][Succeeded / Failed / Skipped / Total] 438 / 261 / 34 / 733:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 733/872 [07:42<01:27,  1.58it/s][Succeeded / Failed / Skipped / Total] 438 / 261 / 34 / 733:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 734/872 [07:43<01:27,  1.58it/s][Succeeded / Failed / Skipped / Total] 439 / 261 / 34 / 734:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 734/872 [07:43<01:27,  1.58it/s][Succeeded / Failed / Skipped / Total] 440 / 261 / 34 / 735:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 735/872 [07:43<01:26,  1.59it/s][Succeeded / Failed / Skipped / Total] 440 / 261 / 34 / 735:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 736/872 [07:44<01:25,  1.59it/s][Succeeded / Failed / Skipped / Total] 441 / 261 / 34 / 736:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 736/872 [07:44<01:25,  1.58it/s][Succeeded / Failed / Skipped / Total] 441 / 261 / 35 / 737:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 737/872 [07:44<01:25,  1.59it/s][Succeeded / Failed / Skipped / Total] 441 / 261 / 35 / 737:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 738/872 [07:45<01:24,  1.59it/s][Succeeded / Failed / Skipped / Total] 441 / 262 / 35 / 738:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 738/872 [07:45<01:24,  1.59it/s][Succeeded / Failed / Skipped / Total] 441 / 263 / 35 / 739:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 739/872 [07:46<01:23,  1.59it/s][Succeeded / Failed / Skipped / Total] 441 / 263 / 35 / 739:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 740/872 [07:46<01:23,  1.59it/s][Succeeded / Failed / Skipped / Total] 441 / 264 / 35 / 740:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 740/872 [07:46<01:23,  1.58it/s][Succeeded / Failed / Skipped / Total] 441 / 265 / 35 / 741:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 741/872 [07:47<01:22,  1.58it/s][Succeeded / Failed / Skipped / Total] 441 / 265 / 35 / 741:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 742/872 [07:48<01:22,  1.58it/s][Succeeded / Failed / Skipped / Total] 442 / 265 / 35 / 742:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 742/872 [07:48<01:22,  1.58it/s][Succeeded / Failed / Skipped / Total] 442 / 266 / 35 / 743:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 743/872 [07:49<01:21,  1.58it/s][Succeeded / Failed / Skipped / Total] 442 / 266 / 35 / 743:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 744/872 [07:49<01:20,  1.58it/s][Succeeded / Failed / Skipped / Total] 443 / 266 / 35 / 744:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 744/872 [07:49<01:20,  1.58it/s][Succeeded / Failed / Skipped / Total] 443 / 266 / 36 / 745:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 745/872 [07:50<01:20,  1.59it/s][Succeeded / Failed / Skipped / Total] 443 / 266 / 36 / 745:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 746/872 [07:50<01:19,  1.59it/s][Succeeded / Failed / Skipped / Total] 444 / 266 / 36 / 746:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 746/872 [07:50<01:19,  1.58it/s][Succeeded / Failed / Skipped / Total] 444 / 267 / 36 / 747:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 747/872 [07:51<01:18,  1.58it/s][Succeeded / Failed / Skipped / Total] 444 / 267 / 36 / 747:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 748/872 [07:52<01:18,  1.58it/s][Succeeded / Failed / Skipped / Total] 444 / 268 / 36 / 748:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 748/872 [07:52<01:18,  1.58it/s][Succeeded / Failed / Skipped / Total] 445 / 268 / 36 / 749:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 749/872 [07:52<01:17,  1.58it/s][Succeeded / Failed / Skipped / Total] 445 / 268 / 36 / 749:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 750/872 [07:53<01:16,  1.59it/s][Succeeded / Failed / Skipped / Total] 446 / 268 / 36 / 750:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 750/872 [07:53<01:16,  1.59it/s][Succeeded / Failed / Skipped / Total] 447 / 268 / 36 / 751:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 751/872 [07:53<01:16,  1.58it/s][Succeeded / Failed / Skipped / Total] 447 / 268 / 36 / 751:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 752/872 [07:54<01:15,  1.58it/s][Succeeded / Failed / Skipped / Total] 448 / 268 / 36 / 752:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 752/872 [07:54<01:15,  1.58it/s][Succeeded / Failed / Skipped / Total] 449 / 268 / 36 / 753:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 753/872 [07:54<01:15,  1.59it/s][Succeeded / Failed / Skipped / Total] 449 / 268 / 36 / 753:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 754/872 [07:55<01:14,  1.58it/s][Succeeded / Failed / Skipped / Total] 449 / 269 / 36 / 754:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 754/872 [07:55<01:14,  1.58it/s][Succeeded / Failed / Skipped / Total] 449 / 270 / 36 / 755:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 755/872 [07:56<01:13,  1.58it/s][Succeeded / Failed / Skipped / Total] 449 / 270 / 36 / 755:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 756/872 [07:57<01:13,  1.58it/s][Succeeded / Failed / Skipped / Total] 450 / 270 / 36 / 756:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 756/872 [07:57<01:13,  1.58it/s][Succeeded / Failed / Skipped / Total] 451 / 270 / 36 / 757:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 757/872 [07:57<01:12,  1.58it/s][Succeeded / Failed / Skipped / Total] 451 / 270 / 36 / 757:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 758/872 [07:58<01:11,  1.59it/s][Succeeded / Failed / Skipped / Total] 452 / 270 / 36 / 758:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 758/872 [07:58<01:11,  1.59it/s][Succeeded / Failed / Skipped / Total] 452 / 271 / 36 / 759:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 759/872 [07:58<01:11,  1.58it/s][Succeeded / Failed / Skipped / Total] 452 / 271 / 36 / 759:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 760/872 [07:59<01:10,  1.58it/s][Succeeded / Failed / Skipped / Total] 453 / 271 / 36 / 760:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 760/872 [07:59<01:10,  1.58it/s][Succeeded / Failed / Skipped / Total] 454 / 271 / 36 / 761:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 761/872 [08:00<01:10,  1.58it/s][Succeeded / Failed / Skipped / Total] 454 / 271 / 36 / 761:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 762/872 [08:00<01:09,  1.58it/s][Succeeded / Failed / Skipped / Total] 455 / 271 / 36 / 762:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 762/872 [08:01<01:09,  1.58it/s][Succeeded / Failed / Skipped / Total] 456 / 271 / 36 / 763:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 763/872 [08:01<01:08,  1.58it/s][Succeeded / Failed / Skipped / Total] 456 / 271 / 36 / 763:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 764/872 [08:02<01:08,  1.58it/s][Succeeded / Failed / Skipped / Total] 456 / 272 / 36 / 764:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 764/872 [08:02<01:08,  1.58it/s][Succeeded / Failed / Skipped / Total] 457 / 272 / 36 / 765:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 765/872 [08:02<01:07,  1.58it/s][Succeeded / Failed / Skipped / Total] 457 / 272 / 36 / 765:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 766/872 [08:03<01:06,  1.58it/s][Succeeded / Failed / Skipped / Total] 458 / 272 / 36 / 766:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 766/872 [08:03<01:06,  1.58it/s][Succeeded / Failed / Skipped / Total] 458 / 273 / 36 / 767:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 767/872 [08:04<01:06,  1.58it/s][Succeeded / Failed / Skipped / Total] 458 / 273 / 36 / 767:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 768/872 [08:04<01:05,  1.58it/s][Succeeded / Failed / Skipped / Total] 458 / 274 / 36 / 768:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 768/872 [08:04<01:05,  1.58it/s][Succeeded / Failed / Skipped / Total] 458 / 275 / 36 / 769:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 769/872 [08:05<01:05,  1.58it/s][Succeeded / Failed / Skipped / Total] 458 / 275 / 36 / 769:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 770/872 [08:06<01:04,  1.58it/s][Succeeded / Failed / Skipped / Total] 458 / 276 / 36 / 770:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 770/872 [08:06<01:04,  1.58it/s][Succeeded / Failed / Skipped / Total] 459 / 276 / 36 / 771:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 771/872 [08:07<01:03,  1.58it/s][Succeeded / Failed / Skipped / Total] 459 / 276 / 36 / 771:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 772/872 [08:07<01:03,  1.58it/s][Succeeded / Failed / Skipped / Total] 460 / 276 / 36 / 772:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 772/872 [08:07<01:03,  1.58it/s][Succeeded / Failed / Skipped / Total] 461 / 276 / 36 / 773:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 773/872 [08:08<01:02,  1.58it/s][Succeeded / Failed / Skipped / Total] 461 / 276 / 36 / 773:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 774/872 [08:08<01:01,  1.58it/s][Succeeded / Failed / Skipped / Total] 461 / 277 / 36 / 774:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 774/872 [08:09<01:01,  1.58it/s][Succeeded / Failed / Skipped / Total] 462 / 277 / 36 / 775:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 775/872 [08:09<01:01,  1.58it/s][Succeeded / Failed / Skipped / Total] 462 / 277 / 36 / 775:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 776/872 [08:10<01:00,  1.58it/s][Succeeded / Failed / Skipped / Total] 463 / 277 / 36 / 776:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 776/872 [08:10<01:00,  1.58it/s][Succeeded / Failed / Skipped / Total] 464 / 277 / 36 / 777:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 777/872 [08:10<01:00,  1.58it/s][Succeeded / Failed / Skipped / Total] 464 / 277 / 36 / 777:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 778/872 [08:11<00:59,  1.58it/s][Succeeded / Failed / Skipped / Total] 464 / 278 / 36 / 778:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 778/872 [08:11<00:59,  1.58it/s][Succeeded / Failed / Skipped / Total] 464 / 279 / 36 / 779:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 779/872 [08:12<00:58,  1.58it/s][Succeeded / Failed / Skipped / Total] 464 / 279 / 36 / 779:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 780/872 [08:13<00:58,  1.58it/s][Succeeded / Failed / Skipped / Total] 465 / 279 / 36 / 780:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 780/872 [08:13<00:58,  1.58it/s][Succeeded / Failed / Skipped / Total] 466 / 279 / 36 / 781:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 781/872 [08:13<00:57,  1.58it/s][Succeeded / Failed / Skipped / Total] 466 / 279 / 36 / 781:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 782/872 [08:14<00:56,  1.58it/s][Succeeded / Failed / Skipped / Total] 467 / 279 / 36 / 782:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 782/872 [08:14<00:56,  1.58it/s][Succeeded / Failed / Skipped / Total] 468 / 279 / 36 / 783:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 783/872 [08:14<00:56,  1.58it/s][Succeeded / Failed / Skipped / Total] 468 / 279 / 36 / 783:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 784/872 [08:15<00:55,  1.58it/s][Succeeded / Failed / Skipped / Total] 468 / 280 / 36 / 784:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 784/872 [08:15<00:55,  1.58it/s][Succeeded / Failed / Skipped / Total] 468 / 281 / 36 / 785:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 785/872 [08:16<00:55,  1.58it/s][Succeeded / Failed / Skipped / Total] 468 / 281 / 36 / 785:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 786/872 [08:17<00:54,  1.58it/s][Succeeded / Failed / Skipped / Total] 468 / 282 / 36 / 786:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 786/872 [08:17<00:54,  1.58it/s][Succeeded / Failed / Skipped / Total] 469 / 282 / 36 / 787:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 787/872 [08:18<00:53,  1.58it/s][Succeeded / Failed / Skipped / Total] 469 / 282 / 36 / 787:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 788/872 [08:18<00:53,  1.58it/s][Succeeded / Failed / Skipped / Total] 470 / 282 / 36 / 788:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 788/872 [08:18<00:53,  1.58it/s][Succeeded / Failed / Skipped / Total] 470 / 283 / 36 / 789:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 789/872 [08:19<00:52,  1.58it/s][Succeeded / Failed / Skipped / Total] 470 / 283 / 36 / 789:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 790/872 [08:20<00:51,  1.58it/s][Succeeded / Failed / Skipped / Total] 471 / 283 / 36 / 790:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 790/872 [08:20<00:51,  1.58it/s][Succeeded / Failed / Skipped / Total] 472 / 283 / 36 / 791:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 791/872 [08:20<00:51,  1.58it/s][Succeeded / Failed / Skipped / Total] 472 / 283 / 36 / 791:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 792/872 [08:20<00:50,  1.58it/s][Succeeded / Failed / Skipped / Total] 472 / 283 / 37 / 792:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 792/872 [08:20<00:50,  1.58it/s][Succeeded / Failed / Skipped / Total] 472 / 284 / 37 / 793:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 793/872 [08:21<00:49,  1.58it/s][Succeeded / Failed / Skipped / Total] 472 / 284 / 37 / 793:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 794/872 [08:22<00:49,  1.58it/s][Succeeded / Failed / Skipped / Total] 473 / 284 / 37 / 794:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 794/872 [08:22<00:49,  1.58it/s][Succeeded / Failed / Skipped / Total] 473 / 285 / 37 / 795:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 795/872 [08:23<00:48,  1.58it/s][Succeeded / Failed / Skipped / Total] 473 / 285 / 37 / 795:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 796/872 [08:23<00:48,  1.58it/s][Succeeded / Failed / Skipped / Total] 474 / 285 / 37 / 796:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 796/872 [08:23<00:48,  1.58it/s][Succeeded / Failed / Skipped / Total] 475 / 285 / 37 / 797:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 797/872 [08:24<00:47,  1.58it/s][Succeeded / Failed / Skipped / Total] 475 / 285 / 37 / 797:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 798/872 [08:24<00:46,  1.58it/s][Succeeded / Failed / Skipped / Total] 476 / 285 / 37 / 798:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 798/872 [08:24<00:46,  1.58it/s][Succeeded / Failed / Skipped / Total] 477 / 285 / 37 / 799:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 799/872 [08:25<00:46,  1.58it/s][Succeeded / Failed / Skipped / Total] 477 / 285 / 37 / 799:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 800/872 [08:26<00:45,  1.58it/s][Succeeded / Failed / Skipped / Total] 477 / 286 / 37 / 800:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 800/872 [08:26<00:45,  1.58it/s][Succeeded / Failed / Skipped / Total] 478 / 286 / 37 / 801:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 801/872 [08:26<00:44,  1.58it/s][Succeeded / Failed / Skipped / Total] 478 / 286 / 37 / 801:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 802/872 [08:27<00:44,  1.58it/s][Succeeded / Failed / Skipped / Total] 479 / 286 / 37 / 802:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 802/872 [08:27<00:44,  1.58it/s][Succeeded / Failed / Skipped / Total] 480 / 286 / 37 / 803:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 803/872 [08:27<00:43,  1.58it/s][Succeeded / Failed / Skipped / Total] 480 / 286 / 37 / 803:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 804/872 [08:28<00:42,  1.58it/s][Succeeded / Failed / Skipped / Total] 481 / 286 / 37 / 804:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 804/872 [08:28<00:43,  1.58it/s][Succeeded / Failed / Skipped / Total] 482 / 286 / 37 / 805:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 805/872 [08:28<00:42,  1.58it/s][Succeeded / Failed / Skipped / Total] 482 / 286 / 37 / 805:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 806/872 [08:29<00:41,  1.58it/s][Succeeded / Failed / Skipped / Total] 483 / 286 / 37 / 806:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 806/872 [08:29<00:41,  1.58it/s][Succeeded / Failed / Skipped / Total] 483 / 287 / 37 / 807:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 807/872 [08:30<00:41,  1.58it/s][Succeeded / Failed / Skipped / Total] 483 / 287 / 37 / 807:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 808/872 [08:30<00:40,  1.58it/s][Succeeded / Failed / Skipped / Total] 483 / 288 / 37 / 808:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 808/872 [08:30<00:40,  1.58it/s][Succeeded / Failed / Skipped / Total] 483 / 289 / 37 / 809:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 809/872 [08:31<00:39,  1.58it/s][Succeeded / Failed / Skipped / Total] 483 / 289 / 37 / 809:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 810/872 [08:32<00:39,  1.58it/s][Succeeded / Failed / Skipped / Total] 483 / 290 / 37 / 810:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 810/872 [08:32<00:39,  1.58it/s][Succeeded / Failed / Skipped / Total] 483 / 291 / 37 / 811:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 811/872 [08:33<00:38,  1.58it/s][Succeeded / Failed / Skipped / Total] 483 / 291 / 37 / 811:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 812/872 [08:33<00:37,  1.58it/s][Succeeded / Failed / Skipped / Total] 484 / 291 / 37 / 812:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 812/872 [08:33<00:37,  1.58it/s][Succeeded / Failed / Skipped / Total] 485 / 291 / 37 / 813:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 813/872 [08:34<00:37,  1.58it/s][Succeeded / Failed / Skipped / Total] 485 / 291 / 37 / 813:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 814/872 [08:35<00:36,  1.58it/s][Succeeded / Failed / Skipped / Total] 486 / 291 / 37 / 814:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 814/872 [08:35<00:36,  1.58it/s][Succeeded / Failed / Skipped / Total] 487 / 291 / 37 / 815:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 815/872 [08:35<00:36,  1.58it/s][Succeeded / Failed / Skipped / Total] 487 / 291 / 37 / 815:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 816/872 [08:36<00:35,  1.58it/s][Succeeded / Failed / Skipped / Total] 487 / 292 / 37 / 816:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 816/872 [08:36<00:35,  1.58it/s][Succeeded / Failed / Skipped / Total] 487 / 293 / 37 / 817:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 817/872 [08:37<00:34,  1.58it/s][Succeeded / Failed / Skipped / Total] 487 / 293 / 37 / 817:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 818/872 [08:38<00:34,  1.58it/s][Succeeded / Failed / Skipped / Total] 487 / 294 / 37 / 818:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 818/872 [08:38<00:34,  1.58it/s][Succeeded / Failed / Skipped / Total] 488 / 294 / 37 / 819:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 819/872 [08:38<00:33,  1.58it/s][Succeeded / Failed / Skipped / Total] 488 / 294 / 37 / 819:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 820/872 [08:38<00:32,  1.58it/s][Succeeded / Failed / Skipped / Total] 488 / 294 / 38 / 820:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 820/872 [08:38<00:32,  1.58it/s][Succeeded / Failed / Skipped / Total] 488 / 295 / 38 / 821:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 821/872 [08:39<00:32,  1.58it/s][Succeeded / Failed / Skipped / Total] 488 / 295 / 38 / 821:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 822/872 [08:40<00:31,  1.58it/s][Succeeded / Failed / Skipped / Total] 488 / 296 / 38 / 822:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 822/872 [08:40<00:31,  1.58it/s][Succeeded / Failed / Skipped / Total] 489 / 296 / 38 / 823:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 823/872 [08:40<00:31,  1.58it/s][Succeeded / Failed / Skipped / Total] 489 / 296 / 38 / 823:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 824/872 [08:41<00:30,  1.58it/s][Succeeded / Failed / Skipped / Total] 490 / 296 / 38 / 824:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 824/872 [08:41<00:30,  1.58it/s][Succeeded / Failed / Skipped / Total] 491 / 296 / 38 / 825:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 825/872 [08:41<00:29,  1.58it/s][Succeeded / Failed / Skipped / Total] 491 / 296 / 38 / 825:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 826/872 [08:42<00:29,  1.58it/s][Succeeded / Failed / Skipped / Total] 491 / 297 / 38 / 826:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 826/872 [08:42<00:29,  1.58it/s][Succeeded / Failed / Skipped / Total] 491 / 298 / 38 / 827:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 827/872 [08:43<00:28,  1.58it/s][Succeeded / Failed / Skipped / Total] 491 / 298 / 38 / 827:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 828/872 [08:44<00:27,  1.58it/s][Succeeded / Failed / Skipped / Total] 492 / 298 / 38 / 828:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 828/872 [08:44<00:27,  1.58it/s][Succeeded / Failed / Skipped / Total] 493 / 298 / 38 / 829:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 829/872 [08:44<00:27,  1.58it/s][Succeeded / Failed / Skipped / Total] 493 / 298 / 38 / 829:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 830/872 [08:45<00:26,  1.58it/s][Succeeded / Failed / Skipped / Total] 494 / 298 / 38 / 830:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 830/872 [08:45<00:26,  1.58it/s][Succeeded / Failed / Skipped / Total] 494 / 299 / 38 / 831:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 831/872 [08:45<00:25,  1.58it/s][Succeeded / Failed / Skipped / Total] 494 / 299 / 38 / 831:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 832/872 [08:46<00:25,  1.58it/s][Succeeded / Failed / Skipped / Total] 495 / 299 / 38 / 832:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 832/872 [08:46<00:25,  1.58it/s][Succeeded / Failed / Skipped / Total] 495 / 299 / 39 / 833:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 833/872 [08:46<00:24,  1.58it/s][Succeeded / Failed / Skipped / Total] 495 / 299 / 39 / 833:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 834/872 [08:47<00:24,  1.58it/s][Succeeded / Failed / Skipped / Total] 496 / 299 / 39 / 834:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 834/872 [08:47<00:24,  1.58it/s][Succeeded / Failed / Skipped / Total] 497 / 299 / 39 / 835:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 835/872 [08:47<00:23,  1.58it/s][Succeeded / Failed / Skipped / Total] 497 / 299 / 39 / 835:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 836/872 [08:48<00:22,  1.58it/s][Succeeded / Failed / Skipped / Total] 497 / 300 / 39 / 836:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 836/872 [08:48<00:22,  1.58it/s][Succeeded / Failed / Skipped / Total] 498 / 300 / 39 / 837:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 837/872 [08:49<00:22,  1.58it/s][Succeeded / Failed / Skipped / Total] 498 / 300 / 39 / 837:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 838/872 [08:50<00:21,  1.58it/s][Succeeded / Failed / Skipped / Total] 498 / 301 / 39 / 838:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 838/872 [08:50<00:21,  1.58it/s][Succeeded / Failed / Skipped / Total] 499 / 301 / 39 / 839:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 839/872 [08:50<00:20,  1.58it/s][Succeeded / Failed / Skipped / Total] 499 / 301 / 39 / 839:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 840/872 [08:50<00:20,  1.58it/s][Succeeded / Failed / Skipped / Total] 500 / 301 / 39 / 840:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 840/872 [08:50<00:20,  1.58it/s][Succeeded / Failed / Skipped / Total] 501 / 301 / 39 / 841:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 841/872 [08:51<00:19,  1.58it/s][Succeeded / Failed / Skipped / Total] 501 / 301 / 39 / 841:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 842/872 [08:52<00:18,  1.58it/s][Succeeded / Failed / Skipped / Total] 502 / 301 / 39 / 842:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 842/872 [08:52<00:18,  1.58it/s][Succeeded / Failed / Skipped / Total] 503 / 301 / 39 / 843:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 843/872 [08:52<00:18,  1.58it/s][Succeeded / Failed / Skipped / Total] 503 / 301 / 39 / 843:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 844/872 [08:53<00:17,  1.58it/s][Succeeded / Failed / Skipped / Total] 504 / 301 / 39 / 844:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 844/872 [08:53<00:17,  1.58it/s][Succeeded / Failed / Skipped / Total] 505 / 301 / 39 / 845:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 845/872 [08:53<00:17,  1.58it/s][Succeeded / Failed / Skipped / Total] 505 / 301 / 39 / 845:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 846/872 [08:54<00:16,  1.58it/s][Succeeded / Failed / Skipped / Total] 506 / 301 / 39 / 846:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 846/872 [08:54<00:16,  1.58it/s][Succeeded / Failed / Skipped / Total] 506 / 301 / 40 / 847:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 847/872 [08:54<00:15,  1.58it/s][Succeeded / Failed / Skipped / Total] 506 / 301 / 40 / 847:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 848/872 [08:55<00:15,  1.58it/s][Succeeded / Failed / Skipped / Total] 507 / 301 / 40 / 848:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 848/872 [08:55<00:15,  1.58it/s][Succeeded / Failed / Skipped / Total] 507 / 302 / 40 / 849:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 849/872 [08:56<00:14,  1.58it/s][Succeeded / Failed / Skipped / Total] 507 / 302 / 40 / 849:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 850/872 [08:56<00:13,  1.58it/s][Succeeded / Failed / Skipped / Total] 508 / 302 / 40 / 850:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 850/872 [08:56<00:13,  1.58it/s][Succeeded / Failed / Skipped / Total] 508 / 302 / 41 / 851:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 851/872 [08:56<00:13,  1.58it/s][Succeeded / Failed / Skipped / Total] 508 / 302 / 41 / 851:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 852/872 [08:57<00:12,  1.59it/s][Succeeded / Failed / Skipped / Total] 509 / 302 / 41 / 852:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 852/872 [08:57<00:12,  1.59it/s][Succeeded / Failed / Skipped / Total] 510 / 302 / 41 / 853:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 853/872 [08:57<00:11,  1.59it/s][Succeeded / Failed / Skipped / Total] 510 / 302 / 41 / 853:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 854/872 [08:58<00:11,  1.59it/s][Succeeded / Failed / Skipped / Total] 511 / 302 / 41 / 854:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 854/872 [08:58<00:11,  1.59it/s][Succeeded / Failed / Skipped / Total] 512 / 302 / 41 / 855:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 855/872 [08:59<00:10,  1.59it/s][Succeeded / Failed / Skipped / Total] 512 / 302 / 41 / 855:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 856/872 [08:59<00:10,  1.59it/s][Succeeded / Failed / Skipped / Total] 512 / 303 / 41 / 856:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 856/872 [08:59<00:10,  1.59it/s][Succeeded / Failed / Skipped / Total] 513 / 303 / 41 / 857:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 857/872 [09:00<00:09,  1.59it/s][Succeeded / Failed / Skipped / Total] 513 / 303 / 41 / 857:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 858/872 [09:01<00:08,  1.58it/s][Succeeded / Failed / Skipped / Total] 513 / 304 / 41 / 858:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 858/872 [09:01<00:08,  1.58it/s][Succeeded / Failed / Skipped / Total] 514 / 304 / 41 / 859:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 859/872 [09:02<00:08,  1.58it/s][Succeeded / Failed / Skipped / Total] 514 / 304 / 41 / 859:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 860/872 [09:03<00:07,  1.58it/s][Succeeded / Failed / Skipped / Total] 514 / 305 / 41 / 860:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 860/872 [09:03<00:07,  1.58it/s][Succeeded / Failed / Skipped / Total] 514 / 306 / 41 / 861:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 861/872 [09:04<00:06,  1.58it/s][Succeeded / Failed / Skipped / Total] 514 / 306 / 41 / 861:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 862/872 [09:05<00:06,  1.58it/s][Succeeded / Failed / Skipped / Total] 515 / 306 / 41 / 862:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 862/872 [09:05<00:06,  1.58it/s][Succeeded / Failed / Skipped / Total] 516 / 306 / 41 / 863:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 863/872 [09:05<00:05,  1.58it/s][Succeeded / Failed / Skipped / Total] 516 / 306 / 41 / 863:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 864/872 [09:06<00:05,  1.58it/s][Succeeded / Failed / Skipped / Total] 517 / 306 / 41 / 864:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 864/872 [09:06<00:05,  1.58it/s][Succeeded / Failed / Skipped / Total] 518 / 306 / 41 / 865:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 865/872 [09:07<00:04,  1.58it/s][Succeeded / Failed / Skipped / Total] 518 / 306 / 41 / 865:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 866/872 [09:07<00:03,  1.58it/s][Succeeded / Failed / Skipped / Total] 518 / 306 / 42 / 866:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 866/872 [09:07<00:03,  1.58it/s][Succeeded / Failed / Skipped / Total] 518 / 307 / 42 / 867:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 867/872 [09:07<00:03,  1.58it/s][Succeeded / Failed / Skipped / Total] 518 / 307 / 42 / 867: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 868/872 [09:08<00:02,  1.58it/s][Succeeded / Failed / Skipped / Total] 519 / 307 / 42 / 868: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 868/872 [09:08<00:02,  1.58it/s][Succeeded / Failed / Skipped / Total] 519 / 308 / 42 / 869: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 869/872 [09:09<00:01,  1.58it/s][Succeeded / Failed / Skipped / Total] 519 / 308 / 42 / 869: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 870/872 [09:09<00:01,  1.58it/s][Succeeded / Failed / Skipped / Total] 520 / 308 / 42 / 870: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 870/872 [09:09<00:01,  1.58it/s][Succeeded / Failed / Skipped / Total] 521 / 308 / 42 / 871: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 871/872 [09:10<00:00,  1.58it/s][Succeeded / Failed / Skipped / Total] 521 / 308 / 42 / 871: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 872/872 [09:11<00:00,  1.58it/s][Succeeded / Failed / Skipped / Total] 521 / 309 / 42 / 872: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 872/872 [09:11<00:00,  1.58it/s][Succeeded / Failed / Skipped / Total] 521 / 309 / 42 / 872: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 872/872 [09:11<00:00,  1.58it/s]
wandb: - 1435.205 MB of 1435.205 MB uploadedwandb: \ 1435.205 MB of 1435.205 MB uploadedwandb: | 1428.669 MB of 1435.205 MB uploadedwandb: / 1434.298 MB of 1435.216 MB uploadedwandb: - 1435.216 MB of 1435.216 MB uploadedTraceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 261, in hf_raise_for_status
    response.raise_for_status()
  File "/usr/local/lib/python3.8/dist-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/gpt2/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/file_download.py", line 1232, in hf_hub_download
    metadata = get_hf_file_metadata(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/file_download.py", line 1608, in get_hf_file_metadata
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/gpt2/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/transformers/src/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/file_download.py", line 1349, in hf_hub_download
    raise LocalEntryNotFoundError(
huggingface_hub.utils._errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 298, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 226, in _attack
    self.attack_log_manager.log_summary()
  File "/src/textattack/textattack/loggers/attack_log_manager.py", line 149, in log_summary
    perplexity_stats = Perplexity().calculate(self.results)
  File "/src/textattack/textattack/metrics/quality_metrics/perplexity.py", line 25, in __init__
    self.ppl_model = GPT2LMHeadModel.from_pretrained("gpt2")
  File "/transformers/src/transformers/modeling_utils.py", line 2682, in from_pretrained
    config, model_kwargs = cls.config_class.from_pretrained(
  File "/transformers/src/transformers/configuration_utils.py", line 592, in from_pretrained
    config_dict, kwargs = cls.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/transformers/src/transformers/configuration_utils.py", line 621, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/transformers/src/transformers/configuration_utils.py", line 676, in _get_config_dict
    resolved_config_file = cached_file(
  File "/transformers/src/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like gpt2 is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.
42+4+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-42-shot-4
2024-01-26 13:13:32.120624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:13:32.979070: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:13:40.632449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:40.644148: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:40.646599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:40.667134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:40.669530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:40.671866: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:40.881922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:40.883640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:40.885124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:40.886626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
2024-01-26 13:13:45.824289: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:13:46.659421: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:13:54.070470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:54.082307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:54.084745: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:54.103953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:54.106371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:54.108720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:54.318518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:54.320154: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:54.321606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:13:54.323063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
1+16+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-1-shot-16
2024-01-26 13:13:59.341394: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:14:00.219622: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:14:07.639241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:07.651010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:07.653491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:07.673964: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:07.676371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:07.678708: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:07.892444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:07.894129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:07.897341: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:07.898986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
2024-01-26 13:14:12.737222: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:14:13.614286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:14:20.963479: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:20.975308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:20.977738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:20.997116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:20.999514: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:21.001857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:21.214343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:21.216113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:21.217579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:21.219067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
13+16+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-13-shot-16
2024-01-26 13:14:26.934109: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:14:27.814428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:14:35.199210: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:35.210706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:35.213194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:35.233286: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:35.235683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:35.238026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:35.455258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:35.456979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:35.458441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:35.459933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
2024-01-26 13:14:40.342638: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:14:41.226136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:14:48.770842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:48.782339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:48.784785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:48.805766: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:48.808164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:48.810505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:49.023335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:49.025068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:49.026545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:14:49.028045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
42+16+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/icl-seed-42-shot-16
2024-01-26 13:14:54.014424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:14:54.909878: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:15:02.491062: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:02.502784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:02.505232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:02.526081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:02.528486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:02.530849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:02.744389: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:02.746420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:02.747922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:02.749427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
2024-01-26 13:15:07.733483: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-26 13:15:08.585994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-01-26 13:15:16.085067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:16.096723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:16.099196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:16.118752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:16.121156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:16.123500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:16.337907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:16.339612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:16.341100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-01-26 13:15:16.342580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38375 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:253: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/data/mvp/src/test.py", line 106, in attacker
    my_dataset, tokenizer, data_collator = prepare_huggingface_dataset(args)
  File "/mnt/data/mvp/src/utils/funcs.py", line 91, in prepare_huggingface_dataset
    my_dataset = load_dataset("glue",name)
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 2129, in load_dataset
    builder_instance = load_dataset_builder(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1815, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1512, in dataset_module_factory
    raise e1 from None
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1479, in dataset_module_factory
    raise e
  File "/usr/local/lib/python3.8/dist-packages/datasets/load.py", line 1453, in dataset_module_factory
    dataset_info = hf_api.dataset_info(
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/hf_api.py", line 1761, in dataset_info
    hf_raise_for_status(r)
  File "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_errors.py", line 303, in hf_raise_for_status
    raise HfHubHTTPError(str(e), response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/datasets/glue
