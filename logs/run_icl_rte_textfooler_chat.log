nohup: ignoring input
1+8+meta-llama/Llama-2-7b-chat-hf+mvp
./checkpoints/rte/meta-llama/Llama-2-7b-chat-hf/textfooler/icl-seed-1-shot-8
2024-03-14 15:21:20.754955: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-03-14 15:21:20.832879: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-14 15:21:33.038590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 37631 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:261: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
/mnt/data/robust/lib/python3.8/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.
  warnings.warn(
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  5.08it/s]Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.13it/s]Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.12it/s]
The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:21<00:21, 21.90s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:29<00:00, 13.60s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:29<00:00, 14.84s/it]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/rte/meta-llama/Llama-2-7b-chat-hf/textfooler/icl-seed-1-shot-8/textfooler_log.csv
  0% 0/277 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
2024-03-14 15:22:52.970921: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
  0% 1/277 [00:18<1:24:59, 18.47s/it][Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   0% 1/277 [00:19<1:28:07, 19.16s/it][Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   1% 2/277 [00:19<44:15,  9.66s/it]  [Succeeded / Failed / Skipped / Total] 0 / 1 / 1 / 2:   1% 2/277 [00:19<44:18,  9.67s/it][Succeeded / Failed / Skipped / Total] 0 / 1 / 1 / 2:   1% 3/277 [00:32<48:57, 10.72s/it][Succeeded / Failed / Skipped / Total] 0 / 2 / 1 / 3:   1% 3/277 [00:32<49:00, 10.73s/it][Succeeded / Failed / Skipped / Total] 0 / 2 / 1 / 3:   1% 4/277 [00:44<50:29, 11.10s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 1 / 4:   1% 4/277 [00:44<50:31, 11.10s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 1 / 4:   2% 5/277 [00:44<40:24,  8.91s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 2 / 5:   2% 5/277 [00:44<40:25,  8.92s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 2 / 5:   2% 6/277 [00:44<33:41,  7.46s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 3 / 6:   2% 6/277 [00:44<33:42,  7.46s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 3 / 6:   3% 7/277 [00:44<28:52,  6.42s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 4 / 7:   3% 7/277 [00:44<28:53,  6.42s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 4 / 7:   3% 8/277 [00:45<25:16,  5.64s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 5 / 8:   3% 8/277 [00:45<25:17,  5.64s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 5 / 8:   3% 9/277 [00:45<22:28,  5.03s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 6 / 9:   3% 9/277 [00:45<22:28,  5.03s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 6 / 9:   4% 10/277 [00:45<20:13,  4.55s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 7 / 10:   4% 10/277 [00:45<20:14,  4.55s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 7 / 10:   4% 11/277 [00:45<18:23,  4.15s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 8 / 11:   4% 11/277 [00:45<18:23,  4.15s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 8 / 11:   4% 12/277 [00:53<19:46,  4.48s/it][Succeeded / Failed / Skipped / Total] 0 / 4 / 8 / 12:   4% 12/277 [00:53<19:47,  4.48s/it][Succeeded / Failed / Skipped / Total] 0 / 4 / 8 / 12:   5% 13/277 [01:06<22:36,  5.14s/it][Succeeded / Failed / Skipped / Total] 0 / 5 / 8 / 13:   5% 13/277 [01:06<22:36,  5.14s/it][Succeeded / Failed / Skipped / Total] 0 / 5 / 8 / 13:   5% 14/277 [01:06<20:58,  4.78s/it][Succeeded / Failed / Skipped / Total] 0 / 5 / 9 / 14:   5% 14/277 [01:06<20:58,  4.79s/it][Succeeded / Failed / Skipped / Total] 0 / 5 / 9 / 14:   5% 15/277 [01:07<19:32,  4.48s/it][Succeeded / Failed / Skipped / Total] 0 / 5 / 10 / 15:   5% 15/277 [01:07<19:33,  4.48s/it]/mnt/data/robust/lib/python3.8/multiprocessing/resource_tracker.py:203: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
