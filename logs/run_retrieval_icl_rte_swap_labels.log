nohup: ignoring input
1+8+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/rte/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-8
2024-03-14 02:25:23.900001: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-03-14 02:25:23.968308: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-14 02:25:36.398592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 37631 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:05.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:261: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
/mnt/data/robust/lib/python3.8/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.
  warnings.warn(
The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.55s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.05s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.12s/it]
Map:   0%|          | 0/277 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277/277 [00:00<00:00, 4179.85 examples/s]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/rte/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-8_sbert/swap_labels_log.csv
  0% 0/277 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  0% 1/277 [00:01<08:19,  1.81s/it][Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:   0% 1/277 [00:02<10:15,  2.23s/it][Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:   1% 2/277 [00:02<05:23,  1.18s/it][Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:   1% 2/277 [00:02<05:37,  1.23s/it][Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:   1% 3/277 [00:05<07:59,  1.75s/it][Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:   1% 3/277 [00:05<08:11,  1.79s/it][Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:   1% 4/277 [00:21<24:21,  5.35s/it][Succeeded / Failed / Skipped / Total] 2 / 0 / 2 / 4:   1% 4/277 [00:21<24:31,  5.39s/it][Succeeded / Failed / Skipped / Total] 2 / 0 / 2 / 4:   2% 5/277 [00:26<24:23,  5.38s/it][Succeeded / Failed / Skipped / Total] 3 / 0 / 2 / 5:   2% 5/277 [00:27<24:30,  5.40s/it][Succeeded / Failed / Skipped / Total] 3 / 0 / 2 / 5:   2% 6/277 [00:35<26:26,  5.85s/it][Succeeded / Failed / Skipped / Total] 4 / 0 / 2 / 6:   2% 6/277 [00:35<26:32,  5.87s/it][Succeeded / Failed / Skipped / Total] 4 / 0 / 2 / 6:   3% 7/277 [00:44<28:39,  6.37s/it][Succeeded / Failed / Skipped / Total] 5 / 0 / 2 / 7:   3% 7/277 [00:44<28:45,  6.39s/it][Succeeded / Failed / Skipped / Total] 5 / 0 / 2 / 7:   3% 8/277 [00:50<28:21,  6.33s/it][Succeeded / Failed / Skipped / Total] 6 / 0 / 2 / 8:   3% 8/277 [00:50<28:26,  6.34s/it]/mnt/data/robust/lib/python3.8/multiprocessing/resource_tracker.py:203: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
