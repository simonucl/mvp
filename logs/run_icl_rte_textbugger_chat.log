nohup: ignoring input
1+8+meta-llama/Llama-2-7b-chat-hf+mvp
./checkpoints/rte/meta-llama/Llama-2-7b-chat-hf/textbugger/icl-seed-1-shot-8
2024-03-14 15:48:26.890330: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-03-14 15:48:26.970552: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-14 15:48:39.286517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 37631 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:05.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:261: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
/mnt/data/robust/lib/python3.8/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.
  warnings.warn(
The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:21<00:21, 21.84s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:27<00:00, 12.18s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:27<00:00, 13.63s/it]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/rte/meta-llama/Llama-2-7b-chat-hf/textbugger/icl-seed-1-shot-8/textbugger_log.csv
  0% 0/277 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
2024-03-14 15:49:55.037771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
  0% 1/277 [00:47<3:38:14, 47.44s/it][Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   0% 1/277 [00:48<3:41:12, 48.09s/it][Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   1% 2/277 [00:48<1:50:33, 24.12s/it][Succeeded / Failed / Skipped / Total] 0 / 1 / 1 / 2:   1% 2/277 [00:48<1:50:36, 24.13s/it][Succeeded / Failed / Skipped / Total] 0 / 1 / 1 / 2:   1% 3/277 [03:35<5:28:15, 71.88s/it][Succeeded / Failed / Skipped / Total] 0 / 2 / 1 / 3:   1% 3/277 [03:35<5:28:18, 71.89s/it][Succeeded / Failed / Skipped / Total] 0 / 2 / 1 / 3:   1% 4/277 [06:06<6:57:22, 91.73s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 1 / 4:   1% 4/277 [06:06<6:57:25, 91.74s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 1 / 4:   2% 5/277 [06:07<5:32:51, 73.42s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 2 / 5:   2% 5/277 [06:07<5:32:52, 73.43s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 2 / 5:   2% 6/277 [06:07<4:36:29, 61.22s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 3 / 6:   2% 6/277 [06:07<4:36:30, 61.22s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 3 / 6:   3% 7/277 [06:07<3:56:14, 52.50s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 4 / 7:   3% 7/277 [06:07<3:56:15, 52.50s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 4 / 7:   3% 8/277 [06:07<3:26:02, 45.96s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 5 / 8:   3% 8/277 [06:07<3:26:03, 45.96s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 5 / 8:   3% 9/277 [06:07<3:02:33, 40.87s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 6 / 9:   3% 9/277 [06:07<3:02:34, 40.87s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 6 / 9:   4% 10/277 [06:08<2:43:46, 36.80s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 7 / 10:   4% 10/277 [06:08<2:43:46, 36.80s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 7 / 10:   4% 11/277 [06:08<2:28:23, 33.47s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 8 / 11:   4% 11/277 [06:08<2:28:24, 33.48s/it][Succeeded / Failed / Skipped / Total] 0 / 3 / 8 / 11:   4% 12/277 [06:22<2:20:54, 31.90s/it][Succeeded / Failed / Skipped / Total] 0 / 4 / 8 / 12:   4% 12/277 [06:22<2:20:55, 31.91s/it][Succeeded / Failed / Skipped / Total] 0 / 4 / 8 / 12:   5% 13/277 [06:38<2:14:48, 30.64s/it][Succeeded / Failed / Skipped / Total] 0 / 5 / 8 / 13:   5% 13/277 [06:38<2:14:48, 30.64s/it][Succeeded / Failed / Skipped / Total] 0 / 5 / 8 / 13:   5% 14/277 [06:38<2:04:45, 28.46s/it][Succeeded / Failed / Skipped / Total] 0 / 5 / 9 / 14:   5% 14/277 [06:38<2:04:45, 28.46s/it][Succeeded / Failed / Skipped / Total] 0 / 5 / 9 / 14:   5% 15/277 [06:38<1:56:02, 26.58s/it][Succeeded / Failed / Skipped / Total] 0 / 5 / 10 / 15:   5% 15/277 [06:38<1:56:03, 26.58s/it][Succeeded / Failed / Skipped / Total] 0 / 5 / 10 / 15:   6% 16/277 [07:15<1:58:18, 27.20s/it][Succeeded / Failed / Skipped / Total] 0 / 6 / 10 / 16:   6% 16/277 [07:15<1:58:18, 27.20s/it]/mnt/data/robust/lib/python3.8/multiprocessing/resource_tracker.py:203: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
