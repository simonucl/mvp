nohup: ignoring input
1+16+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16
2023-11-21 18:09:50.839694: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-21 18:09:51.572737: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-11-21 18:09:58.091050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:09:58.101136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:09:58.103693: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:09:58.114116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:09:58.116598: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:09:58.119077: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:09:58.378640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:09:58.380466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:09:58.382037: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:09:58.383616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38376 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/ceph_rbd/mvp/src/utils/funcs.py:242: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
1
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='cr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=True, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='int8', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='bm25', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_cr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_cr.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, cache_dir='./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='cr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=True, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='int8', prompt_num=2, query_budget=-1, ralm_save_path='./data/ralm/cr_bm25.pkl', replace_ratio=0.1, retrieve_method='bm25', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_cr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_cr.yaml', weight_decay=0.01)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.51s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.03s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.10s/it]
Tokenizing anchor data:   0%|          | 0/3224 [00:00<?, ?it/s]Tokenizing anchor data:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1298/3224 [00:00<00:00, 12973.45it/s]Tokenizing anchor data:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2647/3224 [00:00<00:00, 13273.94it/s]Tokenizing anchor data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3224/3224 [00:00<00:00, 13249.22it/s]
Finished encoding anchor data
Saving retrieved examples to ./data/ralm/cr_bm25.pkl
Length of anchor subsample 0
Length of icl examples 376
Finished loading model
Loading retrieved examples from ./data/ralm/cr_bm25.pkl
2023-11-21 18:10:19.131424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-21 18:10:19.921037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-11-21 18:10:26.360217: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:26.368113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:26.370500: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:26.384036: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:26.386398: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:26.388726: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:26.556530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:26.558116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:26.559559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:26.561006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38376 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/ceph_rbd/mvp/src/utils/funcs.py:242: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
1
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='cr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=True, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_sbert', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='int8', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='sbert', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_cr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_cr.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_sbert
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, cache_dir='./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_sbert/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='cr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=True, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_sbert', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='int8', prompt_num=2, query_budget=-1, ralm_save_path='./data/ralm/cr_sbert.pkl', replace_ratio=0.1, retrieve_method='sbert', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_cr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_cr.yaml', weight_decay=0.01)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.51s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.02s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.10s/it]
Batches:   0%|          | 0/26 [00:00<?, ?it/s]Batches:   4%|â–         | 1/26 [00:00<00:03,  7.99it/s]Batches:  35%|â–ˆâ–ˆâ–ˆâ–      | 9/26 [00:00<00:00, 43.54it/s]Batches:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 17/26 [00:00<00:00, 57.70it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:00<00:00, 67.59it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:00<00:00, 57.78it/s]
Finished encoding anchor data
anchor_data_embeddings shape: torch.Size([3224, 384])
query_embedding shape: torch.Size([376, 384])
cos_scores shape: torch.Size([376, 3224])
top_results shape: torch.Size([376, 64]), torch.Size([376, 64])
Saving retrieved examples to ./data/ralm/cr_sbert.pkl
Length of anchor subsample 0
Length of icl examples 376
Finished loading model
Loading retrieved examples from ./data/ralm/cr_sbert.pkl
2023-11-21 18:10:45.417984: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-21 18:10:46.189864: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-11-21 18:10:52.741701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:52.749528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:52.751914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:52.765595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:52.767943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:52.770253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:52.939243: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:52.940840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:52.942280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:10:52.943727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38376 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/ceph_rbd/mvp/src/utils/funcs.py:242: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
1
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='cr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=True, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_instructor', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='int8', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='instructor', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_cr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_cr.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_instructor
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, cache_dir='./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_instructor/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='cr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=True, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/cr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_instructor', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='int8', prompt_num=2, query_budget=-1, ralm_save_path='./data/ralm/cr_instructor.pkl', replace_ratio=0.1, retrieve_method='instructor', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_cr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_cr.yaml', weight_decay=0.01)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.55s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.04s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.12s/it]
load INSTRUCTOR_Transformer
max_seq_length  512
Batches:   0%|          | 0/26 [00:00<?, ?it/s]Batches:   4%|â–         | 1/26 [00:00<00:22,  1.12it/s]Batches:   8%|â–Š         | 2/26 [00:01<00:15,  1.57it/s]Batches:  12%|â–ˆâ–        | 3/26 [00:01<00:12,  1.87it/s]Batches:  15%|â–ˆâ–Œ        | 4/26 [00:02<00:10,  2.14it/s]Batches:  19%|â–ˆâ–‰        | 5/26 [00:02<00:09,  2.26it/s]Batches:  23%|â–ˆâ–ˆâ–Ž       | 6/26 [00:02<00:08,  2.47it/s]Batches:  27%|â–ˆâ–ˆâ–‹       | 7/26 [00:03<00:07,  2.58it/s]Batches:  31%|â–ˆâ–ˆâ–ˆ       | 8/26 [00:03<00:06,  2.80it/s]Batches:  35%|â–ˆâ–ˆâ–ˆâ–      | 9/26 [00:03<00:05,  2.93it/s]Batches:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 10/26 [00:04<00:05,  3.08it/s]Batches:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/26 [00:04<00:04,  3.16it/s]Batches:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 12/26 [00:04<00:04,  3.31it/s]Batches:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 13/26 [00:04<00:03,  3.28it/s]Batches:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/26 [00:05<00:03,  3.54it/s]Batches:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 15/26 [00:05<00:02,  3.76it/s]Batches:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/26 [00:05<00:02,  3.97it/s]Batches:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 17/26 [00:05<00:02,  4.13it/s]Batches:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 18/26 [00:06<00:01,  4.36it/s]Batches:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 19/26 [00:06<00:01,  4.59it/s]Batches:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 20/26 [00:06<00:01,  4.57it/s]Batches:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 21/26 [00:06<00:01,  4.88it/s]Batches:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/26 [00:06<00:00,  5.05it/s]Batches:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 23/26 [00:07<00:00,  5.26it/s]Batches:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 24/26 [00:07<00:00,  5.53it/s]Batches:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 25/26 [00:07<00:00,  5.89it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:07<00:00,  3.54it/s]
Finished encoding anchor data
anchor_data_embeddings shape: torch.Size([3224, 768])
query shape: 376
query_embedding shape: torch.Size([376, 768])
cos_scores shape: torch.Size([376, 3224])
Saving retrieved examples to ./data/ralm/cr_instructor.pkl
Length of anchor subsample 0
Length of icl examples 376
Finished loading model
Loading retrieved examples from ./data/ralm/cr_instructor.pkl
1+16+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16
2023-11-21 18:11:22.735927: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-21 18:11:23.494365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-11-21 18:11:30.010310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:11:30.018303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:11:30.020727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:11:30.034190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:11:30.036559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:11:30.038887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:11:30.215935: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:11:30.217527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:11:30.218967: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:11:30.220408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38376 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/ceph_rbd/mvp/src/utils/funcs.py:242: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
1
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='mr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=True, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='int8', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='bm25', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_cr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_cr.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, cache_dir='./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='mr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=True, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='int8', prompt_num=2, query_budget=-1, ralm_save_path='./data/ralm/mr_bm25.pkl', replace_ratio=0.1, retrieve_method='bm25', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_cr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_cr.yaml', weight_decay=0.01)
Downloading builder script:   0%|          | 0.00/5.03k [00:00<?, ?B/s]Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.03k/5.03k [00:00<00:00, 34.2MB/s]
Downloading metadata:   0%|          | 0.00/2.02k [00:00<?, ?B/s]Downloading metadata: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.02k/2.02k [00:00<00:00, 17.3MB/s]
Downloading readme:   0%|          | 0.00/7.25k [00:00<?, ?B/s]Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.25k/7.25k [00:00<00:00, 44.9MB/s]
Downloading data:   0%|          | 0.00/488k [00:00<?, ?B/s]Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 488k/488k [00:00<00:00, 5.49MB/s]
Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]Generating train split:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4856/8530 [00:00<00:00, 48459.64 examples/s]Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8530/8530 [00:00<00:00, 51255.20 examples/s]
Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]Generating validation split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1066/1066 [00:00<00:00, 37057.74 examples/s]
Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1066/1066 [00:00<00:00, 36396.80 examples/s]
Map:   0%|          | 0/8530 [00:00<?, ? examples/s]Map:  29%|â–ˆâ–ˆâ–‰       | 2456/8530 [00:00<00:00, 24402.41 examples/s]Map:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4942/8530 [00:00<00:00, 24665.43 examples/s]Map:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7431/8530 [00:00<00:00, 24764.43 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8530/8530 [00:00<00:00, 24572.45 examples/s]
Map:   0%|          | 0/1066 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1066/1066 [00:00<00:00, 23025.33 examples/s]
Map:   0%|          | 0/1066 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1066/1066 [00:00<00:00, 22812.58 examples/s]
Map:   0%|          | 0/8103 [00:00<?, ? examples/s]Map:  17%|â–ˆâ–‹        | 1363/8103 [00:00<00:00, 13552.53 examples/s]Map:  34%|â–ˆâ–ˆâ–ˆâ–      | 2744/8103 [00:00<00:00, 13699.46 examples/s]Map:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 4778/8103 [00:00<00:00, 13616.19 examples/s]Map:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 6792/8103 [00:00<00:00, 13525.89 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8103/8103 [00:00<00:00, 13440.46 examples/s]
Map:   0%|          | 0/1066 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1066/1066 [00:00<00:00, 23163.95 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 24017.96 examples/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.50s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.02s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.09s/it]
Tokenizing anchor data:   0%|          | 0/8103 [00:00<?, ?it/s]Tokenizing anchor data:  14%|â–ˆâ–        | 1164/8103 [00:00<00:00, 11633.22it/s]Tokenizing anchor data:  29%|â–ˆâ–ˆâ–‰       | 2352/8103 [00:00<00:00, 11774.94it/s]Tokenizing anchor data:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3530/8103 [00:00<00:00, 11752.61it/s]Tokenizing anchor data:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 4721/8103 [00:00<00:00, 11811.99it/s]Tokenizing anchor data:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 5904/8103 [00:00<00:00, 11817.56it/s]Tokenizing anchor data:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 7086/8103 [00:00<00:00, 11809.48it/s]Tokenizing anchor data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8103/8103 [00:00<00:00, 11798.93it/s]
Finished encoding anchor data
Saving retrieved examples to ./data/ralm/mr_bm25.pkl
Length of anchor subsample 0
Length of icl examples 1000
Finished loading model
Loading retrieved examples from ./data/ralm/mr_bm25.pkl
2023-11-21 18:12:22.275281: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-21 18:12:23.058344: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-11-21 18:12:29.408961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:29.416624: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:29.418990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:29.432234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:29.434569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:29.436882: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:29.605668: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:29.607269: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:29.608706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:29.610146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38376 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/ceph_rbd/mvp/src/utils/funcs.py:242: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
1
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='mr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=True, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_sbert', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='int8', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='sbert', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_cr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_cr.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_sbert
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, cache_dir='./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_sbert/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='mr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=True, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_sbert', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='int8', prompt_num=2, query_budget=-1, ralm_save_path='./data/ralm/mr_sbert.pkl', replace_ratio=0.1, retrieve_method='sbert', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_cr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_cr.yaml', weight_decay=0.01)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.52s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.03s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.10s/it]
Batches:   0%|          | 0/64 [00:00<?, ?it/s]Batches:   2%|â–         | 1/64 [00:00<00:07,  8.63it/s]Batches:  11%|â–ˆ         | 7/64 [00:00<00:01, 36.64it/s]Batches:  20%|â–ˆâ–ˆ        | 13/64 [00:00<00:01, 45.09it/s]Batches:  31%|â–ˆâ–ˆâ–ˆâ–      | 20/64 [00:00<00:00, 52.59it/s]Batches:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/64 [00:00<00:00, 58.11it/s]Batches:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/64 [00:00<00:00, 63.81it/s]Batches:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 43/64 [00:00<00:00, 66.57it/s]Batches:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 51/64 [00:00<00:00, 68.86it/s]Batches:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/64 [00:00<00:00, 70.34it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:01<00:00, 61.74it/s]
Finished encoding anchor data
anchor_data_embeddings shape: torch.Size([8103, 384])
query_embedding shape: torch.Size([1000, 384])
cos_scores shape: torch.Size([1000, 8103])
top_results shape: torch.Size([1000, 64]), torch.Size([1000, 64])
Saving retrieved examples to ./data/ralm/mr_sbert.pkl
Length of anchor subsample 0
Length of icl examples 1000
Finished loading model
Loading retrieved examples from ./data/ralm/mr_sbert.pkl
2023-11-21 18:12:52.265344: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-21 18:12:52.996459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-11-21 18:12:59.369796: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:59.377702: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:59.380075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:59.393555: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:59.396455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:59.398770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:59.569297: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:59.570907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:59.572347: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-21 18:12:59.573792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38376 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/ceph_rbd/mvp/src/utils/funcs.py:242: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
1
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='mr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=True, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_instructor', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='int8', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='instructor', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_cr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_cr.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_instructor
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, cache_dir='./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_instructor/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='mr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=True, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/mr/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_instructor', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='int8', prompt_num=2, query_budget=-1, ralm_save_path='./data/ralm/mr_instructor.pkl', replace_ratio=0.1, retrieve_method='instructor', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_cr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_cr.yaml', weight_decay=0.01)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.60s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.18s/it]
load INSTRUCTOR_Transformer
max_seq_length  512
Batches:   0%|          | 0/64 [00:00<?, ?it/s]Batches:   2%|â–         | 1/64 [00:00<00:36,  1.72it/s]Batches:   3%|â–Ž         | 2/64 [00:01<00:32,  1.90it/s]Batches:   5%|â–         | 3/64 [00:01<00:30,  2.02it/s]Batches:   6%|â–‹         | 4/64 [00:01<00:27,  2.15it/s]Batches:   8%|â–Š         | 5/64 [00:02<00:26,  2.24it/s]Batches:   9%|â–‰         | 6/64 [00:02<00:25,  2.29it/s]Batches:  11%|â–ˆ         | 7/64 [00:03<00:24,  2.32it/s]Batches:  12%|â–ˆâ–Ž        | 8/64 [00:03<00:25,  2.19it/s]Batches:  14%|â–ˆâ–        | 9/64 [00:04<00:26,  2.11it/s]Batches:  16%|â–ˆâ–Œ        | 10/64 [00:04<00:26,  2.05it/s]Batches:  17%|â–ˆâ–‹        | 11/64 [00:05<00:25,  2.06it/s]Batches:  19%|â–ˆâ–‰        | 12/64 [00:05<00:24,  2.15it/s]Batches:  20%|â–ˆâ–ˆ        | 13/64 [00:06<00:23,  2.17it/s]Batches:  22%|â–ˆâ–ˆâ–       | 14/64 [00:06<00:22,  2.23it/s]Batches:  23%|â–ˆâ–ˆâ–Ž       | 15/64 [00:06<00:22,  2.17it/s]Batches:  25%|â–ˆâ–ˆâ–Œ       | 16/64 [00:07<00:21,  2.23it/s]Batches:  27%|â–ˆâ–ˆâ–‹       | 17/64 [00:07<00:20,  2.34it/s]Batches:  28%|â–ˆâ–ˆâ–Š       | 18/64 [00:08<00:18,  2.46it/s]Batches:  30%|â–ˆâ–ˆâ–‰       | 19/64 [00:08<00:18,  2.40it/s]Batches:  31%|â–ˆâ–ˆâ–ˆâ–      | 20/64 [00:08<00:17,  2.45it/s]Batches:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 21/64 [00:09<00:16,  2.55it/s]Batches:  34%|â–ˆâ–ˆâ–ˆâ–      | 22/64 [00:09<00:15,  2.69it/s]Batches:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 23/64 [00:10<00:15,  2.67it/s]Batches:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/64 [00:10<00:14,  2.72it/s]Batches:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 25/64 [00:10<00:14,  2.68it/s]Batches:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 26/64 [00:11<00:13,  2.72it/s]Batches:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/64 [00:11<00:13,  2.73it/s]Batches:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/64 [00:11<00:13,  2.70it/s]Batches:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/64 [00:12<00:13,  2.67it/s]Batches:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 30/64 [00:12<00:11,  2.84it/s]Batches:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 31/64 [00:12<00:11,  2.83it/s]Batches:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/64 [00:13<00:11,  2.76it/s]Batches:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/64 [00:13<00:10,  2.91it/s]Batches:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 34/64 [00:13<00:10,  2.95it/s]Batches:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/64 [00:14<00:09,  2.98it/s]Batches:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/64 [00:14<00:09,  3.09it/s]Batches:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/64 [00:14<00:08,  3.02it/s]Batches:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 38/64 [00:15<00:08,  3.04it/s]Batches:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 39/64 [00:15<00:07,  3.15it/s]Batches:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 40/64 [00:15<00:07,  3.20it/s]Batches:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 41/64 [00:16<00:07,  3.27it/s]Batches:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 42/64 [00:16<00:06,  3.33it/s]Batches:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 43/64 [00:16<00:06,  3.24it/s]Batches:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/64 [00:17<00:06,  3.29it/s]Batches:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 45/64 [00:17<00:05,  3.32it/s]Batches:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/64 [00:17<00:05,  3.41it/s]Batches:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 47/64 [00:17<00:04,  3.47it/s]Batches:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/64 [00:18<00:04,  3.57it/s]Batches:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 49/64 [00:18<00:04,  3.59it/s]Batches:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 50/64 [00:18<00:03,  3.67it/s]Batches:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 51/64 [00:18<00:03,  3.84it/s]Batches:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/64 [00:19<00:03,  3.70it/s]Batches:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 53/64 [00:19<00:02,  3.86it/s]Batches:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 54/64 [00:19<00:02,  4.01it/s]Batches:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 55/64 [00:19<00:02,  4.11it/s]Batches:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 56/64 [00:20<00:01,  4.32it/s]Batches:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 57/64 [00:20<00:01,  4.39it/s]Batches:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/64 [00:20<00:01,  4.40it/s]Batches:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/64 [00:20<00:01,  4.56it/s]Batches:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 60/64 [00:20<00:00,  4.77it/s]Batches:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 61/64 [00:21<00:00,  4.95it/s]Batches:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 62/64 [00:21<00:00,  5.10it/s]Batches:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 63/64 [00:21<00:00,  5.46it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:21<00:00,  2.98it/s]
Finished encoding anchor data
anchor_data_embeddings shape: torch.Size([8103, 768])
query shape: 1000
query_embedding shape: torch.Size([1000, 768])
cos_scores shape: torch.Size([1000, 8103])
Saving retrieved examples to ./data/ralm/mr_instructor.pkl
Length of anchor subsample 0
Length of icl examples 1000
Finished loading model
Loading retrieved examples from ./data/ralm/mr_instructor.pkl
