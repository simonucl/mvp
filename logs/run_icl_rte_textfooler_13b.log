nohup: ignoring input
1+2+meta-llama/Llama-2-13b-hf+mvp
./checkpoints/rte/meta-llama/Llama-2-13b-hf/textfooler/icl-seed-1-shot-2
2024-03-14 00:08:14.615021: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-03-14 00:08:14.686900: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-14 00:08:27.224202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 37631 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0
/mnt/data/mvp/src/utils/funcs.py:261: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
/mnt/data/robust/lib/python3.8/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.
  warnings.warn(
The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.54s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.61s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.41s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.45s/it]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/rte/meta-llama/Llama-2-13b-hf/textfooler/icl-seed-1-shot-2/textfooler_log.csv
  0% 0/277 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  0% 1/277 [00:01<08:09,  1.77s/it][Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:   0% 1/277 [00:02<09:36,  2.09s/it]2024-03-14 00:09:30.548359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:   1% 2/277 [00:13<31:54,  6.96s/it][Succeeded / Failed / Skipped / Total] 1 / 0 / 1 / 2:   1% 2/277 [00:13<31:57,  6.97s/it][Succeeded / Failed / Skipped / Total] 1 / 0 / 1 / 2:   1% 3/277 [00:20<31:07,  6.81s/it][Succeeded / Failed / Skipped / Total] 2 / 0 / 1 / 3:   1% 3/277 [00:20<31:09,  6.82s/it][Succeeded / Failed / Skipped / Total] 2 / 0 / 1 / 3:   1% 4/277 [00:20<23:22,  5.14s/it][Succeeded / Failed / Skipped / Total] 2 / 0 / 2 / 4:   1% 4/277 [00:20<23:25,  5.15s/it][Succeeded / Failed / Skipped / Total] 2 / 0 / 2 / 4:   2% 5/277 [00:26<24:10,  5.33s/it][Succeeded / Failed / Skipped / Total] 3 / 0 / 2 / 5:   2% 5/277 [00:26<24:11,  5.34s/it][Succeeded / Failed / Skipped / Total] 3 / 0 / 2 / 5:   2% 6/277 [00:31<23:55,  5.30s/it][Succeeded / Failed / Skipped / Total] 3 / 1 / 2 / 6:   2% 6/277 [00:31<23:56,  5.30s/it][Succeeded / Failed / Skipped / Total] 3 / 1 / 2 / 6:   3% 7/277 [00:32<20:55,  4.65s/it][Succeeded / Failed / Skipped / Total] 4 / 1 / 2 / 7:   3% 7/277 [00:32<20:56,  4.65s/it][Succeeded / Failed / Skipped / Total] 4 / 1 / 2 / 7:   3% 8/277 [00:34<19:09,  4.27s/it][Succeeded / Failed / Skipped / Total] 5 / 1 / 2 / 8:   3% 8/277 [00:34<19:10,  4.28s/it][Succeeded / Failed / Skipped / Total] 5 / 1 / 2 / 8:   3% 9/277 [00:36<18:18,  4.10s/it][Succeeded / Failed / Skipped / Total] 6 / 1 / 2 / 9:   3% 9/277 [00:36<18:19,  4.10s/it][Succeeded / Failed / Skipped / Total] 6 / 1 / 2 / 9:   4% 10/277 [00:37<16:50,  3.79s/it][Succeeded / Failed / Skipped / Total] 7 / 1 / 2 / 10:   4% 10/277 [00:37<16:51,  3.79s/it][Succeeded / Failed / Skipped / Total] 7 / 1 / 2 / 10:   4% 11/277 [00:39<16:05,  3.63s/it][Succeeded / Failed / Skipped / Total] 8 / 1 / 2 / 11:   4% 11/277 [00:39<16:06,  3.63s/it][Succeeded / Failed / Skipped / Total] 8 / 1 / 3 / 12:   4% 12/277 [00:40<14:44,  3.34s/it][Succeeded / Failed / Skipped / Total] 8 / 1 / 3 / 12:   5% 13/277 [00:41<13:56,  3.17s/it][Succeeded / Failed / Skipped / Total] 9 / 1 / 3 / 13:   5% 13/277 [00:41<13:56,  3.17s/it][Succeeded / Failed / Skipped / Total] 10 / 1 / 3 / 14:   5% 14/277 [00:42<13:18,  3.04s/it][Succeeded / Failed / Skipped / Total] 10 / 1 / 3 / 14:   5% 15/277 [00:42<12:23,  2.84s/it][Succeeded / Failed / Skipped / Total] 10 / 1 / 4 / 15:   5% 15/277 [00:42<12:24,  2.84s/it][Succeeded / Failed / Skipped / Total] 10 / 1 / 5 / 16:   6% 16/277 [00:42<11:36,  2.67s/it][Succeeded / Failed / Skipped / Total] 10 / 1 / 5 / 16:   6% 17/277 [00:42<10:54,  2.52s/it][Succeeded / Failed / Skipped / Total] 10 / 1 / 6 / 17:   6% 17/277 [00:42<10:54,  2.52s/it]/mnt/data/robust/lib/python3.8/multiprocessing/resource_tracker.py:203: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
