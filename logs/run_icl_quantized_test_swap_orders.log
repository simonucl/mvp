nohup: ignoring input
1+8+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/rte/meta-llama/Llama-2-7b-hf/swap_orders/icl_attack-seed-1-shot-8
2023-11-01 21:28:52.807502: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-01 21:28:53.612757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-11-01 21:29:01.825151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:29:01.832001: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:29:01.834362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:29:01.848804: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:29:01.851151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:29:01.853467: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:29:02.030199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:29:02.031797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:29:02.033232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:29:02.034675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38376 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/ceph_rbd/mvp/src/utils/funcs.py:239: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:19<00:19, 19.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00,  8.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00, 10.31s/it]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/rte/meta-llama/Llama-2-7b-hf/swap_orders/icl_attack-seed-1-shot-8_quantized_test/swap_orders_log.csv
  0%|          | 0/20 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  5%|▌         | 1/20 [00:00<00:12,  1.54it/s][Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:   5%|▌         | 1/20 [00:00<00:17,  1.11it/s][Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|█         | 2/20 [00:01<00:10,  1.65it/s][Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  10%|█         | 2/20 [00:01<00:11,  1.59it/s][Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  15%|█▌        | 3/20 [01:29<08:27, 29.86s/it][Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  15%|█▌        | 3/20 [01:29<08:27, 29.88s/it][Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  20%|██        | 4/20 [02:35<10:23, 38.94s/it][Succeeded / Failed / Skipped / Total] 2 / 0 / 2 / 4:  20%|██        | 4/20 [02:35<10:23, 38.95s/it][Succeeded / Failed / Skipped / Total] 2 / 0 / 2 / 4:  25%|██▌       | 5/20 [03:11<09:35, 38.40s/it][Succeeded / Failed / Skipped / Total] 3 / 0 / 2 / 5:  25%|██▌       | 5/20 [03:12<09:36, 38.41s/it][Succeeded / Failed / Skipped / Total] 3 / 0 / 2 / 5:  30%|███       | 6/20 [05:25<12:39, 54.22s/it][Succeeded / Failed / Skipped / Total] 3 / 1 / 2 / 6:  30%|███       | 6/20 [05:25<12:39, 54.23s/it][Succeeded / Failed / Skipped / Total] 3 / 1 / 2 / 6:  35%|███▌      | 7/20 [07:25<13:46, 63.60s/it][Succeeded / Failed / Skipped / Total] 4 / 1 / 2 / 7:  35%|███▌      | 7/20 [07:25<13:46, 63.61s/it][Succeeded / Failed / Skipped / Total] 4 / 1 / 2 / 7:  40%|████      | 8/20 [09:20<14:00, 70.03s/it][Succeeded / Failed / Skipped / Total] 4 / 2 / 2 / 8:  40%|████      | 8/20 [09:20<14:00, 70.03s/it][Succeeded / Failed / Skipped / Total] 4 / 2 / 2 / 8:  45%|████▌     | 9/20 [11:06<13:34, 74.09s/it][Succeeded / Failed / Skipped / Total] 5 / 2 / 2 / 9:  45%|████▌     | 9/20 [11:06<13:35, 74.09s/it][Succeeded / Failed / Skipped / Total] 5 / 2 / 2 / 9:  50%|█████     | 10/20 [11:07<11:07, 66.71s/it][Succeeded / Failed / Skipped / Total] 5 / 2 / 3 / 10:  50%|█████     | 10/20 [11:07<11:07, 66.72s/it][Succeeded / Failed / Skipped / Total] 5 / 2 / 3 / 10:  55%|█████▌    | 11/20 [13:00<10:38, 70.98s/it][Succeeded / Failed / Skipped / Total] 5 / 3 / 3 / 11:  55%|█████▌    | 11/20 [13:00<10:38, 70.98s/it][Succeeded / Failed / Skipped / Total] 5 / 3 / 3 / 11:  60%|██████    | 12/20 [13:37<09:04, 68.11s/it][Succeeded / Failed / Skipped / Total] 6 / 3 / 3 / 12:  60%|██████    | 12/20 [13:37<09:04, 68.11s/it][Succeeded / Failed / Skipped / Total] 6 / 3 / 3 / 12:  65%|██████▌   | 13/20 [15:30<08:21, 71.61s/it][Succeeded / Failed / Skipped / Total] 6 / 4 / 3 / 13:  65%|██████▌   | 13/20 [15:31<08:21, 71.62s/it][Succeeded / Failed / Skipped / Total] 6 / 4 / 3 / 13:  70%|███████   | 14/20 [16:08<06:54, 69.15s/it][Succeeded / Failed / Skipped / Total] 7 / 4 / 3 / 14:  70%|███████   | 14/20 [16:08<06:54, 69.16s/it][Succeeded / Failed / Skipped / Total] 7 / 4 / 3 / 14:  75%|███████▌  | 15/20 [16:08<05:22, 64.57s/it][Succeeded / Failed / Skipped / Total] 7 / 4 / 4 / 15:  75%|███████▌  | 15/20 [16:08<05:22, 64.57s/it][Succeeded / Failed / Skipped / Total] 7 / 4 / 4 / 15:  80%|████████  | 16/20 [16:45<04:11, 62.87s/it][Succeeded / Failed / Skipped / Total] 8 / 4 / 4 / 16:  80%|████████  | 16/20 [16:46<04:11, 62.88s/it][Succeeded / Failed / Skipped / Total] 8 / 4 / 4 / 16:  85%|████████▌ | 17/20 [16:46<02:57, 59.20s/it][Succeeded / Failed / Skipped / Total] 8 / 4 / 5 / 17:  85%|████████▌ | 17/20 [16:46<02:57, 59.20s/it][Succeeded / Failed / Skipped / Total] 8 / 4 / 5 / 17:  90%|█████████ | 18/20 [17:23<01:55, 57.99s/it][Succeeded / Failed / Skipped / Total] 9 / 4 / 5 / 18:  90%|█████████ | 18/20 [17:23<01:55, 57.99s/it][Succeeded / Failed / Skipped / Total] 9 / 4 / 5 / 18:  95%|█████████▌| 19/20 [19:18<01:00, 60.96s/it][Succeeded / Failed / Skipped / Total] 9 / 5 / 5 / 19:  95%|█████████▌| 19/20 [19:18<01:00, 60.97s/it][Succeeded / Failed / Skipped / Total] 9 / 5 / 5 / 19: 100%|██████████| 20/20 [19:55<00:00, 59.79s/it][Succeeded / Failed / Skipped / Total] 10 / 5 / 5 / 20: 100%|██████████| 20/20 [19:55<00:00, 59.79s/it][Succeeded / Failed / Skipped / Total] 10 / 5 / 5 / 20: 100%|██████████| 20/20 [19:55<00:00, 59.79s/it]
Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 665/665 [00:00<00:00, 114kB/s]
Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]Downloading model.safetensors:   2%|▏         | 10.5M/548M [00:00<00:08, 63.6MB/s]Downloading model.safetensors:   4%|▍         | 21.0M/548M [00:00<00:08, 64.9MB/s]Downloading model.safetensors:   6%|▌         | 31.5M/548M [00:00<00:11, 44.5MB/s]Downloading model.safetensors:   8%|▊         | 41.9M/548M [00:00<00:11, 44.8MB/s]Downloading model.safetensors:  10%|▉         | 52.4M/548M [00:01<00:10, 46.8MB/s]Downloading model.safetensors:  11%|█▏        | 62.9M/548M [00:01<00:10, 47.8MB/s]Downloading model.safetensors:  13%|█▎        | 73.4M/548M [00:01<00:08, 53.0MB/s]Downloading model.safetensors:  15%|█▌        | 83.9M/548M [00:01<00:09, 50.6MB/s]Downloading model.safetensors:  17%|█▋        | 94.4M/548M [00:01<00:09, 50.0MB/s]Downloading model.safetensors:  19%|█▉        | 105M/548M [00:02<00:08, 53.8MB/s] Downloading model.safetensors:  21%|██        | 115M/548M [00:02<00:07, 59.2MB/s]Downloading model.safetensors:  23%|██▎       | 126M/548M [00:02<00:08, 52.1MB/s]Downloading model.safetensors:  25%|██▍       | 136M/548M [00:02<00:07, 53.5MB/s]Downloading model.safetensors:  27%|██▋       | 147M/548M [00:02<00:07, 51.9MB/s]Downloading model.safetensors:  29%|██▊       | 157M/548M [00:03<00:08, 47.6MB/s]Downloading model.safetensors:  31%|███       | 168M/548M [00:03<00:07, 51.1MB/s]Downloading model.safetensors:  33%|███▎      | 178M/548M [00:03<00:07, 50.6MB/s]Downloading model.safetensors:  34%|███▍      | 189M/548M [00:03<00:06, 52.2MB/s]Downloading model.safetensors:  36%|███▋      | 199M/548M [00:03<00:06, 53.1MB/s]Downloading model.safetensors:  38%|███▊      | 210M/548M [00:04<00:06, 50.3MB/s]Downloading model.safetensors:  40%|████      | 220M/548M [00:04<00:06, 50.0MB/s]Downloading model.safetensors:  42%|████▏     | 231M/548M [00:04<00:06, 52.8MB/s]Downloading model.safetensors:  44%|████▍     | 241M/548M [00:04<00:05, 54.7MB/s]Downloading model.safetensors:  46%|████▌     | 252M/548M [00:04<00:05, 52.3MB/s]Downloading model.safetensors:  48%|████▊     | 262M/548M [00:05<00:05, 49.9MB/s]Downloading model.safetensors:  50%|████▉     | 273M/548M [00:05<00:05, 52.8MB/s]Downloading model.safetensors:  52%|█████▏    | 283M/548M [00:05<00:05, 52.3MB/s]Downloading model.safetensors:  54%|█████▎    | 294M/548M [00:05<00:04, 57.5MB/s]Downloading model.safetensors:  55%|█████▌    | 304M/548M [00:05<00:03, 61.6MB/s]Downloading model.safetensors:  57%|█████▋    | 315M/548M [00:05<00:03, 58.8MB/s]Downloading model.safetensors:  59%|█████▉    | 325M/548M [00:06<00:03, 60.4MB/s]Downloading model.safetensors:  61%|██████    | 336M/548M [00:06<00:03, 60.9MB/s]Downloading model.safetensors:  63%|██████▎   | 346M/548M [00:06<00:03, 51.2MB/s]Downloading model.safetensors:  65%|██████▌   | 357M/548M [00:06<00:03, 52.4MB/s]Downloading model.safetensors:  67%|██████▋   | 367M/548M [00:06<00:03, 53.1MB/s]Downloading model.safetensors:  69%|██████▉   | 377M/548M [00:07<00:03, 52.2MB/s]Downloading model.safetensors:  71%|███████   | 388M/548M [00:07<00:03, 52.2MB/s]Downloading model.safetensors:  73%|███████▎  | 398M/548M [00:07<00:03, 45.8MB/s]Downloading model.safetensors:  75%|███████▍  | 409M/548M [00:07<00:03, 44.3MB/s]Downloading model.safetensors:  77%|███████▋  | 419M/548M [00:08<00:02, 49.4MB/s]Downloading model.safetensors:  78%|███████▊  | 430M/548M [00:08<00:02, 51.4MB/s]Downloading model.safetensors:  80%|████████  | 440M/548M [00:08<00:02, 50.5MB/s]Downloading model.safetensors:  82%|████████▏ | 451M/548M [00:08<00:01, 49.0MB/s]Downloading model.safetensors:  84%|████████▍ | 461M/548M [00:08<00:01, 46.8MB/s]Downloading model.safetensors:  86%|████████▌ | 472M/548M [00:09<00:01, 48.2MB/s]Downloading model.safetensors:  88%|████████▊ | 482M/548M [00:09<00:01, 52.3MB/s]Downloading model.safetensors:  90%|████████▉ | 493M/548M [00:09<00:01, 50.1MB/s]Downloading model.safetensors:  92%|█████████▏| 503M/548M [00:09<00:00, 55.0MB/s]Downloading model.safetensors:  94%|█████████▎| 514M/548M [00:09<00:00, 50.8MB/s]Downloading model.safetensors:  96%|█████████▌| 524M/548M [00:10<00:00, 44.9MB/s]Downloading model.safetensors:  98%|█████████▊| 535M/548M [00:10<00:00, 48.8MB/s]Downloading model.safetensors:  99%|█████████▉| 545M/548M [00:10<00:00, 50.2MB/s]Downloading model.safetensors: 100%|██████████| 548M/548M [00:10<00:00, 51.4MB/s]
Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]Downloading (…)neration_config.json: 100%|██████████| 124/124 [00:00<00:00, 25.3kB/s]
Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.64MB/s]Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.64MB/s]
Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.90MB/s]Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.90MB/s]
Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]Downloading (…)/main/tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 15.7MB/s]
Token indices sequence length is longer than the specified maximum sequence length for this model (13467 > 1024). Running this sequence through the model will result in indexing errors
Traceback (most recent call last):
  File "/src/textattack/textattack/constraints/semantics/sentence_encoders/sentence_encoder.py", line 81, in _sim_score
    iter(transformed_text.attack_attrs["newly_modified_indices"])
KeyError: 'newly_modified_indices'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/ceph_rbd/mvp/src/test.py", line 227, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 226, in _attack
    self.attack_log_manager.log_summary()
  File "/src/textattack/textattack/loggers/attack_log_manager.py", line 150, in log_summary
    use_stats = USEMetric().calculate(self.results)
  File "/src/textattack/textattack/metrics/quality_metrics/use.py", line 65, in calculate
    self.use_obj._sim_score(
  File "/src/textattack/textattack/constraints/semantics/sentence_encoders/sentence_encoder.py", line 84, in _sim_score
    raise KeyError(
KeyError: 'Cannot apply sentence encoder constraint without `newly_modified_indices`'
textattack: CSVLogger exiting without calling flush().
1+4+meta-llama/Llama-2-7b-hf+mvp
./checkpoints/rte/meta-llama/Llama-2-7b-hf/swap_orders/icl_attack-seed-1-shot-4
2023-11-01 21:50:02.453444: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-01 21:50:03.268634: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-11-01 21:50:11.433970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:50:11.910985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:50:11.914488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:50:11.929977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:50:11.932341: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:50:11.934661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:50:12.121124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:50:12.122755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:50:12.124229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-11-01 21:50:12.126065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38376 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:08:00.0, compute capability: 8.0
/mnt/ceph_rbd/mvp/src/utils/funcs.py:239: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric('accuracy')
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.
textattack: Logging to CSV at path ./checkpoints/rte/meta-llama/Llama-2-7b-hf/swap_orders/icl_attack-seed-1-shot-4_quantized_test/swap_orders_log.csv
  0%|          | 0/20 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
  5%|▌         | 1/20 [00:04<01:34,  4.95s/it][Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:   5%|▌         | 1/20 [00:05<01:38,  5.18s/it][Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  10%|█         | 2/20 [00:05<00:48,  2.72s/it][Succeeded / Failed / Skipped / Total] 1 / 0 / 1 / 2:  10%|█         | 2/20 [00:05<00:49,  2.73s/it][Succeeded / Failed / Skipped / Total] 1 / 0 / 1 / 2:  15%|█▌        | 3/20 [00:14<01:20,  4.76s/it][Succeeded / Failed / Skipped / Total] 1 / 1 / 1 / 3:  15%|█▌        | 3/20 [00:14<01:21,  4.77s/it][Succeeded / Failed / Skipped / Total] 1 / 1 / 1 / 3:  20%|██        | 4/20 [00:22<01:31,  5.74s/it][Succeeded / Failed / Skipped / Total] 1 / 2 / 1 / 4:  20%|██        | 4/20 [00:22<01:31,  5.75s/it][Succeeded / Failed / Skipped / Total] 1 / 2 / 1 / 4:  25%|██▌       | 5/20 [00:27<01:23,  5.59s/it][Succeeded / Failed / Skipped / Total] 2 / 2 / 1 / 5:  25%|██▌       | 5/20 [00:27<01:23,  5.59s/it][Succeeded / Failed / Skipped / Total] 2 / 2 / 1 / 5:  30%|███       | 6/20 [00:35<01:21,  5.84s/it][Succeeded / Failed / Skipped / Total] 3 / 2 / 1 / 6:  30%|███       | 6/20 [00:35<01:21,  5.84s/it][Succeeded / Failed / Skipped / Total] 3 / 2 / 1 / 6:  35%|███▌      | 7/20 [00:43<01:20,  6.21s/it][Succeeded / Failed / Skipped / Total] 3 / 3 / 1 / 7:  35%|███▌      | 7/20 [00:43<01:20,  6.21s/it][Succeeded / Failed / Skipped / Total] 3 / 3 / 1 / 7:  40%|████      | 8/20 [00:51<01:17,  6.47s/it][Succeeded / Failed / Skipped / Total] 4 / 3 / 1 / 8:  40%|████      | 8/20 [00:51<01:17,  6.47s/it][Succeeded / Failed / Skipped / Total] 4 / 3 / 1 / 8:  45%|████▌     | 9/20 [00:59<01:13,  6.66s/it][Succeeded / Failed / Skipped / Total] 4 / 4 / 1 / 9:  45%|████▌     | 9/20 [00:59<01:13,  6.66s/it][Succeeded / Failed / Skipped / Total] 4 / 4 / 1 / 9:  50%|█████     | 10/20 [01:00<01:00,  6.03s/it][Succeeded / Failed / Skipped / Total] 4 / 4 / 2 / 10:  50%|█████     | 10/20 [01:00<01:00,  6.03s/it][Succeeded / Failed / Skipped / Total] 4 / 4 / 2 / 10:  55%|█████▌    | 11/20 [01:08<00:56,  6.23s/it][Succeeded / Failed / Skipped / Total] 4 / 5 / 2 / 11:  55%|█████▌    | 11/20 [01:08<00:56,  6.24s/it][Succeeded / Failed / Skipped / Total] 4 / 5 / 2 / 11:  60%|██████    | 12/20 [01:16<00:50,  6.37s/it][Succeeded / Failed / Skipped / Total] 5 / 5 / 2 / 12:  60%|██████    | 12/20 [01:16<00:50,  6.37s/it][Succeeded / Failed / Skipped / Total] 5 / 5 / 2 / 12:  65%|██████▌   | 13/20 [01:24<00:45,  6.51s/it][Succeeded / Failed / Skipped / Total] 5 / 6 / 2 / 13:  65%|██████▌   | 13/20 [01:24<00:45,  6.51s/it][Succeeded / Failed / Skipped / Total] 5 / 6 / 2 / 13:  70%|███████   | 14/20 [01:24<00:36,  6.07s/it][Succeeded / Failed / Skipped / Total] 5 / 6 / 3 / 14:  70%|███████   | 14/20 [01:24<00:36,  6.07s/it][Succeeded / Failed / Skipped / Total] 5 / 6 / 3 / 14:  75%|███████▌  | 15/20 [01:25<00:28,  5.68s/it][Succeeded / Failed / Skipped / Total] 5 / 6 / 4 / 15:  75%|███████▌  | 15/20 [01:25<00:28,  5.68s/it][Succeeded / Failed / Skipped / Total] 5 / 6 / 4 / 15:  80%|████████  | 16/20 [01:29<00:22,  5.61s/it][Succeeded / Failed / Skipped / Total] 6 / 6 / 4 / 16:  80%|████████  | 16/20 [01:29<00:22,  5.61s/it][Succeeded / Failed / Skipped / Total] 6 / 6 / 4 / 16:  85%|████████▌ | 17/20 [01:34<00:16,  5.55s/it][Succeeded / Failed / Skipped / Total] 7 / 6 / 4 / 17:  85%|████████▌ | 17/20 [01:34<00:16,  5.55s/it][Succeeded / Failed / Skipped / Total] 7 / 6 / 4 / 17:  90%|█████████ | 18/20 [01:34<00:10,  5.26s/it][Succeeded / Failed / Skipped / Total] 7 / 6 / 5 / 18:  90%|█████████ | 18/20 [01:34<00:10,  5.26s/it][Succeeded / Failed / Skipped / Total] 7 / 6 / 5 / 18:  95%|█████████▌| 19/20 [01:43<00:05,  5.44s/it][Succeeded / Failed / Skipped / Total] 7 / 7 / 5 / 19:  95%|█████████▌| 19/20 [01:43<00:05,  5.44s/it][Succeeded / Failed / Skipped / Total] 7 / 7 / 5 / 19: 100%|██████████| 20/20 [01:51<00:00,  5.59s/it][Succeeded / Failed / Skipped / Total] 7 / 8 / 5 / 20: 100%|██████████| 20/20 [01:51<00:00,  5.59s/it][Succeeded / Failed / Skipped / Total] 7 / 8 / 5 / 20: 100%|██████████| 20/20 [01:51<00:00,  5.59s/it]
Token indices sequence length is longer than the specified maximum sequence length for this model (4831 > 1024). Running this sequence through the model will result in indexing errors
Traceback (most recent call last):
  File "/src/textattack/textattack/constraints/semantics/sentence_encoders/sentence_encoder.py", line 81, in _sim_score
    iter(transformed_text.attack_attrs["newly_modified_indices"])
KeyError: 'newly_modified_indices'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main.py", line 85, in <module>
    attacker(args)
  File "/mnt/ceph_rbd/mvp/src/test.py", line 227, in attacker
    attacker.attack_dataset()
  File "/src/textattack/textattack/attacker.py", line 441, in attack_dataset
    self._attack()
  File "/src/textattack/textattack/attacker.py", line 226, in _attack
    self.attack_log_manager.log_summary()
  File "/src/textattack/textattack/loggers/attack_log_manager.py", line 150, in log_summary
    use_stats = USEMetric().calculate(self.results)
  File "/src/textattack/textattack/metrics/quality_metrics/use.py", line 65, in calculate
    self.use_obj._sim_score(
  File "/src/textattack/textattack/constraints/semantics/sentence_encoders/sentence_encoder.py", line 84, in _sim_score
    raise KeyError(
KeyError: 'Cannot apply sentence encoder constraint without `newly_modified_indices`'
textattack: CSVLogger exiting without calling flush().
