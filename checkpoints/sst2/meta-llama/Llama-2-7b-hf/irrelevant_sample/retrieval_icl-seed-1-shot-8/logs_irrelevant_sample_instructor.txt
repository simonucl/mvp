1
Namespace(adv_augment=0, alpha=None, attack_name='irrelevant_sample', batch_size=4, beta=1.0, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='sst2', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=False, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/sst2/meta-llama/Llama-2-7b-hf/irrelevant_sample/retrieval_icl-seed-1-shot-8_instructor', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='instructor', sampled_num=1, save_icl_examples_path=None, seed=1, shot=8, split='test', template_file='configs/templates_rte.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_rte.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/sst2/meta-llama/Llama-2-7b-hf/irrelevant_sample/retrieval_icl-seed-1-shot-8_instructor
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='irrelevant_sample', batch_size=4, beta=1.0, cache_dir='./checkpoints/sst2/meta-llama/Llama-2-7b-hf/irrelevant_sample/retrieval_icl-seed-1-shot-8_instructor/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='sst2', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=False, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/sst2/meta-llama/Llama-2-7b-hf/irrelevant_sample/retrieval_icl-seed-1-shot-8_instructor', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=-1, ralm_save_path='./data/ralm/sst2_instructor_ood.pkl', replace_ratio=0.1, retrieve_method='instructor', sampled_num=1, save_icl_examples_path=None, seed=1, shot=8, split='test', template_file='configs/templates_rte.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_rte.yaml', weight_decay=0.01)
Finished loading ood dataset
{'sentence': 'is in bad need of major acting lessons and maybe a little coffee ', 'label': 0, 'idx': 17493}
Finished replacing ood dataset
{'sentence': 'is in bad need of major acting lessons and maybe a little coffee ', 'label': 0, 'idx': 17493}
load INSTRUCTOR_Transformer
max_seq_length  512
Length of anchor subsample 16
Length of icl examples 2
Finished loading model
Finished encoding anchor data
anchor_data_embeddings shape: torch.Size([63975, 768])
query shape: 872
query_embedding shape: torch.Size([872, 768])
cos_scores shape: torch.Size([872, 63975])
Saving retrieved examples to ./data/ralm/sst2_instructor_ood.pkl
ICL examples
{'sentence': "it 's a charming and often affecting journey . ", 'label': 1, 'idx': 0, 'Example_0': 'is charming ', 'Label_0': 'false', 'Example_1': 'that work -- is charming , is moving ', 'Label_1': 'false', 'Example_2': 'its charm ', 'Label_2': 'false', 'Example_3': 'the journey is such a mesmerizing one ', 'Label_3': 'false', 'Example_4': 'charming and evoking ', 'Label_4': 'false', 'Example_5': 'charming , ', 'Label_5': 'false', 'Example_6': ', charming ', 'Label_6': 'false', 'Example_7': 'its charms ', 'Label_7': 'false', 'Example_8': 'charming and ', 'Label_8': 'false', 'Example_9': 'surprisingly charming and ', 'Label_9': 'false', 'Example_10': 'that tells stories that work -- is charming , is moving ', 'Label_10': 'false', 'Example_11': 'delightfully charming ', 'Label_11': 'false', 'Example_12': 'work -- is charming , is moving ', 'Label_12': 'false', 'Example_13': 'has a lot of charm . ', 'Label_13': 'false', 'Example_14': 'has a lot of charm ', 'Label_14': 'false', 'Example_15': 'work -- is charming ', 'Label_15': 'false'}
{'sentence': "it 's a charming and often affecting journey . ", 'label': 1, 'idx': 0, 'Example_0': 'is charming ', 'Label_0': 'false', 'Example_1': 'that work -- is charming , is moving ', 'Label_1': 'false', 'Example_2': 'its charm ', 'Label_2': 'false', 'Example_3': 'the journey is such a mesmerizing one ', 'Label_3': 'false', 'Example_4': 'charming and evoking ', 'Label_4': 'false', 'Example_5': 'charming , ', 'Label_5': 'false', 'Example_6': ', charming ', 'Label_6': 'false', 'Example_7': 'its charms ', 'Label_7': 'false', 'Example_8': 'charming and ', 'Label_8': 'false', 'Example_9': 'surprisingly charming and ', 'Label_9': 'false', 'Example_10': 'that tells stories that work -- is charming , is moving ', 'Label_10': 'false', 'Example_11': 'delightfully charming ', 'Label_11': 'false', 'Example_12': 'work -- is charming , is moving ', 'Label_12': 'false', 'Example_13': 'has a lot of charm . ', 'Label_13': 'false', 'Example_14': 'has a lot of charm ', 'Label_14': 'false', 'Example_15': 'work -- is charming ', 'Label_15': 'false'}
['{}\n The question is: {}. True or False?\nThe Answer is: {}']
{0: ['true'], 1: ['false']}
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/irrelevant_sample/retrieval_icl-seed-1-shot-8_instructor/irrelevant_sample_log.csv
<textattack.attacker.Attacker object at 0x7fb962e1b730>
Attack(
  (search_method): GreedyWordSwapWIR(
    (wir_method):  delete
  )
  (goal_function):  UntargetedClassification
  (transformation):  WordSwapEmbedding(
    (max_candidates):  50
    (embedding):  WordEmbedding
  )
  (constraints): 
    (0): MaxWordsPerturbed(
        (max_percent):  0.5
        (compare_against_original):  True
      )
    (1): WordEmbeddingDistance(
        (embedding):  WordEmbedding
        (min_cos_sim):  0.6
        (cased):  False
        (include_unknown_words):  True
        (compare_against_original):  True
      )
    (2): PartOfSpeech(
        (tagger_type):  nltk
        (tagset):  universal
        (allow_verb_noun_swap):  True
        (compare_against_original):  True
      )
    (3): UniversalSentenceEncoder(
        (metric):  angular
        (threshold):  0.840845057
        (window_size):  15
        (skip_text_shorter_than_window):  True
        (compare_against_original):  False
      )
    (4): RepeatModification
    (5): StopwordModification
    (6): InstructionModification(
        (columns_to_ignore):  ['example_', 'label_']
      )
    (7): InputColumnModification(
        (matching_column_labels):  ['premise', 'hypothesis']
        (columns_to_ignore):  {'premise'}
      )
    (8): InputColumnModification(
        (matching_column_labels):  ['question', 'sentence']
        (columns_to_ignore):  {'question'}
      )
  (is_black_box):  True
) 

