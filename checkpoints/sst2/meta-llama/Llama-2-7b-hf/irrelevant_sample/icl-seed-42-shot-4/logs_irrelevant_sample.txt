1
Namespace(adv_augment=0, alpha=None, attack_name='irrelevant_sample', batch_size=8, beta=1.0, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='sst2', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=False, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/sst2/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-42-shot-4', model_id='0', model_type='icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='sbert', sampled_num=1, save_icl_examples_path=None, seed=42, shot=4, split='test', template_file='configs/templates_sst2.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_sst2.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/sst2/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-42-shot-4
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='irrelevant_sample', batch_size=8, beta=1.0, cache_dir='./checkpoints/sst2/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-42-shot-4/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='sst2', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=False, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/sst2/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-42-shot-4', model_id='0', model_type='icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='sbert', sampled_num=1, save_icl_examples_path=None, seed=42, shot=4, split='test', template_file='configs/templates_sst2.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_sst2.yaml', weight_decay=0.01)
Finished loading ood dataset
{'sentence': 'is in bad need of major acting lessons and maybe a little coffee ', 'label': 0, 'idx': 17493}
Finished replacing ood dataset
{'sentence': 'It wasnâ€™t immediately known whether Lane has an attorney.\n', 'label': 0, 'idx': 17493}
Length of anchor subsample 0
Length of icl examples 2
Finished loading model
ICL examples
{'sentence': "it 's a charming and often affecting journey . ", 'label': 1, 'idx': 0, 'Example_0': 'all mood and no movie . ', 'Label_0': 'negative', 'Example_1': 'First Alert Weather: What to expect 5/30\n', 'Label_1': 'positive', 'Example_2': 'has been sacrificed for the sake of spectacle ', 'Label_2': 'negative', 'Example_3': 'emerges with yet another remarkable yet shockingly little-known perspective . ', 'Label_3': 'positive', 'Example_4': 'Photo: Quality Control Music\n', 'Label_4': 'negative', 'Example_5': 'are very , very good reasons ', 'Label_5': 'positive', 'Example_6': 'In this solo show Bart asks you to imagine a line, and then takes you and your line on an imaginary journey from historghrhams, to brightness sliders, to black and white point sliders, to contrast sliders, and finally on to curves and levels adjustments. These controls are ubiquitous, so understanding them should prove extremely useful!\n', 'Label_6': 'negative', 'Example_7': 'the ya-ya sisterhood ', 'Label_7': 'positive'}
{'sentence': "it 's a charming and often affecting journey . ", 'label': 1, 'idx': 0, 'Example_0': 'all mood and no movie . ', 'Label_0': 'negative', 'Example_1': 'First Alert Weather: What to expect 5/30\n', 'Label_1': 'positive', 'Example_2': 'has been sacrificed for the sake of spectacle ', 'Label_2': 'negative', 'Example_3': 'emerges with yet another remarkable yet shockingly little-known perspective . ', 'Label_3': 'positive', 'Example_4': 'Photo: Quality Control Music\n', 'Label_4': 'negative', 'Example_5': 'are very , very good reasons ', 'Label_5': 'positive', 'Example_6': 'In this solo show Bart asks you to imagine a line, and then takes you and your line on an imaginary journey from historghrhams, to brightness sliders, to black and white point sliders, to contrast sliders, and finally on to curves and levels adjustments. These controls are ubiquitous, so understanding them should prove extremely useful!\n', 'Label_6': 'negative', 'Example_7': 'the ya-ya sisterhood ', 'Label_7': 'positive'}
['Review: {}\nSentiment: {}']
{0: ['negative'], 1: ['positive']}
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-42-shot-4/irrelevant_sample_log.csv
<textattack.attacker.Attacker object at 0x7f65ee5581c0>
Attack(
  (search_method): GreedyWordSwapWIR(
    (wir_method):  delete
  )
  (goal_function):  UntargetedClassification
  (transformation):  WordSwapEmbedding(
    (max_candidates):  50
    (embedding):  WordEmbedding
  )
  (constraints): 
    (0): MaxWordsPerturbed(
        (max_percent):  0.5
        (compare_against_original):  True
      )
    (1): WordEmbeddingDistance(
        (embedding):  WordEmbedding
        (min_cos_sim):  0.6
        (cased):  False
        (include_unknown_words):  True
        (compare_against_original):  True
      )
    (2): PartOfSpeech(
        (tagger_type):  nltk
        (tagset):  universal
        (allow_verb_noun_swap):  True
        (compare_against_original):  True
      )
    (3): UniversalSentenceEncoder(
        (metric):  angular
        (threshold):  0.840845057
        (window_size):  15
        (skip_text_shorter_than_window):  True
        (compare_against_original):  False
      )
    (4): RepeatModification
    (5): StopwordModification
    (6): InstructionModification(
        (columns_to_ignore):  ['example_', 'label_']
      )
    (7): InputColumnModification(
        (matching_column_labels):  ['premise', 'hypothesis']
        (columns_to_ignore):  {'premise'}
      )
    (8): InputColumnModification(
        (matching_column_labels):  ['question', 'sentence']
        (columns_to_ignore):  {'question'}
      )
  (is_black_box):  True
) 


+-------------------------------+-------+
| Attack Results                |       |
+-------------------------------+-------+
| Number of successful attacks: | 0     |
| Number of failed attacks:     | 783   |
| Number of skipped attacks:    | 89    |
| Original accuracy:            | 89.79 |
| Accuracy under attack:        | 89.79 |
| Attack success rate:          | 0.0   |
| Average perturbed word %:     | nan   |
| Average num. words per input: | 122.4 |
| Avg num queries:              | 1.0   |
| Adv confidence:               | nan   |
+-------------------------------+-------+
Attack time: 59.0981719493866
Attack time: 59.0981719493866
