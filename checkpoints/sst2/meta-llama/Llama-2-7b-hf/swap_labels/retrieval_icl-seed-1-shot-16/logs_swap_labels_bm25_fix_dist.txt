1
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='sst2', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=True, is_quantized=False, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25_fix_dist', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='bm25', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_sst2.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_sst2.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25_fix_dist
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=1, beta=1.0, cache_dir='./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25_fix_dist/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='sst2', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=True, is_quantized=False, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25_fix_dist', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=-1, ralm_save_path='./data/ralm/sst2_bm25.pkl', replace_ratio=0.1, retrieve_method='bm25', sampled_num=1, seed=1, shot=16, split='test', template_file='configs/templates_sst2.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_sst2.yaml', weight_decay=0.01)
Length of anchor subsample 32
Length of icl examples 2
Finished loading model
Loading retrieved examples from ./data/ralm/sst2_bm25.pkl
ICL examples
{'sentence': "it 's a charming and often affecting journey . ", 'label': 1, 'idx': 0, 'Example_0': 'powerful , chilling , and affecting study ', 'Label_0': 'positive', 'Example_1': 'journey into a philosophical void ', 'Label_1': 'positive', 'Example_2': 'was utterly charming . ', 'Label_2': 'positive', 'Example_3': "it 's a square , sentimental drama that satisfies , as comfort food often can . ", 'Label_3': 'positive', 'Example_4': 'charming and funny ', 'Label_4': 'positive', 'Example_5': 'charming and witty ', 'Label_5': 'positive', 'Example_6': 'surprisingly charming and ', 'Label_6': 'positive', 'Example_7': ", amari 's film falls short in building the drama of lilia 's journey . ", 'Label_7': 'negative', 'Example_8': 'this deeply affecting film ', 'Label_8': 'positive', 'Example_9': 'quietly affecting cop drama ', 'Label_9': 'positive', 'Example_10': 'a humorless journey into a philosophical void . ', 'Label_10': 'negative', 'Example_11': "'s already done way too often ", 'Label_11': 'negative', 'Example_12': 'a charming but slight comedy . ', 'Label_12': 'positive', 'Example_13': 'nasty journey ', 'Label_13': 'negative', 'Example_14': 'spiritual journey ', 'Label_14': 'positive', 'Example_15': 'sentimental journey ', 'Label_15': 'positive', 'Example_16': "like most of jaglom 's films , some of it is honestly affecting , but ", 'Label_16': 'positive', 'Example_17': "is a satisfying well-made romantic comedy that 's both charming and well acted . ", 'Label_17': 'positive', 'Example_18': 'acted , quietly affecting cop drama . ', 'Label_18': 'positive', 'Example_19': "the film has a nearly terminal case of the cutes , and it 's neither as funny nor as charming as it thinks it is . ", 'Label_19': 'negative', 'Example_20': "'s sweet , funny , charming , and completely delightful ", 'Label_20': 'positive', 'Example_21': 'is it a charming , funny and beautifully crafted import ', 'Label_21': 'positive', 'Example_22': "the journey to the secret 's eventual discovery is a separate adventure , and thrill enough . ", 'Label_22': 'positive', 'Example_23': "like most of jaglom 's films , some of it is honestly affecting , ", 'Label_23': 'positive', 'Example_24': 'a powerful , chilling , and affecting study ', 'Label_24': 'positive', 'Example_25': "falls short in building the drama of lilia 's journey . ", 'Label_25': 'negative', 'Example_26': "works more often than it does n't . ", 'Label_26': 'positive', 'Example_27': 'charming and ', 'Label_27': 'positive', 'Example_28': 'is honestly affecting ', 'Label_28': 'positive', 'Example_29': 'deeply affecting film ', 'Label_29': 'positive', 'Example_30': 'piercingly affecting ', 'Label_30': 'positive', 'Example_31': "'s often overwritten , ", 'Label_31': 'negative'}
{'sentence': "it 's a charming and often affecting journey . ", 'label': 1, 'idx': 0, 'Example_0': 'powerful , chilling , and affecting study ', 'Label_0': 'positive', 'Example_1': 'journey into a philosophical void ', 'Label_1': 'positive', 'Example_2': 'was utterly charming . ', 'Label_2': 'positive', 'Example_3': "it 's a square , sentimental drama that satisfies , as comfort food often can . ", 'Label_3': 'positive', 'Example_4': 'charming and funny ', 'Label_4': 'positive', 'Example_5': 'charming and witty ', 'Label_5': 'positive', 'Example_6': 'surprisingly charming and ', 'Label_6': 'positive', 'Example_7': ", amari 's film falls short in building the drama of lilia 's journey . ", 'Label_7': 'negative', 'Example_8': 'this deeply affecting film ', 'Label_8': 'positive', 'Example_9': 'quietly affecting cop drama ', 'Label_9': 'positive', 'Example_10': 'a humorless journey into a philosophical void . ', 'Label_10': 'negative', 'Example_11': "'s already done way too often ", 'Label_11': 'negative', 'Example_12': 'a charming but slight comedy . ', 'Label_12': 'positive', 'Example_13': 'nasty journey ', 'Label_13': 'negative', 'Example_14': 'spiritual journey ', 'Label_14': 'positive', 'Example_15': 'sentimental journey ', 'Label_15': 'positive', 'Example_16': "like most of jaglom 's films , some of it is honestly affecting , but ", 'Label_16': 'positive', 'Example_17': "is a satisfying well-made romantic comedy that 's both charming and well acted . ", 'Label_17': 'positive', 'Example_18': 'acted , quietly affecting cop drama . ', 'Label_18': 'positive', 'Example_19': "the film has a nearly terminal case of the cutes , and it 's neither as funny nor as charming as it thinks it is . ", 'Label_19': 'negative', 'Example_20': "'s sweet , funny , charming , and completely delightful ", 'Label_20': 'positive', 'Example_21': 'is it a charming , funny and beautifully crafted import ', 'Label_21': 'positive', 'Example_22': "the journey to the secret 's eventual discovery is a separate adventure , and thrill enough . ", 'Label_22': 'positive', 'Example_23': "like most of jaglom 's films , some of it is honestly affecting , ", 'Label_23': 'positive', 'Example_24': 'a powerful , chilling , and affecting study ', 'Label_24': 'positive', 'Example_25': "falls short in building the drama of lilia 's journey . ", 'Label_25': 'negative', 'Example_26': "works more often than it does n't . ", 'Label_26': 'positive', 'Example_27': 'charming and ', 'Label_27': 'positive', 'Example_28': 'is honestly affecting ', 'Label_28': 'positive', 'Example_29': 'deeply affecting film ', 'Label_29': 'positive', 'Example_30': 'piercingly affecting ', 'Label_30': 'positive', 'Example_31': "'s often overwritten , ", 'Label_31': 'negative'}
['Review: {}\nSentiment: {}']
{0: ['negative'], 1: ['positive']}
./checkpoints/sst2/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-16_bm25_fix_dist/swap_labels_log.csv
<textattack.attacker.Attacker object at 0x7facb6c8edc0>
Attack(
  (search_method): GreedySearch
  (goal_function):  UntargetedClassification
  (transformation):  CompositeTransformation(
    (0): WordSwapDuo
    )
  (constraints): 
    (0): MaxWordsPerturbed(
        (max_percent):  0.5
        (compare_against_original):  True
      )
    (1): UniformSwap(
        (threshold):  1
        (compare_against_original):  True
      )
    (2): InstructionModification(
        (columns_to_ignore):  ['sentence', 'example_', 'premise', 'hypothesis']
      )
    (3): RepeatModification
  (is_black_box):  True
) 


+-------------------------------+--------+
| Attack Results                |        |
+-------------------------------+--------+
| Number of successful attacks: | 701    |
| Number of failed attacks:     | 132    |
| Number of skipped attacks:    | 39     |
| Original accuracy:            | 95.53  |
| Accuracy under attack:        | 15.14  |
| Attack success rate:          | 84.15  |
| Average perturbed word %:     | 2.03   |
| Average num. words per input: | 370.42 |
| Avg num queries:              | 600.8  |
| Adv confidence:               | 0.59   |
| Average Original Perplexity:  | 14.73  |
| Average Attack Perplexity:    | 14.74  |
| Average Attack USE Score:     | 0.98   |
+-------------------------------+--------+
Attack time: 45856.07406163216
Attack time: 45856.07406163216
