1
Namespace(adv_augment=0, alpha=None, attack_name='irrelevant_sample', batch_size=4, beta=1.0, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='mr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=False, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/mr/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-42-shot-8', model_id='0', model_type='icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='sbert', sampled_num=1, save_icl_examples_path=None, seed=42, shot=8, split='test', template_file='configs/templates_mr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_mr.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/mr/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-42-shot-8
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='irrelevant_sample', batch_size=4, beta=1.0, cache_dir='./checkpoints/mr/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-42-shot-8/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='mr', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=False, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/mr/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-42-shot-8', model_id='0', model_type='icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=2, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='sbert', sampled_num=1, save_icl_examples_path=None, seed=42, shot=8, split='test', template_file='configs/templates_mr.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_mr.yaml', weight_decay=0.01)
Finished loading ood dataset
{'label': 0, 'sentence': 'as a movie , it never seems fresh and vital . it never plays as dramatic even when dramatic things happen to people . it labours as storytelling .', 'idx': 0}
Finished replacing ood dataset
{'label': 0, 'sentence': 'It wasn’t immediately known whether Lane has an attorney.\n', 'idx': 0}
Length of anchor subsample 0
Length of icl examples 2
Finished loading model
ICL examples
{'label': 1, 'sentence': 'lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .', 'idx': 0, 'Example_0': 'The other finalists are Buenos Aires, Argentina, and Lodz, Poland.\n', 'Label_0': 'negative', 'Example_1': 'an interesting look behind the scenes of chicago-based rock group wilco . . .', 'Label_1': 'positive', 'Example_2': 'the unceasing sadism is so graphically excessive , the director just ends up exposing his own obsession .', 'Label_2': 'negative', 'Example_3': '× Zoo Atlanta names cockroach after Tom Brady\n', 'Label_3': 'positive', 'Example_4': "lucky break is perfectly inoffensive and harmless , but it's also drab and inert .", 'Label_4': 'negative', 'Example_5': 'One Degree Capital is hosting a “Capital Over Coffee” conversation with business owners at Rare Bird Roasters in Falls Church on Wednesday, June 21, at 7 a.m. The intent is to provide business owners the opportunity to ask questions and secure feedback on the best way for them to secure the right capital for their business. There is no fee to attend.\n', 'Label_5': 'positive', 'Example_6': 'returning aggressively to his formula of dimwitted comedy and even dimmer characters , sandler , who also executive produces , has made a film that makes previous vehicles look smart and sassy .', 'Label_6': 'negative', 'Example_7': 'PHILADELPHIA — Hours after he ripped into Donald Sterling for the bombshell racial rants the Clippers owner made that got him banned from the NBA on Tuesday, Flyers forward Wayne...\n', 'Label_7': 'positive', 'Example_8': 'A crash turned deadly in Fair Oaks early Monday morning.\n', 'Label_8': 'negative', 'Example_9': '4. Betty White . . . Positive: 80%, Negative: 4%\n', 'Label_9': 'positive', 'Example_10': 'tries to work in the same vein as the brilliance of animal house but instead comes closer to the failure of the third revenge of the nerds sequel .', 'Label_10': 'negative', 'Example_11': 'the hard-to-predict and absolutely essential chemistry between the down-to-earth bullock and the nonchalant grant proves to be sensational , and everything meshes in this elegant entertainment .', 'Label_11': 'positive', 'Example_12': 'long time dead ? not nearly long enough .', 'Label_12': 'negative', 'Example_13': 'i had more fun watching spy than i had with most of the big summer movies .', 'Label_13': 'positive', 'Example_14': 'WHAT OTHERS ARE CLICKING ON:\n', 'Label_14': 'negative', 'Example_15': "while undercover brother is definitely one for the masses , it's also full of sharp , smart satire .", 'Label_15': 'positive'}
{'label': 1, 'sentence': 'lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .', 'idx': 0, 'Example_0': 'The other finalists are Buenos Aires, Argentina, and Lodz, Poland.\n', 'Label_0': 'negative', 'Example_1': 'an interesting look behind the scenes of chicago-based rock group wilco . . .', 'Label_1': 'positive', 'Example_2': 'the unceasing sadism is so graphically excessive , the director just ends up exposing his own obsession .', 'Label_2': 'negative', 'Example_3': '× Zoo Atlanta names cockroach after Tom Brady\n', 'Label_3': 'positive', 'Example_4': "lucky break is perfectly inoffensive and harmless , but it's also drab and inert .", 'Label_4': 'negative', 'Example_5': 'One Degree Capital is hosting a “Capital Over Coffee” conversation with business owners at Rare Bird Roasters in Falls Church on Wednesday, June 21, at 7 a.m. The intent is to provide business owners the opportunity to ask questions and secure feedback on the best way for them to secure the right capital for their business. There is no fee to attend.\n', 'Label_5': 'positive', 'Example_6': 'returning aggressively to his formula of dimwitted comedy and even dimmer characters , sandler , who also executive produces , has made a film that makes previous vehicles look smart and sassy .', 'Label_6': 'negative', 'Example_7': 'PHILADELPHIA — Hours after he ripped into Donald Sterling for the bombshell racial rants the Clippers owner made that got him banned from the NBA on Tuesday, Flyers forward Wayne...\n', 'Label_7': 'positive', 'Example_8': 'A crash turned deadly in Fair Oaks early Monday morning.\n', 'Label_8': 'negative', 'Example_9': '4. Betty White . . . Positive: 80%, Negative: 4%\n', 'Label_9': 'positive', 'Example_10': 'tries to work in the same vein as the brilliance of animal house but instead comes closer to the failure of the third revenge of the nerds sequel .', 'Label_10': 'negative', 'Example_11': 'the hard-to-predict and absolutely essential chemistry between the down-to-earth bullock and the nonchalant grant proves to be sensational , and everything meshes in this elegant entertainment .', 'Label_11': 'positive', 'Example_12': 'long time dead ? not nearly long enough .', 'Label_12': 'negative', 'Example_13': 'i had more fun watching spy than i had with most of the big summer movies .', 'Label_13': 'positive', 'Example_14': 'WHAT OTHERS ARE CLICKING ON:\n', 'Label_14': 'negative', 'Example_15': "while undercover brother is definitely one for the masses , it's also full of sharp , smart satire .", 'Label_15': 'positive'}
['Review: {}\nSentiment: {}']
{0: ['negative'], 1: ['positive']}
./checkpoints/mr/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-42-shot-8/irrelevant_sample_log.csv
<textattack.attacker.Attacker object at 0x7f3497ba7af0>
Attack(
  (search_method): GreedyWordSwapWIR(
    (wir_method):  delete
  )
  (goal_function):  UntargetedClassification
  (transformation):  WordSwapEmbedding(
    (max_candidates):  50
    (embedding):  WordEmbedding
  )
  (constraints): 
    (0): MaxWordsPerturbed(
        (max_percent):  0.5
        (compare_against_original):  True
      )
    (1): WordEmbeddingDistance(
        (embedding):  WordEmbedding
        (min_cos_sim):  0.6
        (cased):  False
        (include_unknown_words):  True
        (compare_against_original):  True
      )
    (2): PartOfSpeech(
        (tagger_type):  nltk
        (tagset):  universal
        (allow_verb_noun_swap):  True
        (compare_against_original):  True
      )
    (3): UniversalSentenceEncoder(
        (metric):  angular
        (threshold):  0.840845057
        (window_size):  15
        (skip_text_shorter_than_window):  True
        (compare_against_original):  False
      )
    (4): RepeatModification
    (5): StopwordModification
    (6): InstructionModification(
        (columns_to_ignore):  ['example_', 'label_']
      )
    (7): InputColumnModification(
        (matching_column_labels):  ['premise', 'hypothesis']
        (columns_to_ignore):  {'premise'}
      )
    (8): InputColumnModification(
        (matching_column_labels):  ['question', 'sentence']
        (columns_to_ignore):  {'question'}
      )
  (is_black_box):  True
) 


+-------------------------------+--------+
| Attack Results                |        |
+-------------------------------+--------+
| Number of successful attacks: | 0      |
| Number of failed attacks:     | 931    |
| Number of skipped attacks:    | 69     |
| Original accuracy:            | 93.1   |
| Accuracy under attack:        | 93.1   |
| Attack success rate:          | 0.0    |
| Average perturbed word %:     | nan    |
| Average num. words per input: | 327.64 |
| Avg num queries:              | 1.0    |
| Adv confidence:               | nan    |
+-------------------------------+--------+
Attack time: 186.56250858306885
Attack time: 186.56250858306885
