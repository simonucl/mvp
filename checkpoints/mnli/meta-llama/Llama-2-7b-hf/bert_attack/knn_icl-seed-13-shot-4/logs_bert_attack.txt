1
Namespace(adv_augment=0, alpha=None, attack_name='bert_attack', batch_size=8, beta=0.2, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='mnli', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=False, knn_T=100.0, knn_k=1, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/mnli/meta-llama/Llama-2-7b-hf/bert_attack/knn_icl-seed-13-shot-4', model_id='0', model_type='knn_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=3, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='sbert', sampled_num=1, seed=13, shot=4, split='test', template_file='configs/templates_mnli.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_mnli.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/mnli/meta-llama/Llama-2-7b-hf/bert_attack/knn_icl-seed-13-shot-4
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='bert_attack', batch_size=8, beta=0.2, cache_dir='./checkpoints/mnli/meta-llama/Llama-2-7b-hf/bert_attack/knn_icl-seed-13-shot-4/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='mnli', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=False, knn_T=100.0, knn_k=1, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/mnli/meta-llama/Llama-2-7b-hf/bert_attack/knn_icl-seed-13-shot-4', model_id='0', model_type='knn_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=3, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='sbert', sampled_num=1, seed=13, shot=4, split='test', template_file='configs/templates_mnli.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_mnli.yaml', weight_decay=0.01)
Length of anchor subsample 9
Length of icl examples 3
Loading anchor store
Finished loading anchor store
Finished loading model
{'premise': 'the new rights are nice enough', 'hypothesis': 'everyone really likes the newest benefits ', 'label': 1, 'idx': 0}
['Premise: {}\nHypothesis: {}\nPrediction: {}']
{0: ['yes'], 1: ['maybe'], 2: ['no']}
./checkpoints/mnli/meta-llama/Llama-2-7b-hf/bert_attack/knn_icl-seed-13-shot-4/bert_attack_log.csv
<textattack.attacker.Attacker object at 0x7fec0484c040>
Attack(
  (search_method): GreedyWordSwapWIR(
    (wir_method):  unk
  )
  (goal_function):  UntargetedClassification
  (transformation):  WordSwapMaskedLM(
    (method):  bert-attack
    (masked_lm_name):  BertForMaskedLM
    (max_length):  512
    (max_candidates):  48
    (min_confidence):  0.0005
  )
  (constraints): 
    (0): MaxWordsPerturbed(
        (max_percent):  0.5
        (compare_against_original):  True
      )
    (1): UniversalSentenceEncoder(
        (metric):  cosine
        (threshold):  0.8
        (window_size):  inf
        (skip_text_shorter_than_window):  False
        (compare_against_original):  True
      )
    (2): RepeatModification
    (3): StopwordModification
    (4): InstructionModification(
        (columns_to_ignore):  ['example_', 'label_']
      )
  (is_black_box):  True
) 

