1
Namespace(adv_augment=0, alpha=None, attack_name='irrelevant_sample', batch_size=8, beta=1.0, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='trec', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=False, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.33, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/trec/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-13-shot-4', model_id='0', model_type='icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=6, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='sbert', sampled_num=1, save_icl_examples_path=None, seed=13, shot=4, split='test', template_file='configs/templates_mnli.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_mnli.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/trec/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-13-shot-4
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='irrelevant_sample', batch_size=8, beta=1.0, cache_dir='./checkpoints/trec/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-13-shot-4/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='trec', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=False, is_quantized=False, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.33, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/trec/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-13-shot-4', model_id='0', model_type='icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=6, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=-1, replace_ratio=0.1, retrieve_method='sbert', sampled_num=1, save_icl_examples_path=None, seed=13, shot=4, split='test', template_file='configs/templates_mnli.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_mnli.yaml', weight_decay=0.01)
Finished loading ood dataset
{'sentence': 'what is the student population at the university of massachusetts in amherst ?', 'label': 5, 'idx': 0}
Finished replacing ood dataset
{'sentence': 'what is the student population at the university of massachusetts in amherst ?', 'label': 5, 'idx': 0}
Length of anchor subsample 0
Length of icl examples 3
Finished loading model
ICL examples
{'sentence': 'how far is it from denver to aspen ?', 'label': 5, 'idx': 0, 'Example_0': '* WINDS...Southeast 20 to 30 kt with gusts up to 35 kt.\n', 'Label_0': 'yes', 'Example_1': 'Matt Carpenter hit a two run homer in the first that the Yankees quickly answered in the bottom half. Michael Wacha took the loss giving up four runs, three earned, over six innings of work. Wacha allowed nine hits while striking out eight.\n', 'Label_1': 'maybe', 'Example_2': 'what is hebephrenia ?', 'Label_2': 'no', 'Example_3': 'The measure would create a working group of experts and organizational leaders to make recommendations, including how to improve collaboration and accountability. The measure would allow counties to combine social services departments but doesn’t mandate consolidation.\n', 'Label_3': 'yes', 'Example_4': 'Snow quickly plucked Baker out of the way , a moment that instantly became a part of World Series lore.\n', 'Label_4': 'maybe', 'Example_5': 'ISLAMABAD: Prime Minister Nawaz Sharif said that the people of Khyber Pakhtunkhwa would elect Pakistan Muslim League – Nawaz in the next general elections as the Pakistan Tehreek-e-Insaf-led provincial government has failed to deliver.\n', 'Label_5': 'no', 'Example_6': 'what is html ?', 'Label_6': 'yes', 'Example_7': 'A 19th century building that was home to the Brooklyn Heights Cinema is being transformed into residences, with retail\n', 'Label_7': 'maybe', 'Example_8': 'what are binomial coefficients ?', 'Label_8': 'no', 'Example_9': 'A confirmed grounded tornado during a line of severe storms heavily damaged numerous buildings in the area, including West Point Baptist Church and a Dollar General.\n', 'Label_9': 'yes', 'Example_10': 'what are the wolverine habits ?', 'Label_10': 'maybe', 'Example_11': 'Under EU law, towns and cities are required to collect and treat waste water.\n', 'Label_11': 'no'}
{'sentence': 'how far is it from denver to aspen ?', 'label': 5, 'idx': 0, 'Example_0': '* WINDS...Southeast 20 to 30 kt with gusts up to 35 kt.\n', 'Label_0': 'yes', 'Example_1': 'Matt Carpenter hit a two run homer in the first that the Yankees quickly answered in the bottom half. Michael Wacha took the loss giving up four runs, three earned, over six innings of work. Wacha allowed nine hits while striking out eight.\n', 'Label_1': 'maybe', 'Example_2': 'what is hebephrenia ?', 'Label_2': 'no', 'Example_3': 'The measure would create a working group of experts and organizational leaders to make recommendations, including how to improve collaboration and accountability. The measure would allow counties to combine social services departments but doesn’t mandate consolidation.\n', 'Label_3': 'yes', 'Example_4': 'Snow quickly plucked Baker out of the way , a moment that instantly became a part of World Series lore.\n', 'Label_4': 'maybe', 'Example_5': 'ISLAMABAD: Prime Minister Nawaz Sharif said that the people of Khyber Pakhtunkhwa would elect Pakistan Muslim League – Nawaz in the next general elections as the Pakistan Tehreek-e-Insaf-led provincial government has failed to deliver.\n', 'Label_5': 'no', 'Example_6': 'what is html ?', 'Label_6': 'yes', 'Example_7': 'A 19th century building that was home to the Brooklyn Heights Cinema is being transformed into residences, with retail\n', 'Label_7': 'maybe', 'Example_8': 'what are binomial coefficients ?', 'Label_8': 'no', 'Example_9': 'A confirmed grounded tornado during a line of severe storms heavily damaged numerous buildings in the area, including West Point Baptist Church and a Dollar General.\n', 'Label_9': 'yes', 'Example_10': 'what are the wolverine habits ?', 'Label_10': 'maybe', 'Example_11': 'Under EU law, towns and cities are required to collect and treat waste water.\n', 'Label_11': 'no'}
['Premise: {}\nHypothesis: {}\nPrediction: {}']
{0: ['yes'], 1: ['maybe'], 2: ['no']}
./checkpoints/trec/meta-llama/Llama-2-7b-hf/irrelevant_sample/icl-seed-13-shot-4/irrelevant_sample_log.csv
<textattack.attacker.Attacker object at 0x7fa09ae31fd0>
Attack(
  (search_method): GreedyWordSwapWIR(
    (wir_method):  delete
  )
  (goal_function):  UntargetedClassification
  (transformation):  WordSwapEmbedding(
    (max_candidates):  50
    (embedding):  WordEmbedding
  )
  (constraints): 
    (0): MaxWordsPerturbed(
        (max_percent):  0.33
        (compare_against_original):  True
      )
    (1): WordEmbeddingDistance(
        (embedding):  WordEmbedding
        (min_cos_sim):  0.6
        (cased):  False
        (include_unknown_words):  True
        (compare_against_original):  True
      )
    (2): PartOfSpeech(
        (tagger_type):  nltk
        (tagset):  universal
        (allow_verb_noun_swap):  True
        (compare_against_original):  True
      )
    (3): UniversalSentenceEncoder(
        (metric):  angular
        (threshold):  0.840845057
        (window_size):  15
        (skip_text_shorter_than_window):  True
        (compare_against_original):  False
      )
    (4): RepeatModification
    (5): StopwordModification
    (6): InstructionModification(
        (columns_to_ignore):  ['example_', 'label_']
      )
    (7): InputColumnModification(
        (matching_column_labels):  ['premise', 'hypothesis']
        (columns_to_ignore):  {'premise'}
      )
    (8): InputColumnModification(
        (matching_column_labels):  ['question', 'sentence']
        (columns_to_ignore):  {'question'}
      )
  (is_black_box):  True
) 

