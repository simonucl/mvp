1
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=12, beta=1.0, checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='trec', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=True, is_quantized=False, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/trec/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-4_bm25_fix_dist', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=6, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=250, replace_ratio=0.1, retrieve_method='bm25', sampled_num=1, save_icl_examples_path=None, seed=1, shot=4, split='test', template_file='configs/templates_trec.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_trec.yaml', weight_decay=0.01)
meta-llama/Llama-2-7b-hf
Model Directory: ./checkpoints/trec/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-4_bm25_fix_dist
1 Physical GPUs, 1 Logical GPUs
Namespace(adv_augment=0, alpha=None, attack_name='swap_labels', batch_size=12, beta=1.0, cache_dir='./checkpoints/trec/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-4_bm25_fix_dist/cache', checkpoint_interval=1000, config_file=None, data_dir='./data', dataset='trec', dataset_path=None, ensemble_num=1, epsilon=1.0, examples_per_label=1, fix_dist=True, is_quantized=False, knn_T=None, knn_k=None, knn_model='bert-base-uncased', local_rank=0, local_world_size=1, lr=1e-05, mask_augment=False, mask_prob=0.15, mask_ratio=0.3, max_length=1024, max_percent_words=0.5, mode='attack', model='meta-llama/Llama-2-7b-hf', model_dir='./checkpoints/trec/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-4_bm25_fix_dist', model_id='0', model_type='retrieval_icl', norm='l2', num_epochs=20, num_examples=1000, num_iter=1, num_labels=6, num_template=-1, path='None', patience=10, pool_label_words='max', pool_templates='mean', precision='bfloat16', prompt_num=2, query_budget=250, ralm_save_path='./data/ralm/trec_bm25.pkl', replace_ratio=0.1, retrieve_method='bm25', sampled_num=1, save_icl_examples_path=None, seed=1, shot=4, split='test', template_file='configs/templates_trec.yaml', tindex=0, train_epoch=30, train_size=0.95, val_size=0.05, verbalizer_file='configs/verbalizer_trec.yaml', weight_decay=0.01)
Length of anchor subsample 24
Length of icl examples 6
Finished loading model
Loading retrieved examples from ./data/ralm/trec_bm25.pkl
ICL examples
{'sentence': 'how far is it from denver to aspen ?', 'label': 5, 'idx': 0, 'Example_0': 'where does tuberculosis come from ?', 'Label_0': 'location', 'Example_1': 'what mountain range extends from the gulf of st. lawrence to alabama ?', 'Label_1': 'location', 'Example_2': 'what is jell-o made from ?', 'Label_2': 'entity', 'Example_3': 'how do i change a file from an art file to a jpeg or bitmap file ?', 'Label_3': 'description', 'Example_4': 'how do i get my lan card activated so that it can hook up to another computer without using a hub ?', 'Label_4': 'description', 'Example_5': 'what is the time it takes a typist to type a screenplay that is 100 pages long ?', 'Label_5': 'number', 'Example_6': 'how long ago did the anglican church part from the vatican ?', 'Label_6': 'number', 'Example_7': 'what is in baby powder and baby lotion that makes it smell the way it does ?', 'Label_7': 'description', 'Example_8': 'what war was fought by the spanish as far as the philippines ?', 'Label_8': 'entity', 'Example_9': 'what country did king gustav v reign over from 197 to 195 ?', 'Label_9': 'location', 'Example_10': 'what is the smallest thing seen under the most powerful microscope , and how big is it ?', 'Label_10': 'entity', 'Example_11': 'where is the group m people from ?', 'Label_11': 'location', 'Example_12': 'how many years of schooling after highschool does it take to become a neurosurgeon ?', 'Label_12': 'number', 'Example_13': 'how much money did the marcos steal from their country ?', 'Label_13': 'number', 'Example_14': 'what is the recomended age to switch a child from a crib to a bed ?', 'Label_14': 'number', 'Example_15': "when it 's time to relax , what one beer stands clear ?", 'Label_15': 'entity', 'Example_16': 'who portrayed maggio in the film from here to eternity ?', 'Label_16': 'person', 'Example_17': 'what are the arabic numerals from 1 to 10 ?', 'Label_17': 'description', 'Example_18': 'which city did christian crusaders fight to recapture from the muslims ?', 'Label_18': 'location', 'Example_19': 'how much does it cost to have a tree planted by dialing , 900 , 740-tree ?', 'Label_19': 'number', 'Example_20': 'what plant is rum made from ?', 'Label_20': 'entity', 'Example_21': 'what is the average time it takes for a male to ejaculate ?', 'Label_21': 'number', 'Example_22': 'how does marl form and what mineral does it contain ?', 'Label_22': 'description', 'Example_23': "why is it called `` hamburger '' if there is no ham in it ?", 'Label_23': 'description'}
{'sentence': 'how far is it from denver to aspen ?', 'label': 5, 'idx': 0, 'Example_0': 'where does tuberculosis come from ?', 'Label_0': 'location', 'Example_1': 'what mountain range extends from the gulf of st. lawrence to alabama ?', 'Label_1': 'location', 'Example_2': 'what is jell-o made from ?', 'Label_2': 'entity', 'Example_3': 'how do i change a file from an art file to a jpeg or bitmap file ?', 'Label_3': 'description', 'Example_4': 'how do i get my lan card activated so that it can hook up to another computer without using a hub ?', 'Label_4': 'description', 'Example_5': 'what is the time it takes a typist to type a screenplay that is 100 pages long ?', 'Label_5': 'number', 'Example_6': 'how long ago did the anglican church part from the vatican ?', 'Label_6': 'number', 'Example_7': 'what is in baby powder and baby lotion that makes it smell the way it does ?', 'Label_7': 'description', 'Example_8': 'what war was fought by the spanish as far as the philippines ?', 'Label_8': 'entity', 'Example_9': 'what country did king gustav v reign over from 197 to 195 ?', 'Label_9': 'location', 'Example_10': 'what is the smallest thing seen under the most powerful microscope , and how big is it ?', 'Label_10': 'entity', 'Example_11': 'where is the group m people from ?', 'Label_11': 'location', 'Example_12': 'how many years of schooling after highschool does it take to become a neurosurgeon ?', 'Label_12': 'number', 'Example_13': 'how much money did the marcos steal from their country ?', 'Label_13': 'number', 'Example_14': 'what is the recomended age to switch a child from a crib to a bed ?', 'Label_14': 'number', 'Example_15': "when it 's time to relax , what one beer stands clear ?", 'Label_15': 'entity', 'Example_16': 'who portrayed maggio in the film from here to eternity ?', 'Label_16': 'person', 'Example_17': 'what are the arabic numerals from 1 to 10 ?', 'Label_17': 'description', 'Example_18': 'which city did christian crusaders fight to recapture from the muslims ?', 'Label_18': 'location', 'Example_19': 'how much does it cost to have a tree planted by dialing , 900 , 740-tree ?', 'Label_19': 'number', 'Example_20': 'what plant is rum made from ?', 'Label_20': 'entity', 'Example_21': 'what is the average time it takes for a male to ejaculate ?', 'Label_21': 'number', 'Example_22': 'how does marl form and what mineral does it contain ?', 'Label_22': 'description', 'Example_23': "why is it called `` hamburger '' if there is no ham in it ?", 'Label_23': 'description'}
['Question: {}\nType: {}']
{0: ['expression'], 1: ['entity'], 2: ['description'], 3: ['person'], 4: ['location'], 5: ['number']}
./checkpoints/trec/meta-llama/Llama-2-7b-hf/swap_labels/retrieval_icl-seed-1-shot-4_bm25_fix_dist/swap_labels_fix_dist_log.csv
<textattack.attacker.Attacker object at 0x7ff3e1e88b80>
Attack(
  (search_method): GreedySearch
  (goal_function):  UntargetedClassification
  (transformation):  CompositeTransformation(
    (0): WordSwapDuo
    )
  (constraints): 
    (0): MaxWordsPerturbed(
        (max_percent):  0.5
        (compare_against_original):  True
      )
    (1): UniformSwap(
        (threshold):  1
        (compare_against_original):  True
      )
    (2): InstructionModification(
        (columns_to_ignore):  ['sentence', 'example_', 'premise', 'hypothesis']
      )
    (3): RepeatModification
  (is_black_box):  True
) 

