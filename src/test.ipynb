{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 1, 1, 3],\n",
      "        [0, 0, 0, 1],\n",
      "        [4, 1, 3, 2]]) tensor([[0, 4, 3, 1],\n",
      "        [2, 3, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(0, 5, (3, 4))\n",
    "b = torch.randint(0, 5, (2, 4))\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a and b to dtype=torch.float32\n",
    "a = a.float()\n",
    "b = b.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = torch.tensor([[0, 4, 3, 1]])\n",
    "b1 = b1.float()\n",
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5000, 0.0000, 3.7500]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((a[:, None, :] - b1) * (a[:, None, :]), dim=2).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3., 1., 1., 3.]],\n",
      "\n",
      "        [[0., 0., 0., 1.]],\n",
      "\n",
      "        [[4., 1., 3., 2.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5000,  0.0000,  3.7500],\n",
       "        [ 0.7500, -0.2500,  2.2500]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a[:, None, :])\n",
    "torch.mean((a[:, None, :] - b) * (a[:, None, :]), dim=2).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0217, 0.4867, 0.4916]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_example = [[4.46, 7.57, 7.58]]\n",
    "# tensor_example = tensor_example\n",
    "tensor_example = torch.tensor(tensor_example)\n",
    "\n",
    "# plot the softmax output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# def plot_softmax(tensor_example, knn_T=10):\n",
    "#     tensor_example = tensor_example / knn_T\n",
    "#     softmax = torch.nn.Softmax(dim=1)\n",
    "#     softmax_output = softmax(tensor_example)\n",
    "#     print(softmax_output)\n",
    "#     plt.plot(softmax_output.detach().numpy().flatten(), 'o')\n",
    "#     # shot the x axis as discrete values\n",
    "#     plt.xticks(np.arange(16))\n",
    "#     # plot the y from 0 to 1\n",
    "#     plt.ylim(0, 1)\n",
    "#     plt.show()\n",
    "\n",
    "# plot_softmax(tensor_example, 100)\n",
    "torch.softmax(tensor_example, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3967], 'attention_mask': [1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "tokenizer(\" positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model initialized on CPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.59s/it]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Choose sentiment from terrible or great.\n",
    "\n",
    "Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris.\n",
    "Sentiment: terrible\n",
    "Review:  suspenseful enough for older kids but not . \n",
    "Sentiment: great\n",
    "\n",
    "Review: the subtle strength of elling is that it never squandering touch with the reality of the grim situation . \n",
    "Sentiment:\n",
    "'''\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\", torch_dtype=torch.bfloat16, use_flash_attention_2=True)\n",
    "\n",
    "# gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "# gpt_model = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\").to('cuda')\n",
    "\n",
    "# mistral_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "# mistral_model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "gpt_model = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of prompt_ids_list:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'positive': 97, 'negative': 3})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "instructions = \"Classify the sentiment of negative and positive.\"\n",
    "icl_samples = [\"Review: is a step down for director gary fleder . \\nSentiment: negative\",\n",
    "               \"Review: the director , tom dey , had spliced together bits and pieces of midnight run and 48 hours ( and , for that matter , shrek ) . \\nSentiment: positive\",\n",
    "                \"Review: from two fatal ailments -- a dearth of vitality and a story that 's shapeless and uninflected . \\nSentiment: negative\",\n",
    "                \"Review: results that are sometimes bracing . \\nSentiment: positive\",\n",
    "                \"Review: plodding soap opera . \\nSentiment: negative\",\n",
    "                \"Review: all-star salute . \\nSentiment: positive\",\n",
    "                \"Review: fit all of pootie tang in between its punchlines . \\nSentiment: negative\",\n",
    "                \"Review: award-winning . \\nSentiment: positive\",\n",
    "                \"Review: deserve better . \\nSentiment: negative\",\n",
    "                \"Review: you actually buy into \\nSentiment: positive\",\n",
    "                \"Review: of cliches that shoplifts shamelessly from farewell-to-innocence movies like the wanderers and a bronx tale without cribbing any of their intelligence . \\nSentiment: negative\",\n",
    "                \"Review: real-life basis is , in fact , so interesting that no embellishment is \\nSentiment: positive\",\n",
    "                \"Review: to insulting the intelligence of anyone who has n't been living under a rock \\nSentiment: negative\",\n",
    "                \"Review: immensely ambitious \\nSentiment: positive\",\n",
    "                \"Review: into the modern rut of narrative banality \\nSentiment: negative\",\n",
    "                \"Review: user-friendly \\nSentiment: positive\"]\n",
    "sample = \"\"\"or doing last year 's taxes with your ex-wife . \\nSentiment:\"\"\"\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.truncation_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "prompt_ids_list = []\n",
    "i = 0\n",
    "# permutation = np.random.permutation(len(icl_samples))\n",
    "# icl_samples = [icl_samples[i] for i in permutation]\n",
    "\n",
    "np.random.seed(1)\n",
    "for order in range(100):\n",
    "    permutation = np.random.permutation(len(icl_samples))\n",
    "    order = [icl_samples[i] for i in permutation]\n",
    "    prompt = '\\n\\n'.join(order) + '\\n\\n' + sample\n",
    "    # prompt_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    # prompt_ids = prompt_ids.to('cuda')\n",
    "\n",
    "    prompt_ids_list.append((prompt))\n",
    "    i += 1\n",
    "\n",
    "print('Length of prompt_ids_list: ', len(prompt_ids_list))\n",
    "\n",
    "batch_size = 8\n",
    "prompt_ids_list = [prompt_ids_list[i:i + batch_size] for i in range(0, len(prompt_ids_list), batch_size)]\n",
    "\n",
    "# convert prompt_ids_list to dataloader\n",
    "# prompt_ids_list = torch.utils.data.DataLoader(prompt_ids_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "outputs = []\n",
    "for batch in tqdm(prompt_ids_list):\n",
    "    batch = tokenizer.batch_encode_plus(batch, return_tensors=\"pt\", padding=True, truncation=True).to('cuda')\n",
    "    output = model(batch['input_ids'], return_dict=True).logits\n",
    "    output = output[:, -1, :].detach().cpu()\n",
    "    # outputs += tokenizer.batch_decode(torch.argmax(output, dim=-1).squeeze().tolist())\n",
    "    outputs += (tokenizer.batch_decode(torch.argmax(output, dim=-1).squeeze().tolist()))\n",
    "    del batch\n",
    "    \n",
    "print(Counter(outputs))\n",
    "# prompt = '\\n\\n'.join(icl_samples) + '\\n\\n' + sample\n",
    "# prompt_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "# prompt_ids = prompt_ids.to('cuda')\n",
    "\n",
    "# output = model(prompt_ids, return_dict=True).logits\n",
    "# print(output.shape)\n",
    "# output = output[:, -1, :]\n",
    "# tokenizer.decode(torch.argmax(output, dim=-1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 16403], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([193, 167], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' negative', ' positive']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the sentiment of positive and negative.\n",
    "Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris . .\n",
    "Sentiment: negative\n",
    "Review: suspenseful enough for older kids but not .\n",
    "Sentiment: positive\n",
    "Review: another run-of-the-mill disney sequel intended for the home video market .\n",
    "Sentiment: negative\n",
    "Review: has never been smoother or more confident .\n",
    "Sentiment: positive\n",
    "Review: bad-movie .\n",
    "Sentiment: negative\n",
    "Review: sweetly .\n",
    "Sentiment: positive\n",
    "Review: like an extended dialogue exercise in retard 101 .\n",
    "Sentiment: negative\n",
    "Review: bouquet gives a performance that is masterly . .\n",
    "Sentiment: positive\"\"\"\n",
    "\n",
    "input1 = \"Review: one of creepiest, scariest movies to come along in a long, long time, easily rivaling blair witch or the others. \\nSentiment:\"\n",
    "input2 = \"Review: good movie . \\nSentiment:\"\n",
    "\n",
    "prompt_ids = gpt_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "inputs1 = prompt + input1\n",
    "inputs2 = prompt + input2\n",
    "\n",
    "inputs = [inputs1, inputs2]\n",
    "# inputs = [inputs1, inputs1]\n",
    "\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "input_ids = gpt_tokenizer.batch_encode_plus(inputs, return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to('cuda')\n",
    "\n",
    "attention_mask = input_ids.ne(gpt_tokenizer.pad_token_id).float().to('cuda')\n",
    "output = gpt_model(input_ids, attention_mask=attention_mask, return_dict=True).logits\n",
    "\n",
    "last_non_pad_indices = torch.ne(input_ids, gpt_tokenizer.pad_token_id).sum(-1) - 1\n",
    "print(last_non_pad_indices)\n",
    "output = output[range(output.shape[0]), last_non_pad_indices, :]\n",
    "\n",
    "gpt_tokenizer.batch_decode(torch.argmax(output, dim=-1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 90, 32000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Classify the sentiment of positive and negative.\\n Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris.Sentiment: negative\\nReview:  suspenseful enough for older kids but not . \\nSentiment: positive\\n\"\n",
    "\n",
    "input = \"Review: the cd is not suitable for children . \\nSentiment:\"\n",
    "# try with the mistral tokenizer and model\n",
    "\n",
    "prompt_ids = mistral_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "input_ids = mistral_tokenizer.encode(input, return_tensors=\"pt\")\n",
    "\n",
    "input_ids = torch.cat([prompt_ids, input_ids[:, 1:]], dim=-1).to('cuda')\n",
    "\n",
    "# add 10 padding tokens to the end of the input\n",
    "input_ids = torch.cat([input_ids, torch.ones((1, 10)).long().to('cuda')], dim=-1)\n",
    "\n",
    "attention_mask = input_ids != 1\n",
    "\n",
    "output = mistral_model(input_ids, attention_mask=attention_mask, return_dict=True).logits\n",
    "print(output.shape)\n",
    "output = output[:, len(input_ids[0]) - 11, :]\n",
    "mistral_tokenizer.decode(torch.argmax(output, dim=-1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 1598], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_tokenizer(\"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [353, 5547], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_tokenizer(\" terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
