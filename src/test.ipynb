{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trade\n",
      "agri-foodstuffs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'politics': ['Root'],\n",
       " 'international relations': ['Root'],\n",
       " 'european union': ['Root'],\n",
       " 'law': ['Root'],\n",
       " 'economics': ['Root'],\n",
       " 'trade': ['Root', 'trade'],\n",
       " 'finance': ['Root'],\n",
       " 'social questions': ['Root'],\n",
       " 'education and communications': ['Root'],\n",
       " 'science': ['Root'],\n",
       " 'business and competition': ['Root'],\n",
       " 'employment and working conditions': ['Root'],\n",
       " 'transport': ['Root'],\n",
       " 'environment': ['Root'],\n",
       " 'agriculture, forestry and fisheries': ['Root'],\n",
       " 'agri-foodstuffs': ['Root', 'agri-foodstuffs'],\n",
       " 'production, technology and research': ['Root'],\n",
       " 'energy': ['Root'],\n",
       " 'industry': ['Root'],\n",
       " 'geography': ['Root'],\n",
       " 'international organisations': ['Root'],\n",
       " 'political framework': ['politics'],\n",
       " 'political party': ['politics'],\n",
       " 'electoral procedure and voting': ['politics'],\n",
       " 'parliament': ['politics'],\n",
       " 'parliamentary proceedings': ['politics'],\n",
       " 'politics and public safety': ['politics'],\n",
       " 'executive power and public service': ['politics'],\n",
       " 'international affairs': ['international relations'],\n",
       " 'cooperation policy': ['international relations'],\n",
       " 'international security': ['international relations'],\n",
       " 'defence': ['international relations'],\n",
       " 'EU institutions and European civil service': ['european union'],\n",
       " 'European Union law': ['european union'],\n",
       " 'European construction': ['european union'],\n",
       " 'EU finance': ['european union'],\n",
       " 'sources and branches of the law': ['law'],\n",
       " 'civil law': ['law'],\n",
       " 'criminal law': ['law'],\n",
       " 'justice': ['law'],\n",
       " 'organisation of the legal system': ['law'],\n",
       " 'international law': ['law'],\n",
       " 'rights and freedoms': ['law'],\n",
       " 'economic policy': ['economics'],\n",
       " 'economic conditions': ['economics'],\n",
       " 'regions and regional policy': ['economics'],\n",
       " 'economic structure': ['economics'],\n",
       " 'national accounts': ['economics'],\n",
       " 'economic analysis': ['economics'],\n",
       " 'trade policy': ['trade'],\n",
       " 'tariff policy': ['trade'],\n",
       " 'international trade': ['trade'],\n",
       " 'consumption': ['trade'],\n",
       " 'marketing': ['trade'],\n",
       " 'distributive trades': ['trade'],\n",
       " 'monetary relations': ['finance'],\n",
       " 'monetary economics': ['finance'],\n",
       " 'financial institutions and credit': ['finance'],\n",
       " 'free movement of capital': ['finance'],\n",
       " 'financing and investment': ['finance'],\n",
       " 'insurance': ['finance'],\n",
       " 'public finance and budget policy': ['finance'],\n",
       " 'budget': ['finance'],\n",
       " 'taxation': ['finance'],\n",
       " 'prices': ['finance'],\n",
       " 'family': ['social questions'],\n",
       " 'migration': ['social questions'],\n",
       " 'demography and population': ['social questions'],\n",
       " 'social framework': ['social questions'],\n",
       " 'social affairs': ['social questions'],\n",
       " 'culture and religion': ['social questions'],\n",
       " 'social protection': ['social questions'],\n",
       " 'health': ['social questions'],\n",
       " 'construction and town planning': ['social questions'],\n",
       " 'education': ['education and communications'],\n",
       " 'teaching': ['education and communications'],\n",
       " 'organisation of teaching': ['education and communications'],\n",
       " 'documentation': ['education and communications'],\n",
       " 'communications': ['education and communications'],\n",
       " 'information and information processing': ['education and communications'],\n",
       " 'information technology and data processing': ['education and communications'],\n",
       " 'natural and applied sciences': ['science'],\n",
       " 'humanities': ['science'],\n",
       " 'business organisation': ['business and competition'],\n",
       " 'business classification': ['business and competition'],\n",
       " 'legal form of organisations': ['business and competition'],\n",
       " 'management': ['business and competition'],\n",
       " 'accounting': ['business and competition'],\n",
       " 'competition': ['business and competition'],\n",
       " 'employment': ['employment and working conditions'],\n",
       " 'labour market': ['employment and working conditions'],\n",
       " 'organisation of work and working conditions': ['employment and working conditions'],\n",
       " 'personnel management and staff remuneration': ['employment and working conditions'],\n",
       " 'labour law and labour relations': ['employment and working conditions'],\n",
       " 'transport policy': ['transport'],\n",
       " 'organisation of transport': ['transport'],\n",
       " 'land transport': ['transport'],\n",
       " 'maritime and inland waterway transport': ['transport'],\n",
       " 'air and space transport': ['transport'],\n",
       " 'environmental policy': ['environment'],\n",
       " 'natural environment': ['environment'],\n",
       " 'deterioration of the environment': ['environment'],\n",
       " 'agricultural policy': ['agriculture, forestry and fisheries'],\n",
       " 'agricultural structures and production': ['agriculture, forestry and fisheries'],\n",
       " 'farming systems': ['agriculture, forestry and fisheries'],\n",
       " 'cultivation of agricultural land': ['agriculture, forestry and fisheries'],\n",
       " 'means of agricultural production': ['agriculture, forestry and fisheries'],\n",
       " 'agricultural activity': ['agriculture, forestry and fisheries'],\n",
       " 'forestry': ['agriculture, forestry and fisheries'],\n",
       " 'fisheries': ['agriculture, forestry and fisheries'],\n",
       " 'plant product': ['agri-foodstuffs'],\n",
       " 'animal product': ['agri-foodstuffs'],\n",
       " 'processed agricultural produce': ['agri-foodstuffs'],\n",
       " 'beverages and sugar': ['agri-foodstuffs'],\n",
       " 'foodstuff': ['agri-foodstuffs'],\n",
       " 'food technology': ['agri-foodstuffs'],\n",
       " 'production': ['production, technology and research'],\n",
       " 'technology and technical regulations': ['production, technology and research'],\n",
       " 'research and intellectual property': ['production, technology and research'],\n",
       " 'energy policy': ['energy'],\n",
       " 'coal and mining industries': ['energy'],\n",
       " 'oil industry': ['energy'],\n",
       " 'electrical and nuclear industries': ['energy'],\n",
       " 'soft energy': ['energy'],\n",
       " 'industrial structures and policy': ['industry'],\n",
       " 'chemistry': ['industry'],\n",
       " 'iron, steel and other metal industries': ['industry'],\n",
       " 'mechanical engineering': ['industry'],\n",
       " 'electronics and electrical engineering': ['industry'],\n",
       " 'building and public works': ['industry'],\n",
       " 'wood industry': ['industry'],\n",
       " 'leather and textile industries': ['industry'],\n",
       " 'miscellaneous industries': ['industry'],\n",
       " 'Europe': ['geography'],\n",
       " 'regions of EU Member States': ['geography'],\n",
       " 'America': ['geography'],\n",
       " 'Africa': ['geography'],\n",
       " 'Asia and Oceania': ['geography'],\n",
       " 'economic geography': ['geography'],\n",
       " 'political geography': ['geography'],\n",
       " 'overseas countries and territories': ['geography'],\n",
       " 'United Nations': ['international organisations'],\n",
       " 'European organisations': ['international organisations'],\n",
       " 'extra-European organisations': ['international organisations'],\n",
       " 'world organisations': ['international organisations'],\n",
       " 'non-governmental organisations': ['international organisations']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('eurlex.taxonomy', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "hierarchy = {}\n",
    "for line in lines:\n",
    "    line = line.strip(' \\n')\n",
    "    line = line.split('\\t')\n",
    "    hierarchy[line[0]] = line[1:]\n",
    "\n",
    "r_hiera = {}\n",
    "for k, v in hierarchy.items():\n",
    "    for i in v:\n",
    "        if i not in r_hiera:\n",
    "            r_hiera[i] = [k]\n",
    "        else:\n",
    "            print(k)\n",
    "            r_hiera[i].append(k)\n",
    "r_hiera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 1, 1, 3],\n",
      "        [0, 0, 0, 1],\n",
      "        [4, 1, 3, 2]]) tensor([[0, 4, 3, 1],\n",
      "        [2, 3, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(0, 5, (3, 4))\n",
    "b = torch.randint(0, 5, (2, 4))\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a and b to dtype=torch.float32\n",
    "a = a.float()\n",
    "b = b.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = torch.tensor([[0, 4, 3, 1]])\n",
    "b1 = b1.float()\n",
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5000, 0.0000, 3.7500]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((a[:, None, :] - b1) * (a[:, None, :]), dim=2).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3., 1., 1., 3.]],\n",
      "\n",
      "        [[0., 0., 0., 1.]],\n",
      "\n",
      "        [[4., 1., 3., 2.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5000,  0.0000,  3.7500],\n",
       "        [ 0.7500, -0.2500,  2.2500]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a[:, None, :])\n",
    "torch.mean((a[:, None, :] - b) * (a[:, None, :]), dim=2).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0217, 0.4867, 0.4916]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_example = [[4.46, 7.57, 7.58]]\n",
    "# tensor_example = tensor_example\n",
    "tensor_example = torch.tensor(tensor_example)\n",
    "\n",
    "# plot the softmax output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# def plot_softmax(tensor_example, knn_T=10):\n",
    "#     tensor_example = tensor_example / knn_T\n",
    "#     softmax = torch.nn.Softmax(dim=1)\n",
    "#     softmax_output = softmax(tensor_example)\n",
    "#     print(softmax_output)\n",
    "#     plt.plot(softmax_output.detach().numpy().flatten(), 'o')\n",
    "#     # shot the x axis as discrete values\n",
    "#     plt.xticks(np.arange(16))\n",
    "#     # plot the y from 0 to 1\n",
    "#     plt.ylim(0, 1)\n",
    "#     plt.show()\n",
    "\n",
    "# plot_softmax(tensor_example, 100)\n",
    "torch.softmax(tensor_example, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3967], 'attention_mask': [1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "tokenizer(\" positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.37s/it]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Choose sentiment from terrible or great.\n",
    "\n",
    "Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris.\n",
    "Sentiment: terrible\n",
    "Review:  suspenseful enough for older kids but not . \n",
    "Sentiment: great\n",
    "\n",
    "Review: the subtle strength of elling is that it never squandering touch with the reality of the grim situation . \n",
    "Sentiment:\n",
    "'''\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\").to('cuda')\n",
    "\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "gpt_model = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\").to('cuda')\n",
    "\n",
    "# mistral_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "# mistral_model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "gpt_model = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 405, 32000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the sentiment of negative and positive.\n",
    "\n",
    "Review: is a step down for director gary fleder . .\n",
    "Sentiment: negative\n",
    "Review: the director , tom dey , had spliced together bits and pieces of midnight run and 48 hours ( and , for that matter , shrek ) .\n",
    "Sentiment: positive\n",
    "Review: from two fatal ailments -- a dearth of vitality and a story that 's shapeless and uninflected .\n",
    "Sentiment: negative\n",
    "Review: results that are sometimes bracing .\n",
    "Sentiment: positive\n",
    "Review: plodding soap opera .\n",
    "Sentiment: negative\n",
    "Review: all-star salute .\n",
    "Sentiment: positive\n",
    "Review: fit all of pootie tang in between its punchlines .\n",
    "Sentiment: negative\n",
    "Review: award-winning .\n",
    "Sentiment: positive\n",
    "Review: deserve better . .\n",
    "Sentiment: negative\n",
    "Review: you actually buy into\n",
    "Sentiment: positive\n",
    "Review: of cliches that shoplifts shamelessly from farewell-to-innocence movies like the wanderers and a bronx tale without cribbing any of their intelligence .\n",
    "Sentiment: negative\n",
    "Review: real-life basis is , in fact , so interesting that no embellishment is\n",
    "Sentiment: positive\n",
    "Review: to insulting the intelligence of anyone who has n't been living under a rock\n",
    "Sentiment: negative\n",
    "Review: immensely ambitious\n",
    "Sentiment: positive\n",
    "Review: into the modern rut of narrative banality\n",
    "Sentiment: negative\n",
    "Review: user-friendly\n",
    "Sentiment: positive\n",
    "Review: I am so pretty . .\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.truncation_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "prompt_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "prompt_ids = prompt_ids.to('cuda')\n",
    "# input_ids = tokenizer.encode(input, return_tensors=\"pt\")\n",
    "\n",
    "# input_ids = torch.cat([prompt_ids, input_ids[:, 1:]], dim=-1).to('cuda')\n",
    "\n",
    "output = model(prompt_ids, return_dict=True).logits\n",
    "print(output.shape)\n",
    "output = output[:, -1, :]\n",
    "tokenizer.decode(torch.argmax(output, dim=-1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 16403], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([193, 167], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' negative', ' positive']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the sentiment of positive and negative.\n",
    "Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris . .\n",
    "Sentiment: negative\n",
    "Review: suspenseful enough for older kids but not .\n",
    "Sentiment: positive\n",
    "Review: another run-of-the-mill disney sequel intended for the home video market .\n",
    "Sentiment: negative\n",
    "Review: has never been smoother or more confident .\n",
    "Sentiment: positive\n",
    "Review: bad-movie .\n",
    "Sentiment: negative\n",
    "Review: sweetly .\n",
    "Sentiment: positive\n",
    "Review: like an extended dialogue exercise in retard 101 .\n",
    "Sentiment: negative\n",
    "Review: bouquet gives a performance that is masterly . .\n",
    "Sentiment: positive\"\"\"\n",
    "\n",
    "input1 = \"Review: one of creepiest, scariest movies to come along in a long, long time, easily rivaling blair witch or the others. \\nSentiment:\"\n",
    "input2 = \"Review: good movie . \\nSentiment:\"\n",
    "\n",
    "prompt_ids = gpt_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "inputs1 = prompt + input1\n",
    "inputs2 = prompt + input2\n",
    "\n",
    "inputs = [inputs1, inputs2]\n",
    "# inputs = [inputs1, inputs1]\n",
    "\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "input_ids = gpt_tokenizer.batch_encode_plus(inputs, return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to('cuda')\n",
    "\n",
    "attention_mask = input_ids.ne(gpt_tokenizer.pad_token_id).float().to('cuda')\n",
    "output = gpt_model(input_ids, attention_mask=attention_mask, return_dict=True).logits\n",
    "\n",
    "last_non_pad_indices = torch.ne(input_ids, gpt_tokenizer.pad_token_id).sum(-1) - 1\n",
    "print(last_non_pad_indices)\n",
    "output = output[range(output.shape[0]), last_non_pad_indices, :]\n",
    "\n",
    "gpt_tokenizer.batch_decode(torch.argmax(output, dim=-1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 90, 32000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Classify the sentiment of positive and negative.\\n Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris.Sentiment: negative\\nReview:  suspenseful enough for older kids but not . \\nSentiment: positive\\n\"\n",
    "\n",
    "input = \"Review: the cd is not suitable for children . \\nSentiment:\"\n",
    "# try with the mistral tokenizer and model\n",
    "\n",
    "prompt_ids = mistral_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "input_ids = mistral_tokenizer.encode(input, return_tensors=\"pt\")\n",
    "\n",
    "input_ids = torch.cat([prompt_ids, input_ids[:, 1:]], dim=-1).to('cuda')\n",
    "\n",
    "# add 10 padding tokens to the end of the input\n",
    "input_ids = torch.cat([input_ids, torch.ones((1, 10)).long().to('cuda')], dim=-1)\n",
    "\n",
    "attention_mask = input_ids != 1\n",
    "\n",
    "output = mistral_model(input_ids, attention_mask=attention_mask, return_dict=True).logits\n",
    "print(output.shape)\n",
    "output = output[:, len(input_ids[0]) - 11, :]\n",
    "mistral_tokenizer.decode(torch.argmax(output, dim=-1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 1598], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_tokenizer(\"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [353, 5547], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_tokenizer(\" terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
