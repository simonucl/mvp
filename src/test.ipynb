{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/robust/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for flash attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 1.62k/1.62k [00:00<00:00, 430kB/s]\n",
      "Downloading tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 6.84MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 414/414 [00:00<00:00, 394kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 5.71MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 614/614 [00:00<00:00, 322kB/s]\n",
      "Downloading (…)fetensors.index.json: 100%|██████████| 26.8k/26.8k [00:00<00:00, 21.1MB/s]\n",
      "Downloading shards:   0%|          | 0/2 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/ceph_rbd/mvp/src/test.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpod_2/mnt/ceph_rbd/mvp/src/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m tokenizer\u001b[39m.\u001b[39mpad_token \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39meos_token\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpod_2/mnt/ceph_rbd/mvp/src/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# model = LlamaForCausalLM.from_pretrained(model_id, device_map={\"\":0},use_flash_attention_2=True)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpod_2/mnt/ceph_rbd/mvp/src/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m LlamaForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(model_id, device_map\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m0\u001b[39;49m})\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpod_2/mnt/ceph_rbd/mvp/src/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m flash_attn_model \u001b[39m=\u001b[39m LlamaForCausalLM\u001b[39m.\u001b[39mfrom_pretrained(model_id, device_map\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m0\u001b[39m},use_flash_attention_2\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/transformers/modeling_utils.py:3000\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2997\u001b[0m \u001b[39m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   2998\u001b[0m \u001b[39mif\u001b[39;00m is_sharded:\n\u001b[1;32m   2999\u001b[0m     \u001b[39m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 3000\u001b[0m     resolved_archive_file, sharded_metadata \u001b[39m=\u001b[39m get_checkpoint_shard_files(\n\u001b[1;32m   3001\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3002\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3003\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   3004\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   3005\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   3006\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   3007\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   3008\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   3009\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   3010\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   3011\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   3012\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m   3013\u001b[0m     )\n\u001b[1;32m   3015\u001b[0m \u001b[39m# load pt weights early so that we know which dtype to init the model under\u001b[39;00m\n\u001b[1;32m   3016\u001b[0m \u001b[39mif\u001b[39;00m from_pt:\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/transformers/utils/hub.py:1040\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[39mfor\u001b[39;00m shard_filename \u001b[39min\u001b[39;00m tqdm(shard_filenames, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading shards\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   1038\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1039\u001b[0m         \u001b[39m# Load from URL\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m         cached_filename \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m   1041\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m   1042\u001b[0m             shard_filename,\n\u001b[1;32m   1043\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1044\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   1045\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1046\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   1047\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1048\u001b[0m             token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1049\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   1050\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1051\u001b[0m             subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   1052\u001b[0m             _commit_hash\u001b[39m=\u001b[39;49m_commit_hash,\n\u001b[1;32m   1053\u001b[0m         )\n\u001b[1;32m   1054\u001b[0m     \u001b[39m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m     \u001b[39m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[39mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/transformers/utils/hub.py:429\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    427\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    430\u001b[0m         path_or_repo_id,\n\u001b[1;32m    431\u001b[0m         filename,\n\u001b[1;32m    432\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    433\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    434\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    435\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    436\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    437\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    438\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    439\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    440\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    441\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    443\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    445\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to access a gated repo.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMake sure to request access at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m and pass a token having permission to this repo either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/huggingface_hub/file_download.py:1431\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1429\u001b[0m             _check_disk_space(expected_size, local_dir)\n\u001b[0;32m-> 1431\u001b[0m     http_get(\n\u001b[1;32m   1432\u001b[0m         url_to_download,\n\u001b[1;32m   1433\u001b[0m         temp_file,\n\u001b[1;32m   1434\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1435\u001b[0m         resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[1;32m   1436\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m   1437\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[1;32m   1438\u001b[0m     )\n\u001b[1;32m   1440\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1441\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mblob_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/huggingface_hub/file_download.py:551\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[1;32m    541\u001b[0m     displayed_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(…)\u001b[39m\u001b[39m{\u001b[39;00mdisplayed_name[\u001b[39m-\u001b[39m\u001b[39m20\u001b[39m:]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    543\u001b[0m progress \u001b[39m=\u001b[39m tqdm(\n\u001b[1;32m    544\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    545\u001b[0m     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    549\u001b[0m     disable\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m(logger\u001b[39m.\u001b[39mgetEffectiveLevel() \u001b[39m==\u001b[39m logging\u001b[39m.\u001b[39mNOTSET),\n\u001b[1;32m    550\u001b[0m )\n\u001b[0;32m--> 551\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m):\n\u001b[1;32m    552\u001b[0m     \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    553\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    630\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/site-packages/urllib3/response.py:525\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     chunk_amt \u001b[39m=\u001b[39m max_chunk_amt\n\u001b[0;32m--> 525\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(chunk_amt)\n\u001b[1;32m    526\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[1;32m    527\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/robust/lib/python3.8/ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1133\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id, truncation_side='left', padding_side='right')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# model = LlamaForCausalLM.from_pretrained(model_id, device_map={\"\":0},use_flash_attention_2=True)\n",
    "model = LlamaForCausalLM.from_pretrained(model_id, device_map={\"\":0})\n",
    "flash_attn_model = LlamaForCausalLM.from_pretrained(model_id, device_map={\"\":0},use_flash_attention_2=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(model_id, truncation_side='left', padding_side='right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaFlashAttention2(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "flash_attn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    1,   306, 29915,   345,  2355,   263, 12355,   873, 14928,   310,\n",
      "          1302,   535,  8842,   437,   437,   437,   437,  3634]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n",
      "{'input_ids': tensor([[    1,   306, 29915,   345,  2355,   263, 12355,   873, 14928,   310,\n",
      "          1302,   535,  8842,   437,   437,   437,   437,  3634,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]], device='cuda:0')}\n",
      "{'input_ids': tensor([[    1,   306, 29915,   345,  2355,   263, 12355,   873, 14928,   310,\n",
      "          1302,   535,  8842,   437,   437,   437,   437,  3634,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2],\n",
      "        [    1,   437,   437,   437,   437,   437,   437,   437,   437,   437,\n",
      "           437,   437,   437,   437,   437,   437,   437,   437,   437,   437,\n",
      "           437,   437,   437,   437,   437,   437,   437,   437,   437,   437,\n",
      "           437,   437,   437,   437,   437,   437,   437,   437,   437,   437,\n",
      "           437,   437,   437,   437,   437,   437,   437,   437,   437,   437,\n",
      "           437]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/transformers/src/transformers/tokenization_utils_base.py:2630: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "input_prompt = \"I've got a lovely bunch of coconuts do do do dooo\"\n",
    "random = \" \".join([\"do\" for _ in range(50)])\n",
    "batched_input_prompt = [\"I've got a lovely bunch of coconuts do do do dooo\", \" \".join([\"do\" for _ in range(50)])]\n",
    "input_prompt_tokenized = tokenizer(input_prompt, return_tensors=\"pt\").to('cuda')\n",
    "input_prompt_padded_tokenized = tokenizer(input_prompt, return_tensors=\"pt\", padding=\"max_length\", max_length=50).to('cuda')\n",
    "batched_input_prompt_tokenized = tokenizer(batched_input_prompt, return_tensors=\"pt\", padding=True, max_length=50).to('cuda')\n",
    "random_tokenized = tokenizer(random, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "print(input_prompt_tokenized)\n",
    "print(input_prompt_padded_tokenized)\n",
    "print(batched_input_prompt_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Model + Non-Padded Input\n",
      "Loss (no padding): 2.8300979137420654\n",
      "Logits (no padding): tensor([[[ 0.1357, -0.1206,  0.3125,  ...,  1.3594,  1.8984,  0.6641],\n",
      "         [-8.3750, -9.8125, -0.3691,  ..., -3.4844, -8.0000, -2.8594],\n",
      "         [-3.7812, -2.7656,  4.0000,  ..., -1.4297, -2.8125, -0.3926],\n",
      "         ...,\n",
      "         [-3.4688, -3.0625,  8.3125,  ...,  0.2559, -2.6875, -2.8125],\n",
      "         [-3.0000, -3.0938,  8.7500,  ...,  0.0806, -2.5156, -2.7656],\n",
      "         [-2.6562, -1.6953,  7.7812,  ..., -0.6484, -3.1562, -2.5000]]],\n",
      "       device='cuda:0', dtype=torch.float32, grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_ids_masked = torch.zeros(input_prompt_padded_tokenized.input_ids.shape, dtype=torch.int64).to('cuda')\n",
    "torch.where(input_prompt_padded_tokenized.input_ids == tokenizer.pad_token_id,\n",
    "            torch.tensor(-100, dtype=torch.int64),\n",
    "            input_prompt_padded_tokenized.input_ids,\n",
    "            out=input_ids_masked)\n",
    "\n",
    "loss1 = model(\n",
    "    input_prompt_tokenized.input_ids,\n",
    "    attention_mask=input_prompt_tokenized.attention_mask,\n",
    "    labels=input_prompt_tokenized.input_ids\n",
    ").loss\n",
    "\n",
    "logits1 = model(\n",
    "    input_prompt_tokenized.input_ids,\n",
    "    attention_mask=input_prompt_tokenized.attention_mask,\n",
    "    labels=input_prompt_tokenized.input_ids\n",
    ").logits\n",
    "\n",
    "print(f\"Normal Model + Non-Padded Input\")\n",
    "print(f\"Loss (no padding): {loss1}\")\n",
    "print(f\"Logits (no padding): {logits1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flash Attn Model + Non-Padded Input\n",
      "Loss (no padding) with flash attn: 2.8371522426605225\n",
      "Logits (no padding) with flash attn: tensor([[[ 0.1357, -0.1206,  0.3125,  ...,  1.3594,  1.8984,  0.6641],\n",
      "         [-8.4375, -9.8750, -0.3555,  ..., -3.5000, -8.0625, -2.9062],\n",
      "         [-3.7812, -2.7812,  4.0625,  ..., -1.3828, -2.7969, -0.3438],\n",
      "         ...,\n",
      "         [-3.4844, -3.0781,  8.3750,  ...,  0.2871, -2.6719, -2.8125],\n",
      "         [-3.0625, -3.1250,  8.6875,  ...,  0.0928, -2.5781, -2.7812],\n",
      "         [-2.6562, -1.6719,  7.7812,  ..., -0.6914, -3.1406, -2.5156]]],\n",
      "       device='cuda:0', dtype=torch.float32, grad_fn=<ToCopyBackward0>)\n",
      "Loss (no padding) with flash attn: 8.834760665893555\n"
     ]
    }
   ],
   "source": [
    "loss1_falsh_attn = flash_attn_model(\n",
    "    input_prompt_tokenized.input_ids,\n",
    "    attention_mask=input_prompt_tokenized.attention_mask,\n",
    "    labels=input_prompt_tokenized.input_ids\n",
    ").loss\n",
    "\n",
    "logits1_falsh_attn = flash_attn_model(\n",
    "    input_prompt_tokenized.input_ids,\n",
    "    attention_mask=input_prompt_tokenized.attention_mask,\n",
    "    labels=input_prompt_tokenized.input_ids\n",
    ").logits\n",
    "\n",
    "loss_random = model(\n",
    "    random_tokenized.input_ids,\n",
    "    attention_mask=random_tokenized.attention_mask,\n",
    "    labels=random_tokenized.input_ids\n",
    ").loss\n",
    "\n",
    "print(f\"Flash Attn Model + Non-Padded Input\")\n",
    "print(f\"Loss (no padding) with flash attn: {loss1_falsh_attn}\")\n",
    "print(f\"Logits (no padding) with flash attn: {logits1_falsh_attn}\")\n",
    "print(f\"Loss (no padding) with flash attn: {loss_random + loss1_falsh_attn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 32000])\n",
      "Unterscheidung'm been a bitely little of coconuts\n",
      "o do do doo<s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>'''\n",
      "Normal Model + Padded Input\n",
      "Loss (padding): 8.399846076965332\n",
      "Logits (padding): tensor([[[ 0.1357, -0.1206,  0.3125,  ...,  1.3594,  1.8984,  0.6641],\n",
      "         [-8.3750, -9.8125, -0.3691,  ..., -3.4844, -8.0000, -2.8594],\n",
      "         [-3.7812, -2.7656,  4.0000,  ..., -1.4297, -2.8125, -0.3926],\n",
      "         ...,\n",
      "         [-4.9062,  8.0000,  5.2500,  ..., -2.2812, -2.2812, -2.7344],\n",
      "         [-5.4062,  3.4219,  5.3125,  ..., -2.6094, -1.1250, -3.4062],\n",
      "         [-5.3125,  2.5312,  5.9375,  ..., -2.2656, -0.9961, -3.6719]]],\n",
      "       device='cuda:0', dtype=torch.float32, grad_fn=<ToCopyBackward0>)\n",
      "Decoded Logits (padding): []\n"
     ]
    }
   ],
   "source": [
    "loss2 = model(\n",
    "    input_prompt_padded_tokenized.input_ids,\n",
    "    attention_mask=input_prompt_padded_tokenized.attention_mask,\n",
    "    labels=input_prompt_padded_tokenized.input_ids\n",
    ").loss\n",
    "\n",
    "logits2 = model(\n",
    "    input_prompt_padded_tokenized.input_ids,\n",
    "    attention_mask=input_prompt_padded_tokenized.attention_mask,\n",
    "    labels=input_prompt_padded_tokenized.input_ids\n",
    ").logits\n",
    "\n",
    "print(logits2.shape)\n",
    "# decode the logits\n",
    "print(tokenizer.decode(logits2.argmax(dim=-1)[0]))\n",
    "\n",
    "print(f\"Normal Model + Padded Input\")\n",
    "print(f\"Loss (padding): {loss2}\")\n",
    "print(f\"Logits (padding): {logits2}\")\n",
    "print(f\"Decoded Logits (padding): {decoded_logits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unterscheidung'm been a bitely little of coconuts\n",
      "o do do doo<s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n",
      "Flash Attn Model + Padded Input\n",
      "Loss (padding) with flash attn: 16.86910057067871\n",
      "Logits (padding) with flash attn: tensor([[[ 0.1357, -0.1206,  0.3125,  ...,  1.3594,  1.8984,  0.6641],\n",
      "         [-8.4375, -9.8750, -0.3555,  ..., -3.5000, -8.0625, -2.9062],\n",
      "         [-3.7812, -2.7812,  4.0625,  ..., -1.3828, -2.7969, -0.3438],\n",
      "         ...,\n",
      "         [ 8.5000, 27.0000,  2.2188,  ...,  4.2188,  1.9766,  3.6250],\n",
      "         [ 8.5000, 27.0000,  2.2188,  ...,  4.2188,  1.9766,  3.6250],\n",
      "         [ 8.5000, 27.0000,  2.2188,  ...,  4.2188,  1.9766,  3.6250]]],\n",
      "       device='cuda:0', dtype=torch.float32, grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss2_falsh_attn = flash_attn_model(\n",
    "    input_prompt_padded_tokenized.input_ids,\n",
    "    attention_mask=input_prompt_padded_tokenized.attention_mask,\n",
    "    labels=input_prompt_padded_tokenized.input_ids\n",
    ").loss\n",
    "\n",
    "logits2_falsh_attn = flash_attn_model(\n",
    "    input_prompt_padded_tokenized.input_ids,\n",
    "    attention_mask=input_prompt_padded_tokenized.attention_mask,\n",
    "    labels=input_prompt_padded_tokenized.input_ids\n",
    ").logits\n",
    "\n",
    "print(tokenizer.decode(logits2_falsh_attn.argmax(dim=-1)[0]))\n",
    "\n",
    "print(f\"Flash Attn Model + Padded Input\")\n",
    "print(f\"Loss (padding) with flash attn: {loss2_falsh_attn}\")\n",
    "print(f\"Logits (padding) with flash attn: {logits2_falsh_attn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Logits\n",
      "------------------\n",
      "Unterscheidung'm been a bitely little of coconuts\n",
      "o do do doo<s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>''''\n",
      "------------------\n",
      "\n",
      "Normal Model + Padded Input\n",
      "Loss (with padding): 7.247009754180908\n",
      "Logits (with padding): tensor([[ 0.0608, -0.1953,  0.3203,  ...,  1.3281,  1.8359,  0.6094],\n",
      "        [-8.3750, -9.8125, -0.3574,  ..., -3.5000, -8.0625, -2.8750],\n",
      "        [-3.8281, -2.8281,  4.0000,  ..., -1.4375, -2.8438, -0.4102],\n",
      "        ...,\n",
      "        [-5.3438,  3.5625,  5.4062,  ..., -2.5781, -1.0469, -3.3594],\n",
      "        [-5.3750,  2.4375,  5.8438,  ..., -2.2969, -1.0547, -3.7031],\n",
      "        [-5.1250,  3.9844,  5.8750,  ..., -1.9766, -0.9297, -3.1250]],\n",
      "       device='cuda:0', dtype=torch.float32, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss2 = model(\n",
    "    batched_input_prompt_tokenized.input_ids,\n",
    "    attention_mask=batched_input_prompt_tokenized.attention_mask,\n",
    "    labels=batched_input_prompt_tokenized.input_ids\n",
    ").loss\n",
    "\n",
    "logits2 = model(\n",
    "    batched_input_prompt_tokenized.input_ids,\n",
    "    attention_mask=batched_input_prompt_tokenized.attention_mask,\n",
    "    labels=batched_input_prompt_tokenized.input_ids\n",
    ").logits\n",
    "\n",
    "print('Decoded Logits')\n",
    "print('------------------')\n",
    "print(tokenizer.decode(logits2.argmax(dim=-1)[0]))\n",
    "print('------------------\\n')\n",
    "\n",
    "print(f\"Normal Model + Padded Input\")\n",
    "print(f\"Loss (with padding): {loss2}\")\n",
    "print(f\"Logits (with padding): {logits2[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Logits\n",
      "------------------\n",
      "Unterscheidung'm been a bitely little of coconuts\n",
      "o do do doo<s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n",
      "------------------\n",
      "\n",
      "Flash Attn Model + Padded Input\n",
      "Loss (padding input & masking labels): 11.508078575134277\n",
      "Logits (padding input & masking labels): tensor([[ 0.0608, -0.1953,  0.3203,  ...,  1.3281,  1.8359,  0.6094],\n",
      "        [-8.4375, -9.8750, -0.3477,  ..., -3.5312, -8.0625, -2.8906],\n",
      "        [-3.7656, -2.8125,  4.0625,  ..., -1.3672, -2.7812, -0.3457],\n",
      "        ...,\n",
      "        [ 8.5000, 27.0000,  2.2344,  ...,  4.2500,  2.0000,  3.6562],\n",
      "        [ 8.5000, 27.0000,  2.2344,  ...,  4.2500,  2.0000,  3.6562],\n",
      "        [ 8.5000, 27.0000,  2.2344,  ...,  4.2500,  2.0000,  3.6562]],\n",
      "       device='cuda:0', dtype=torch.float32, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "flash_attn_loss = flash_attn_model(\n",
    "    batched_input_prompt_tokenized.input_ids,\n",
    "    attention_mask=batched_input_prompt_tokenized.attention_mask,\n",
    "    labels=batched_input_prompt_tokenized.input_ids\n",
    ").loss\n",
    "\n",
    "flash_attn_logits = flash_attn_model(\n",
    "    batched_input_prompt_tokenized.input_ids,\n",
    "    attention_mask=batched_input_prompt_tokenized.attention_mask,\n",
    "    labels=batched_input_prompt_tokenized.input_ids\n",
    ").logits\n",
    "\n",
    "print('Decoded Logits')\n",
    "print('------------------')\n",
    "print(tokenizer.decode(flash_attn_logits.argmax(dim=-1)[0]))\n",
    "print('------------------\\n')\n",
    "\n",
    "print(f\"Flash Attn Model + Padded Input\")\n",
    "print(f\"Loss (padding input & masking labels): {flash_attn_loss}\")\n",
    "print(f\"Logits (padding input & masking labels): {flash_attn_logits[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 0, 3, 0],\n",
      "        [1, 0, 3, 3],\n",
      "        [0, 3, 2, 0]]) tensor([[3, 4, 2, 0],\n",
      "        [3, 4, 2, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(0, 5, (3, 4))\n",
    "b = torch.randint(0, 5, (2, 4))\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a and b to dtype=torch.float32\n",
    "a = a.float()\n",
    "b = b.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = torch.tensor([[0, 4, 3, 1]])\n",
    "b1 = b1.float()\n",
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.7500, -1.2500]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((a[:, None, :] - b1) * (a[:, None, :]), dim=2).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2., 0., 3., 0.]],\n",
      "\n",
      "        [[1., 0., 3., 3.]],\n",
      "\n",
      "        [[0., 3., 2., 0.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2500,  2.5000, -0.7500],\n",
       "        [ 0.2500, -0.5000, -0.7500]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a[:, None, :])\n",
    "torch.mean((a[:, None, :] - b) * (a[:, None, :]), dim=2).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0217, 0.4867, 0.4916]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_example = [[4.46, 7.57, 7.58]]\n",
    "# tensor_example = tensor_example\n",
    "tensor_example = torch.tensor(tensor_example)\n",
    "\n",
    "# plot the softmax output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# def plot_softmax(tensor_example, knn_T=10):\n",
    "#     tensor_example = tensor_example / knn_T\n",
    "#     softmax = torch.nn.Softmax(dim=1)\n",
    "#     softmax_output = softmax(tensor_example)\n",
    "#     print(softmax_output)\n",
    "#     plt.plot(softmax_output.detach().numpy().flatten(), 'o')\n",
    "#     # shot the x axis as discrete values\n",
    "#     plt.xticks(np.arange(16))\n",
    "#     # plot the y from 0 to 1\n",
    "#     plt.ylim(0, 1)\n",
    "#     plt.show()\n",
    "\n",
    "# plot_softmax(tensor_example, 100)\n",
    "torch.softmax(tensor_example, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3967], 'attention_mask': [1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "tokenizer(\" positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /root/miniconda3/envs/robust/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/robust/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: /root/miniconda3/envs/robust did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/root/miniconda3/envs/robust/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/root/miniconda3/envs/robust/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/root/miniconda3/envs/robust/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:147: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Choose sentiment from terrible or great.\n",
    "\n",
    "Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris.\n",
    "Sentiment: terrible\n",
    "Review:  suspenseful enough for older kids but not . \n",
    "Sentiment: great\n",
    "\n",
    "Review: the subtle strength of elling is that it never squandering touch with the reality of the grim situation . \n",
    "Sentiment:\n",
    "'''\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\", torch_dtype=torch.bfloat16, use_flash_attention_2=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_flash_attention_2=True, load_in_8bit=True)\n",
    "# gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "# gpt_model = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\").to('cuda')\n",
    "\n",
    "# mistral_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "# mistral_model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.truncation_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "gpt_model = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm  # for notebooks\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df = pd.read_csv(\"../checkpoints/rte/meta-llama/Llama-2-7b-hf/swap_labels/icl_attack-seed-1-shot-8_quantized_bound/swap_labels_log.csv\")\n",
    "\n",
    "\n",
    "def get_demo_and_question(text):\n",
    "    demons = text.split(\"<SPLIT>\")\n",
    "    demons = [demon.split(\":\")[1].strip('\\n ').strip('[]') for demon in demons]\n",
    "\n",
    "    question = (demons[0], demons[1], \"\")\n",
    "    icl_examples = []\n",
    "    demons = demons[2:]\n",
    "    for i in range(len(demons) // 3):\n",
    "        icl_examples.append((demons[i * 3], demons[i * 3 + 1], demons[i * 3 + 2]))\n",
    "    return question, icl_examples\n",
    "\n",
    "def get_prompt(text):\n",
    "    question, icl_examples = get_demo_and_question(text)\n",
    "    template = \"{}\\n The question is: {}. True or False?\\nThe Answer is: {}\"\n",
    "    verbalizer = {0: \"true\", 1: \"false\"}\n",
    "\n",
    "    demos = []\n",
    "    for demo in icl_examples:\n",
    "        demos.append(template.format(demo[0], demo[1], demo[2]))\n",
    "    q = template.format(question[0], question[1], \"\").strip()\n",
    "\n",
    "    prompt = \"\\n\\n\".join(demos) + \"\\n\\n\" + q\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:00<00:00, 15759.08it/s]\n",
      "  0%|          | 0/277 [00:00<?, ?it/s]2023-10-27 11:15:30.174692: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-27 11:15:30.893151: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "100%|██████████| 277/277 [01:01<00:00,  4.47it/s]\n",
      "100%|██████████| 277/277 [00:59<00:00,  4.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "attacked_answer\n",
       " 1    119\n",
       " 0     80\n",
       "-1     78\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_non_modifable(row):\n",
    "    original = row['original_text']\n",
    "    modified = row['perturbed_text']\n",
    "    ori_q, ori_icl_examples = get_demo_and_question(original)\n",
    "    mod_q, mod_icl_examples = get_demo_and_question(modified)\n",
    "\n",
    "    return (all([(e[0] == ae[0]) and (e[1] == ae[1]) for e, ae in zip(ori_icl_examples, mod_icl_examples)])) and (ori_q == mod_q)\n",
    "\n",
    "def compute_distributions(question, icl_examples):\n",
    "    template = \"{}\\n The question is: {}. True or False?\\nThe Answer is: {}\"\n",
    "    verbalizer = {0: \"true\", 1: \"false\"}\n",
    "    label_id = [tokenizer.encode(verbalizer[0])[1], tokenizer.encode(verbalizer[1])[1]]\n",
    "\n",
    "    demos = []\n",
    "    for demo in icl_examples:\n",
    "        demos.append(template.format(demo[0], demo[1], demo[2]))\n",
    "    q = template.format(question[0], question[1], \"\").strip()\n",
    "\n",
    "    prompt = \"\\n\\n\".join(demos) + \"\\n\\n\" + q\n",
    "\n",
    "    # print(prompt)\n",
    "    tokenized = tokenizer(prompt, return_tensors=\"pt\", padding=True).to('cuda')\n",
    "    logits = model(**tokenized).logits\n",
    "    output = logits[:, -1, :].detach().cpu()\n",
    "\n",
    "    output_label = output[:, label_id].softmax(dim=-1)\n",
    "    return output_label.argmax(dim=-1).item()\n",
    "\n",
    "def compute_the_attacked_answer(row):\n",
    "    if row['result_type'] == 'Skipped':\n",
    "        return -1\n",
    "    \n",
    "    original = row['original_text']\n",
    "    modified = row['perturbed_text']\n",
    "    # ori_q, ori_icl_examples = get_demo_and_question(original)\n",
    "    mod_q, mod_icl_examples = get_demo_and_question(modified)\n",
    "\n",
    "    return compute_distributions(mod_q, mod_icl_examples)\n",
    "\n",
    "def compute_original_answer(row):\n",
    "    if row['result_type'] == 'Skipped':\n",
    "        return -1\n",
    "    \n",
    "    original = row['original_text']\n",
    "    modified = row['perturbed_text']\n",
    "    ori_q, ori_icl_examples = get_demo_and_question(original)\n",
    "    # mod_q, mod_icl_examples = get_demo_and_question(modified)\n",
    "\n",
    "    return compute_distributions(ori_q, ori_icl_examples)\n",
    "\n",
    "df['non_modifiable'] = df.progress_apply(compare_non_modifable, axis=1)\n",
    "df['attacked_answer'] = df.progress_apply(compute_the_attacked_answer, axis=1)\n",
    "df['original_answer'] = df.progress_apply(compute_original_answer, axis=1)\n",
    "\n",
    "df['attacked_answer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:00<00:00,  4.58it/s]\n"
     ]
    }
   ],
   "source": [
    "def random_flip(icl_examples, percentage):\n",
    "    np.random.seed(1)\n",
    "    idx = np.random.choice(len(icl_examples), int(len(icl_examples) * percentage), replace=False)\n",
    "    for i in idx:\n",
    "        icl_examples[i] = (icl_examples[i][0], icl_examples[i][1], 'false' if icl_examples[i][2] == 'true' else 'true')\n",
    "\n",
    "    return icl_examples\n",
    "\n",
    "def compute_random_flip_original_answer(row):\n",
    "    if row['result_type'] == 'Skipped':\n",
    "        return -1\n",
    "    \n",
    "    original = row['original_text']\n",
    "    ori_q, ori_icl_examples = get_demo_and_question(original)\n",
    "    ori_icl_examples = random_flip(ori_icl_examples, 0.5)\n",
    "    # mod_q, mod_icl_examples = get_demo_and_question(modified)\n",
    "\n",
    "    return compute_distributions(ori_q, ori_icl_examples)\n",
    "\n",
    "df['random_flip_original_answer'] = df.progress_apply(compute_random_flip_original_answer, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy\n",
      "correct\n",
      "True     192\n",
      "False     85\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attack Accuracy\n",
      "attack_correct\n",
      "False    212\n",
      "True      65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Random Flip Accuracy\n",
      "random_flip_correct\n",
      "True     175\n",
      "False    102\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['correct'] = df['original_answer'] == df['ground_truth_output']\n",
    "df['attack_correct'] = df['attacked_answer'] == df['ground_truth_output']\n",
    "df['random_flip_correct'] = df['random_flip_original_answer'] == df['ground_truth_output']\n",
    "\n",
    "print('Original Accuracy')\n",
    "print(df['correct'].value_counts())\n",
    "print('\\nAttack Accuracy')\n",
    "print(df['attack_correct'].value_counts())\n",
    "print('\\nRandom Flip Accuracy')\n",
    "print(df['random_flip_correct'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHDCAYAAAATEUquAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAACET0lEQVR4nO3de1xUdfoH8M8Aw0Xxwh0zFO+XvIuallmbSmb+sqzMrUDbLDHcNmort9TKTMty3VKh8tbF0i2tdTO8YVarpileC1FJw1TueAEFBji/PybmODAIBw7Md77n83695rXLzHxnzkM+z5kPZ+aMSVEUBURERERERFQtN2dvABERERERkegYnIiIiIiIiGrA4ERERERERFQDBiciIiIiIqIaMDgRERERERHVgMGJiIiIiIioBgxORERERERENWBwIiIiIiIiqgGDExERERERUQ0YnIiIiIiIiGrA4ERERI1uyZIlMJlMGDRokLM3hYiIqFZMiqIozt4IIiIylptuuglnz57FqVOncPz4cXTs2NHZm0RERHRNPOJERESN6uTJk9i5cycWLFiAoKAgrFq1ytmb5FBhYaGzN4GIiATC4ERERI1q1apV8PPzw+jRo3Hfffc5DE7nz5/H008/jfDwcHh5eeH6669HVFQUcnJybPcpKirCyy+/jM6dO8Pb2xutWrXCvffei7S0NADA9u3bYTKZsH37drvHPnXqFEwmE1auXGm7buLEifD19UVaWhruvPNONGvWDA899BAA4IcffsD999+PNm3awMvLC2FhYXj66adx5cqVKtt99OhRPPDAAwgKCoKPjw+6dOmCF198EQDw7bffwmQy4csvv6yy7tNPP4XJZMKuXbs0/z6JiKhxeDh7A4iIyFhWrVqFe++9F56enpgwYQLi4+Px008/YcCAAQCAgoICDB06FCkpKXj00UfRr18/5OTkYP369fj9998RGBiIsrIy3HXXXUhKSsKDDz6Ip556CpcuXcKWLVtw5MgRdOjQQfN2lZaWIjIyEjfffDPeeustNGnSBADw+eef4/Lly4iJiUFAQAD27NmDd999F7///js+//xz2/pDhw5h6NChMJvNePzxxxEeHo60tDT897//xZw5c3DrrbciLCwMq1atwj333FPld9KhQwcMHjy4Hr9ZIiJqSAxORETUaPbt24ejR4/i3XffBQDcfPPNuP7667Fq1SpbcJo/fz6OHDmCdevW2QWMl156CRUfy/3oo4+QlJSEBQsW4Omnn7bd54UXXkBdP7pbXFyM+++/H3PnzrW7/o033oCPj4/t58cffxwdO3bEP/7xD6Snp6NNmzYAgGnTpkFRFCQnJ9uuA4B58+YBAEwmEx5++GEsWLAAFy5cQIsWLQAA2dnZ2Lx5s+3IFBERiYlv1SMiokazatUqhISE4LbbbgNgDRPjx4/H6tWrUVZWBgBYu3YtevfuXeWoTMX9K+4TGBiIadOmVXufuoiJialy3dWhqbCwEDk5ORgyZAgURcH+/fsBWMPP999/j0cffdQuNFXenqioKBQXF+OLL76wXbdmzRqUlpbi4YcfrvN2ExFRw2NwIiKiRlFWVobVq1fjtttuw8mTJ3HixAmcOHECgwYNQmZmJpKSkgAAaWlp6NGjxzUfKy0tDV26dIGHh35vnPDw8MD1119f5fr09HRMnDgR/v7+8PX1RVBQEIYNGwYAuHDhAgDg119/BYAat7tr164YMGCA3ee6Vq1ahRtvvJFnFiQiEhzfqkdERI1i27ZtOHfuHFavXo3Vq1dXuX3VqlUYOXKkbs9X3ZGniiNblXl5ecHNza3KfUeMGIG8vDw8//zz6Nq1K5o2bYozZ85g4sSJKC8v17xdUVFReOqpp/D777+juLgYP/74IxYtWqT5cYiIqHExOBERUaNYtWoVgoODsXjx4iq3rVu3Dl9++SUSEhLQoUMHHDly5JqP1aFDB+zevRsWiwVms9nhffz8/ABYz9B3td9++63W23z48GEcO3YMH374IaKiomzXb9myxe5+7du3B4AatxsAHnzwQcTFxeGzzz7DlStXYDabMX78+FpvExEROQffqkdERA3uypUrWLduHe666y7cd999VS6xsbG4dOkS1q9fj3HjxuHgwYMOT9tdceKHcePGIScnx+GRmor7tG3bFu7u7vj+++/tbl+yZEmtt9vd3d3uMSv+/7/+9S+7+wUFBeGWW27B8uXLkZ6e7nB7KgQGBmLUqFH45JNPsGrVKtxxxx0IDAys9TYREZFz8IgTERE1uPXr1+PSpUv4v//7P4e333jjjbYvw/3000/xxRdf4P7778ejjz6K/v37Iy8vD+vXr0dCQgJ69+6NqKgofPTRR4iLi8OePXswdOhQFBYWYuvWrZg6dSruvvtutGjRAvfffz/effddmEwmdOjQAV9//TWysrJqvd1du3ZFhw4d8Oyzz+LMmTNo3rw51q5di/z8/Cr3feedd3DzzTejX79+ePzxx9GuXTucOnUKGzZswIEDB+zuGxUVhfvuuw8AMHv27Nr/IomIyGkYnIiIqMGtWrUK3t7eGDFihMPb3dzcMHr0aKxatQrFxcX44YcfMGvWLHz55Zf48MMPERwcjNtvv9128gZ3d3d88803mDNnDj799FOsXbsWAQEBuPnmm9GzZ0/b47777ruwWCxISEiAl5cXHnjgAcyfP7/GkzhUMJvN+O9//4u//vWvmDt3Lry9vXHPPfcgNjYWvXv3trtv79698eOPP2LGjBmIj49HUVER2rZtiwceeKDK444ZMwZ+fn4oLy+vNkwSEZFYTEpdv/CCiIiI6qS0tBTXXXcdxowZg2XLljl7c4iIqBb4GSciIqJG9tVXXyE7O9vuhBNERCQ2HnEiIiJqJLt378ahQ4cwe/ZsBAYGIjk52dmbREREtcQjTkRERI0kPj4eMTExCA4OxkcffeTszSEiIg14xImIiIiIiKgGPOJERERERERUA6cHp8WLFyM8PBze3t4YNGgQ9uzZc837L1y4EF26dIGPjw/CwsLw9NNPo6ioqJG2loiIiIiIjMip3+O0Zs0axMXFISEhAYMGDcLChQsRGRmJ1NRUBAcHV7n/p59+ihdeeAHLly/HkCFDcOzYMUycOBEmkwkLFiyo1XOWl5fj7NmzaNasGUwmk94lERERERGRi1AUBZcuXcJ1110HN7drH1Ny6mecBg0ahAEDBmDRokUArKEmLCwM06ZNwwsvvFDl/rGxsUhJSUFSUpLtumeeeQa7d+/G//73v1o95++//46wsDB9CiAiIiIiIpd3+vRp25esV8dpR5xKSkqwb98+TJ8+3Xadm5sbhg8fjl27djlcM2TIEHzyySfYs2cPBg4ciF9//RXffPMNHnnkkWqfp7i4GMXFxbafK3Li6dOn0bx5c52qISIiIiIiV3Px4kWEhYWhWbNmNd7XacEpJycHZWVlCAkJsbs+JCQER48edbjmz3/+M3JycnDzzTdDURSUlpZiypQp+Mc//lHt88ydOxevvPJKleubN2/O4ERERERERLX6CI/TTw6hxfbt2/H6669jyZIlSE5Oxrp167BhwwbMnj272jXTp0/HhQsXbJfTp0834hYTEREREZEMnHbEKTAwEO7u7sjMzLS7PjMzE6GhoQ7XzJgxA4888ggee+wxAEDPnj1RWFiIxx9/HC+++KLDD3R5eXnBy8tL/wKIiIiIiMgwnHbEydPTE/3797c70UN5eTmSkpIwePBgh2suX75cJRy5u7sDUD+7REREREREpDenno48Li4O0dHRiIiIwMCBA7Fw4UIUFhZi0qRJAICoqCi0bt0ac+fOBQCMGTMGCxYsQN++fTFo0CCcOHECM2bMwJgxY2wBioiIiIioIZWVlcFisTh7M6iWPD09azzVeG04NTiNHz8e2dnZmDlzJjIyMtCnTx9s3LjRdsKI9PR0uyJfeuklmEwmvPTSSzhz5gyCgoIwZswYzJkzx1klEBEREZFBKIqCjIwMnD9/3tmbQhq4ubmhXbt28PT0rNfjOPV7nJzh4sWLaNGiBS5cuMCz6hERERFRrZ07dw7nz59HcHAwmjRpUqszsZFzlZeX4+zZszCbzWjTpk2V/2ZasoFTjzgREREREbmCsrIyW2gKCAhw9uaQBkFBQTh79ixKS0thNpvr/DgudTpyIiIiIiJnqPhMU5MmTZy8JaRVxVv0ysrK6vU4DE5ERERERLXEt+e5Hr3+mzE4ERERERER1YCfcSIiIiIiqqP09HTk5OQ02vMFBgaiTZs2jfZ8pGJwIiIiIiKqg/T0dHTp2g1FVy432nN6+zRB6tEUzeEpIyMDc+bMwYYNG3DmzBkEBwejT58++Nvf/obbb7+9gba2blauXIm//e1vwp32ncGJiIiIiKgOcnJyUHTlMgLuegbmgLAa72/J/g25m+Nh9guF/4gpMJm9NT2fJfc0cr9+Gzk5OZqC06lTp3DTTTehZcuWmD9/Pnr27AmLxYJNmzbhySefxNGjRzVtBwCUlJQ4/F4ki8VSrzPXiYyfcSIiIiIiqgdzQBi8Qjte84LyMuRtfQ9eIe0Q+tCb8A7rUeOaypfiM7/UafumTp0Kk8mEPXv2YNy4cejcuTNuuOEGxMXF4ccffwRgPXp29913w9fXF82bN8cDDzyAzMxM22O8/PLL6NOnD5YuXYp27drB29sa+kwmE+Lj4/F///d/aNq0KebMmQMA+M9//oN+/frB29sb7du3xyuvvILS0lLb450/fx5PPPEEQkJC4O3tjR49euDrr7/G9u3bMWnSJFy4cAEmkwkmkwkvv/xyHf/L6ItHnIiIiIiIGlDx2VRkrpkBz6C2CL7/Fbh5aT+l+fmdq1GwP1Hzury8PGzcuBFz5sxB06ZNq9zesmVLlJeX20LTd999h9LSUjz55JMYP348tm/fbrvviRMnsHbtWqxbtw7u7u62619++WXMmzcPCxcuhIeHB3744QdERUXhnXfewdChQ5GWlobHH38cADBr1iyUl5dj1KhRuHTpEj755BN06NABv/zyC9zd3TFkyBAsXLgQM2fORGpqKgDA19dXc90NgcGJiIgMq7E/1G1k/EA7GZVeoenCD5/At+8ozeHpxIkTUBQFXbt2rfY+SUlJOHz4ME6ePImwMOtbDj/66CPccMMN+OmnnzBgwAAA1rfnffTRRwgKCrJb/+c//xmTJk2y/fzoo4/ihRdeQHR0NACgffv2mD17Np577jnMmjULW7duxZ49e5CSkoLOnTvb7lOhRYsWMJlMCA0N1VRrQ2NwIiIiQ0pPT0fXLp1xpajY2ZtiCE18vJFyNJXhiQxFz9DUYujD8GkfoTk4KYpS431SUlIQFhZmC00A0L17d7Rs2RIpKSm24NS2bdsqoQkAIiIi7H4+ePAgduzYYXvbHmD98tmioiJcvnwZBw4cwPXXX28LTa6CwYmIiAwpJycHV4qK8ck9PugWVPuP/BaWKIhNLEJaXjmWjPZGj2D3mhdVciSrDFM3FKGDvxsWjfJGU0/tX864NLkE8XstiIkw47F+VT+gXZPGrCMluxwPf3lF8wfaiVyZ3qGp5ZAHUZxxQvNjdOrUCSaTqU4ngKjM0Vv9HF1fUFCAV155Bffee2+V+3p7e8PHx6fe2+IMDE5ERGRo3YLc0K9V7ULDpWIFd6y6jFPny7EtuikGttYeNvacKcO0xCL0DnXHxoeaoJmX9tD02vfFiN9rwezbvPDSLV6a14tSB5GsGiI01ZW/vz8iIyOxePFi/PWvf60Scs6fP49u3brh9OnTOH36tO2o0y+//ILz58+je/fump+zX79+SE1NRceOHR3e3qtXL/z+++84duyYw6NOnp6eKCsr0/y8DY1n1SMiIqqFirBxJKsMWx6pe9gY8XEhegTXLzTN+La43qHJ2XUQyUqk0FRh8eLFKCsrw8CBA7F27VocP34cKSkpeOeddzB48GAMHz4cPXv2xEMPPYTk5GTs2bMHUVFRGDZsWJW34dXGzJkz8dFHH+GVV17Bzz//jJSUFKxevRovvfQSAGDYsGG45ZZbMG7cOGzZsgUnT55EYmIiNm7cCAAIDw9HQUEBkpKSkJOTg8uXG+97sq6FR5yIiIhqIErYYGgiEpMl97T1f6/6nqaWw6JhyT+r+bEKDm1Cwf5E+PYdBZ/2EXZvz6t4Hq3at2+P5ORkzJkzB8888wzOnTuHoKAg9O/fH/Hx8TCZTPjPf/6DadOm4ZZbboGbmxvuuOMOvPvuu3V6vsjISHz99dd49dVX8cYbb8BsNqNr16547LHHbPdZu3Ytnn32WUyYMAGFhYXo2LEj5s2bBwAYMmQIpkyZgvHjxyM3NxezZs0S4pTkJqU2nxiTyMWLF9GiRQtcuHABzZs3d/bmEBGRkyQnJ6N///7Y93jTa75VT5Sw4cqhKflcGfq/X4h9+/ahX79+mp+XSARFRUU4efKk3XcYpaeno0vXbii60nhHRLx9miD1aAo/L6iBo/92FbRkAx5xIiIiqgZDk4pHmoiqatOmDVKPpjTq1xrw1P7Ow+BERETkgChhg6GJSGxt2rRhkDEInhyCiIioElHChiyhaWlyieY1RESiYXAiIiK6iihhQ5bQVHHqdCIiV8fgRERE9AeRwoYsoWnGt8WIiTBrXktEJBoGJyIiIogXNmQJTbNv88Jj/Tw1ryciEg2DExERGZ6IYUOW0FSXOoiIRMTgREREhlZYIkfYYGgiImpYPB05EREZWmxiEU6dL3fpsMHQRETU8BiciIjI0NLyyrEt2nXDBkMTkXOlp6fzC3ANgsGJiIgMbclob5cNGwxNRM6Vnp6Obl274PKVokZ7ziY+3kg5mqopPE2cOBHnz5/HV1991XAb5iS33nor+vTpg4ULFzb4czE4ERGRofUIds2wwdBE5Hw5OTm4fKUIn9zjg25BVU8dsDS5BPF7LYiJMNfp7JKFJQpiE4uQlleOJaO94W4y4eEvryAnJ8eljjqVlJTA09O+/rKyMphMJri5uc4pF1xnS4mIiAQgQthgaCISS7cgN/Rr5W53+eZ4KeL3WjD7Ni8sGe1T5faaLp383fBCUjFOnbe+nTiqt6fDcKbVrbfeir/+9a947rnn4O/vj9DQULz88st29zl//jyeeOIJhISEwNvbGz169MDXX39tu33t2rW44YYb4OXlhfDwcLz99tt268PDwzF79mxERUWhefPmePzxx7Fy5Uq0bNkS69evR/fu3eHl5YX09HQUFxfj2WefRevWrdG0aVMMGjQI27dvt3u8HTt24NZbb0WTJk3g5+eHyMhI5OfnY+LEifjuu+/wr3/9CyaTCSaTCadOnar376g6DE5ERES1JELYYGgiEp8IfX4tH374IZo2bYrdu3fjzTffxKuvvootW7YAAMrLyzFq1Cjs2LEDn3zyCX755RfMmzcP7u7Wbdi3bx8eeOABPPjggzh8+DBefvllzJgxAytXrrR7jrfeegu9e/fG/v37MWPGDADA5cuX8cYbb2Dp0qX4+eefERwcjNjYWOzatQurV6/GoUOHcP/99+OOO+7A8ePHAQAHDhzA7bffju7du2PXrl343//+hzFjxqCsrAz/+te/MHjwYEyePBnnzp3DuXPnEBYWpuvv6mp8qx4REVEtiBA2GJqIxCdCn9ekV69emDVrFgCgU6dOWLRoEZKSkjBixAhs3boVe/bsQUpKCjp37gwAaN++vW3tggULcPvtt9vCUOfOnfHLL79g/vz5mDhxou1+f/rTn/DMM8/Yfv7hhx9gsViwZMkS9O7dG4D1M2IrVqxAeno6rrvuOgDAs88+i40bN2LFihV4/fXX8eabbyIiIgJLliyxPdYNN9xg+/+enp5o0qQJQkNDdf4tVcUjTkRERDUQIWwwNBGJT4Q+r41evXrZ/dyqVStkZWUBsB7huf76622hqbKUlBTcdNNNdtfddNNNOH78OMrKymzXRUREVFnr6elp99yHDx9GWVkZOnfuDF9fX9vlu+++Q1pamm17br/99roVqjMecSIiIroGEcIGQxOR+ETo89oym812P5tMJpSXlwMAfHx8dHmOpk2bVrnOx8cHJpM6ewoKCuDu7o59+/bZ3gpYwdfXV9ft0QOPOBEREVVDhLDB0EQkvqXJJU7vc7306tULv//+O44dO+bw9m7dumHHjh121+3YsQOdO3euEn5q0rdvX5SVlSErKwsdO3a0u1S89a5Xr15ISkqq9jE8PT3tjnQ1JAYnIiIiB0QIG7KEpsISRfMaIldScfY8Vw9NADBs2DDccsstGDduHLZs2YKTJ08iMTERGzduBAA888wzSEpKwuzZs3Hs2DF8+OGHWLRoEZ599lnNz9W5c2c89NBDiIqKwrp163Dy5Ens2bMHc+fOxYYNGwAA06dPx08//YSpU6fi0KFDOHr0KOLj421fOhweHo7du3fj1KlTyMnJsR05awh8qx4REVElIoQNWULTpWLr99AQyey+bh64s5MHks9pO/JR+XuaPNxwzcdIyW64UHC1tWvX4tlnn8WECRNQWFiIjh07Yt68eQCAfv364d///jdmzpyJ2bNno1WrVnj11VftTgyhxYoVK/Daa6/hmWeewZkzZxAYGIgbb7wRd911FwBruNq8eTP+8Y9/YODAgfDx8cGgQYMwYcIEANaTSURHR6N79+64cuUKTp48ifDwcD1+DVWYFEVx+p+BFi9ejPnz5yMjIwO9e/fGu+++i4EDBzq876233orvvvuuyvV33nmnLZley8WLF9GiRQtcuHABzZs3r/e2ExGRa0pOTkb//v2x7/Gm6NdKDSWihA1ZQtMdqy7jYEYZCi3W0xj369dP8+MQiaCoqAgnT55Eu3bt4O3tDcB6VriuXTrjSlFxo21HEx9vpBxNdakvwHU2R//tKmjJBk4/4rRmzRrExcUhISEBgwYNwsKFCxEZGYnU1FQEBwdXuf+6detQUlJi+zk3Nxe9e/fG/fff35ibTUREEhIpbMgSmo5klWHJaG9Ef8WjTiSfNm3a4GjqMdvbxhpDYGAgQ5OTOD04LViwAJMnT8akSZMAAAkJCdiwYQOWL1+OF154ocr9/f397X5evXo1mjRpwuBERET1IlrYkCU0bXmkKTz4iWqSWJs2bRhkDMKpo6ykpAT79u3D8OHDbde5ublh+PDh2LVrV60eY9myZXjwwQcdnvKQiIioNkQMG7KEJmd/0J2ISC9OPeKUk5ODsrIyhISE2F0fEhKCo0eP1rh+z549OHLkCJYtW1btfYqLi1FcrL7v9OLFi3XfYCIiks6RrDJMSyxy+bDB0ERE1LBc+uD5smXL0LNnz2pPJAEAc+fORYsWLWyXsLCwRtxCIiIS3dQNDE2AGHUQEYnMqcEpMDAQ7u7uyMzMtLs+MzPT9qVX1SksLMTq1avxl7/85Zr3mz59Oi5cuGC7nD59ut7bTURE8ujg7+bSYYOhiahxNeT3BFHD0Osk4k59q56npyf69++PpKQkjB07FoD1H2NSUhJiY2Ovufbzzz9HcXExHn744Wvez8vLC15eYn/DeXp6eqOejcXIeCYaIqps0Shvlw0bDE1EjcfT0xNubm44e/YsgoKC4OnpCZNJe89R41IUBdnZ2TCZTDCbzfV6LKefVS8uLg7R0dGIiIjAwIEDsXDhQhQWFtrOshcVFYXWrVtj7ty5duuWLVuGsWPHIiAgwBmbrZv09HR06twZJcWNd/5/I/P2aYLUoykMT0Rk09TTNcMGQxNR43Jzc0O7du1w7tw5nD171tmbQxqYTCZcf/31cHev34xyenAaP348srOzMXPmTGRkZKBPnz7YuHGj7YQR6enpcHOzf0dhamoq/ve//2Hz5s3O2GRd5eTkoKS4GP53TINnSAfN6wsObULB/kT49h0F316RmtcrliLkbUmAJT8DASNjYA5qq/kxLNm/IXdzPMx+ofAfMQUms3fNiyppjDosuaeR+/XbyMnJYXAiojoTIWwwNBE5h6enJ9q0aYPS0lKUlZU5e3Oolsxmc71DEyBAcAKA2NjYat+at3379irXdenSRbf3KorCM6QDvEI7alpzfudqFOxPRIuhD6PlkAc1P2d58WVkfT4LpReyEDphDryu66L5MYrPpiJv63vwCmmH4PtfgZtXE82PIUIdRES1IULYYGgicq6Kt3zV921f5Hpc+qx6RnZ+52pc+OGTeoeNkuzfEDJ+dp1DU+aaGfAMaluv0OTsOoiIakOEsMHQRETkPAxOLkiEsMHQRERGIkLYYGgiInIuBicXI0LYYGgiIiMRIWwwNBEROR+DkwsRIWwwNBGRkYgQNhiaiIjEwODkIkQIGwxNRGQkIoQNWULTkSyefYyIXB+DkwsQIWwwNBGRkYgQNmQJTXvOlGHqhiLN64iIRMPgJDgRwoYsocmS/ZvmNURkPKKEDVlC04iPC9HBny83iMj1cZIJTISwIUtoKj6bitzN8ZrXEZGxiBQ2ZAlNPYLdsWiU9i9GJyISDYOToEQJG7KEpsw1M2D2C9W8loiMQ7SwIUto2vhQEzT11F4HEZFoGJwEJFLYkCU0eQa1hf+IKZrXE5ExiBg2ZAlNdamDiEhEHs7eALInWtiQJTQF3/8KLPlnNT8GEclvaXIJ4vdaXD5sMDQRETUsHnESiIhhQ5bQVJc6iMgYGJrEqYOISGQ84iSIgkObULA/0eXDBkMTEbmamAizS4cNhiYiosbBI06CYGgSpw4iMpbH+nlqXiNK2GBoIiJqPAxOgvDtO8qlwwZDExEZhShhg6GJiKhxMTgJwrdXpOY1ooQNhiYiMgpRwgZDExFR42NwclGihA2GJiIyClHCBkMTEZFzMDi5IFHCBkMTERmFKGGDoYmIyHkYnFyMKGGDoYmIjEKUsMHQRETkXAxOLkSUsMHQRERGIUrYYGgiInI+BicXIUrYYGgiIqMQJWwwNBERiYHByQWIEjYYmojIKEQJG7KEpqXJJZrXEBGJhsFJcKKEDYYmIjIKUcKGLKHpte+LEb/XonkdEZFoGJwEJkrYkCU0FRzapHkNERmLSGFDltA049tixESYNa8lIhINg5OgRAkbsoSm8ztXo2B/ouZ1RGQcooUNWULT7Nu88Fg/T83riYhEw+AkIJHChiyh6cIPn8C37yjNa4nIGEQMG7KEprrUQUQkIg9nbwDZEy1syBKaWgx9GD7tI3jUiYiqKCyRI2wwNMkpPT0dOTk5zt4MwwgMDESbNm2cvRkkKAYngYgYNmQJTS2HPIjijBOaH4OI5BebWIRT58tdOmwwNMkpPT0dnTp3QUlxkbM3xTC8fZog9WgKwxM5xOAkCMVSJGTY0ErU0EREVJ20vHJsi3bdsMHQJK+cnByUFBch4K5nYA4I07S24NAmFOxPhG/fUfDtFan5uRVLEfK2JMCSn4GAkTEwB7XV/BiW7N+QuzkeZr9Q+I+YApPZW/NjNGYdltzTyP36beTk5DA4kUMMToLI25KA0gtZLh02GJqIyBUtGe3tsmGDockYzAFh8ArtWOv7V5wQqb7789ILWQidMKfO+/O8re/BK6RdvU/s5Mw6iK7Gk0MIwpKf4dJhg6GJiFxVj2DXDBsMTeQI9+dWetRBVBmDkyACRsYYejiJUAcRUW2IEDYYmsgR7s+tGJqooTA4CaIu7x2WZTiJUAcRUW2IEDYYmsgR7s+tGJqoITE4uShZhpMIdRAR1YYIYYOhiRzh/tyKoYkaGoOTC5JlOIlQBxFRbYgQNhiayBHuz630qMOS/ZvmNWQsDE4uRpbhJEIdRES1IULYYGgiR7g/t9KrjtzN8ZrXkbEwOLkQmYaTs+sgIqoNEcIGQxM5wv25lZ51mP1CNa8lY3F6cFq8eDHCw8Ph7e2NQYMGYc+ePde8//nz5/Hkk0+iVatW8PLyQufOnfHNN9800tY6j2zDiaGJiEQnQtiQJTQVliia11D1uD+30rsO/xFTNK8nY3HqF+CuWbMGcXFxSEhIwKBBg7Bw4UJERkYiNTUVwcHBVe5fUlKCESNGIDg4GF988QVat26N3377DS1btmz8jW9EMg4nhiYiEpkIYUOW0HSpWEFsYpHmdeQY9+dWDVGHJf+s5scgY3FqcFqwYAEmT56MSZMmAQASEhKwYcMGLF++HC+88EKV+y9fvhx5eXnYuXMnzGYzACA8PLwxN7nRyTqcnFGHYuGOm4hqJkrYkCU03bHqMtLyyjWvpaq4P7cSpQ4yHqe9Va+kpAT79u3D8OHD1Y1xc8Pw4cOxa9cuh2vWr1+PwYMH48knn0RISAh69OiB119/HWVlZY212Y2Kw0mlRx15WxI0ryMiYxEpbMgSmo5klWHJaG/N68ke9+dWotRBxuS0I045OTkoKytDSEiI3fUhISE4evSowzW//vortm3bhoceegjffPMNTpw4galTp8JisWDWrFkO1xQXF6O4uNj288WLF/UrogFxOKn0qsOSn6F5LREZh2hhQ5bQtOWRpvBw+ieqXVvBoU0o2J/I/bkgdZBxudQoKy8vR3BwMN5//330798f48ePx4svvoiEhOqPJMydOxctWrSwXcLCwhpxi+uGw0mlZx0BI2M0ryciYxAxbMgSmupSB9ljaBKnDjI2pwWnwMBAuLu7IzMz0+76zMxMhIY6Ph1kq1at0LlzZ7i7q0O4W7duyMjIQElJicM106dPx4ULF2yX06dP61dEA+BwUuldhzmorebHICL5HcmSI2wwNMnLt+8o7s8FqIPIacHJ09MT/fv3R1JSku268vJyJCUlYfDgwQ7X3HTTTThx4gTKy9UPmR47dgytWrWCp6enwzVeXl5o3ry53UVUHE4qEeogImOYuqHI5cMGQ5PcfHtFal7D/bmKoYn04tS36sXFxeGDDz7Ahx9+iJSUFMTExKCwsNB2lr2oqChMnz7ddv+YmBjk5eXhqaeewrFjx7Bhwwa8/vrrePLJJ51Vgm4s2b9xOP1BhDqIyDg6+Lu5dNhgaKLKuD9XMTSRnpx6OvLx48cjOzsbM2fOREZGBvr06YONGzfaThiRnp4ONzc124WFhWHTpk14+umn0atXL7Ru3RpPPfUUnn/+eWeVoJvczfHwCmln+OEkQh1EZCyLRnm7bNhgaKLKuD9XMTSR3pwanAAgNjYWsbGxDm/bvn17lesGDx6MH3/8sYG3qvGZ/UINP5xEqIOIjKepp2uGDYYmqoz7cxVDEzUElzqrnsz8R0wx9HASoQ4iotoQIWwwNFFl3J+rGJqooTA4CcJk1v7lgLIMJxHqICKqDRHCBkMTVcb9uYqhiRoSg5OLkmU4iVAHEVFtiBA2GJqoMu7PVQxN1NAYnFyQLMNJhDqIiGpDhLDB0ESVcX+u0qOOgkObNK8hY2FwcjGyDCcR6iAiqg0RwgZDE1XG/blKrzoK9idqXkfGwuDkQmQaTs6ug4ioNkQIGwxNVBn35yo96/DtO0rzWjIWBicXIdtwYmgiItGJEDZkCU1Hsso0ryHHuD9X6V2Hb69IzevJWBicXICMw4mhiYhEJkLYkCU07TlThqkbijSvo6q4P1eJUAcZD4OT4DicrPSow5L9m+Y1RGQ8ooQNWULTiI8L0cGfLzfqi/tzlQh1kDFxkgmMw8lKrzpyN8drXkdExiJS2JAlNPUIdseiUdq/q5BUiqWI+/M/iFAHGReDk6A4nKz0rMPsF6p5LREZh2hhQ5bQtPGhJmjqqb0OUuVtSeD+HGLUQcbG4CQgDicrvevwHzFF83oiMgYRw4YsoakudZA9S34G9+cC1EHk4ewNIHscTlYNUYcl/6zmxyAi+S1NLkH8XovLhw2GJnkFjIzh/pyhiQTAI04C4XCyEqUOIjIGhiZx6iDHzEFtNa/h/lzF0ER64REnQRQc2oSC/YmGH06i1EFExhETYXbpsMHQRJVxf65iaCI98YiTIBiaxKmDiIzlsX6emteIEjYYmqgy7s9VDE2kNwYnQfj2HWXo4SRKHURENRElbDA0UWXcn6sYmqghMDgJwrdXpOY1sgwnUeogIqqJKGGDoYkq4/5cxdBEDYXByUXJMpxEqYOIqCaihA2GJqqM+3MVQxM1JAYnFyTLcBKlDiKimogSNhiaqDLuz1X1rUOxFGleQ8bC4ORiZBlOotRBRFQTUcIGQxNVxv25So868rYkaF5HxsLg5EJkGk4i1EFEVBNRwgZDE1XG/blKrzos+Rma15KxMDi5CNmGk7PrICKqiShhg6GJKuP+XKVnHQEjYzSvJ2PhF+C6ABmHE0MTEYlMlLAhS2hamlyieQ05xv25Su864Ka9P8hYeMRJcLIOJ4YmIhKVKGFDltD02vfFiN9r0byOquL+XCVCHWQ8DE4C43BS6VFHwaFNmtcQkbGIFDZkCU0zvi1GTIRZ81qyx/25SoQ6yJgYnATF4aTSq46C/Yma1xGRcYgWNmQJTbNv88Jj/Tw1ryeVJfs37s//IEIdZFwMTgLicFLpWYdv31Ga1xKRMYgYNmQJTXWpg+zlbo7n/hxi1EHGxuAkGA4nld51+PaK1LyeiORXWCJH2GBokpfZL5T7cwHqIGJwEgiHk0qEOojIGGITi1w+bDA0yc1/xBTuzxmaSAA8HbkgFEsRh9MfRKiDiIwjLa8c26JdN2wwNMnPZPbWvIb7cyuGJtITg5Mg8rYkoPRCluGHkwh1EJGxLBnt7bJhg6GJHOH+3IqhifTGt+oJwpKfYfjhJEIdRGQ8PYJdM2wwNJEj3J9bMTRRQ2BwEkTAyBhDDycR6iAiqg0RwgZDEznC/bkVQxM1FAYnQZiD2mpeI8twEqEOIqLaECFsMDSRI9yfWzE0UUNicHJRsgwnEeogIqoNEcIGQxM5wv25FUMTNTQGJxcky3ASoQ4iotoQIWwwNJEj3J9b6VGHJfs3zWvIWIQITosXL0Z4eDi8vb0xaNAg7Nmzp9r7rly5EiaTye7i7a39NJ2uSpbhJEIdRES1IULYYGgiR7g/t9KrjtzN8ZrXkbE4PTitWbMGcXFxmDVrFpKTk9G7d29ERkYiKyur2jXNmzfHuXPnbJfffjPGXwhkGk7OroOIqDZECBsMTeQI9+dWetZh9gvVvJaMxenBacGCBZg8eTImTZqE7t27IyEhAU2aNMHy5curXWMymRAaGmq7hISENOIWO4dsw4mhiYhEJ0LYkCU0FZYomtdQ9bg/t9K7Dv8RUzSvJ2NxanAqKSnBvn37MHz4cNt1bm5uGD58OHbt2lXtuoKCArRt2xZhYWG4++678fPPPzfG5jqNjMOJoYmIRCZC2JAlNF0qVhCbWKR5HTnG/blVQ9RhMhvnox9UN04NTjk5OSgrK6tyxCgkJAQZGRkO13Tp0gXLly/Hf/7zH3zyyScoLy/HkCFD8Pvvvzu8f3FxMS5evGh3cSWyDidn1KFYuOMmopqJEjZkCU13rLqMtLxyzWupKu7PrUSpg4zH6W/V02rw4MGIiopCnz59MGzYMKxbtw5BQUF47733HN5/7ty5aNGihe0SFhbWyFtcdxxOKj3qyNuSoHkdERmLSGFDltB0JKsMS0bzL/n1xf25lSh1kDE5NTgFBgbC3d0dmZmZdtdnZmYiNLR2H9Azm83o27cvTpw44fD26dOn48KFC7bL6dOn673djYHDSaVXHZZ8x0cxiYgA8cKGLKFpyyNN0SNYex2kKji0iftziFMHGZdTg5Onpyf69++PpKQk23Xl5eVISkrC4MGDa/UYZWVlOHz4MFq1auXwdi8vLzRv3tzuIjoOJ5WedQSMjNG8noiMQcSwIUtoqksdZK9gfyL354LUQcbm4ewNiIuLQ3R0NCIiIjBw4EAsXLgQhYWFmDRpEgAgKioKrVu3xty5cwEAr776Km688UZ07NgR58+fx/z58/Hbb7/hsccec2YZuuFwUuldB9y48yaiqo5klWFaYpHLhw2GJnn59h3F/bkAdRA5PTiNHz8e2dnZmDlzJjIyMtCnTx9s3LjRdsKI9PR0uLmpB8by8/MxefJkZGRkwM/PD/3798fOnTvRvXt3Z5WgGw4nVUPUUZzh+O2cRGRsUzcUoXeoa4cNhia5+faK1LxG5v25VgxNpBenBycAiI2NRWxsrMPbtm/fbvfzP//5T/zzn/9shK1qXJbs35C39T0OJ4hRBxEZRwd/N5cOGwxNVBn35yqGJtKTy51VT1a5m+M5nCBGHURkLItGebts2GBoosq4P1cxNJHeGJwEYfYLNfxwEqEOIjKepp6uGTYYmqgy7s9VDE3UEBicBOE/Yoqhh5MIdRAR1YYIYYOhiSrj/lzF0EQNhcFJECaz9i8HlGU4iVAHEVFtiBA2GJqoMu7PVQxN1JAYnFyULMNJhDqIiGpDhLDB0ESVcX+uYmiihsbg5IJkGU4i1EFEVBsihA2GJqqM+3OVHnUUHNqkeQ0ZC4OTi5FlOIlQBxFRbYgQNhiaqDLuz1V61VGwP1HzOjIWBicXItNwcnYdRES1IULYYGiiyrg/V+lZh2/fUZrXkrEwOLkI2YYTQxMRiU6EsCFLaDqSVaZ5DTnG/blK7zp8e0VqXk/GwuDkAmQcTgxNRCQyEcKGLKFpz5kyTN1QpHkdVcX9uUqEOsh4GJwEx+FkpUcdluzfNK8hIuMRJWzIEppGfFyIDv58uVFf3J+rRKiDjImTTGAcTlZ61ZG7OV7zOiIyFpHChiyhqUewOxaN0v5dhaRSLEXcn/9BhDrIuBicBMXhZKVnHWa/UM1ricg4RAsbsoSmjQ81QVNP7XWQKm9LAvfnEKMOMjYGJwFxOFnpXYf/iCma1xORMYgYNmQJTXWpg+xZ8jO4PxegDiIPZ28A2eNwsmqIOiz5ZzU/BhHJb2lyCeL3Wlw+bDA0yStgZAz35wxNJAAecRIIh5OVKHUQkTEwNIlTBzlmDmqreQ335yqGJtILjzgJouDQJhTsTzT8cBKlDiIyjpgIs0uHDYYmqoz7cxVDE+mJR5wEwdAkTh1EZCyP9fPUvEaUsMHQRJVxf65iaCK9MTgJwrfvKEMPJ1HqICKqiShhg6GJKuP+XMXQRA2BwUkQvr0iNa+RZTiJUgcRUU1ECRsMTVQZ9+cqhiZqKAxOLkqW4SRKHURENRElbDA0UWXcn6sYmqghMTi5IFmGkyh1EBHVRJSwwdBElXF/rqpvHYqlSPMaMpY6Baf27dsjNze3yvXnz59H+/bt671RVD1ZhpModRAR1USUsMHQRJVxf67So468LQma15Gx1Ck4nTp1CmVlZVWuLy4uxpkzZ+q9UeSYTMNJhDqIiGoiSthgaKLKuD9X6VWHJT9D81oyFk3f47R+/Xrb/9+0aRNatGhh+7msrAxJSUkIDw/XbeNIJdtwcnYdREQ1ESVsMDRRZdyfq/SsI2BkDHK/+afmxyDj0BScxo4dCwAwmUyIjo62u81sNiM8PBxvv/22bhtHVjIOJ4YmIhKZKGFDltC0NLlE8xpyjPtzld51wE17f5CxaApO5eXlAIB27drhp59+QmBgYINsFKlkHU4MTUQkKlHChiyh6bXvixG/16J5HVXF/bmqIeoozjih+XHIWOr0GaeTJ08yNDUCmYeTVnrUUXBok+Y1RGQsIoUNWULTjG+LERNh1ryW7HF/rhKhDjImTUecrpaUlISkpCRkZWXZjkRVWL58eb03zOg4nFR61VGwP1HzOiIyDtHChiyhafZtXrizkwePOtWDJfs35G19j/tziFEHGVedjji98sorGDlyJJKSkpCTk4P8/Hy7C9UPh5NKzzp8+47SvJaIjEHEsCFLaKpLHWQvd3M89+cQow4ytjodcUpISMDKlSvxyCOP6L09hsfhpNK7Dp/2ETzqRERVFJbIETYYmuRl9gvl/lyAOojqdMSppKQEQ4YM0XtbDI/DSSVCHURkDLGJRS4fNhia5OY/Ygr35wxNJIA6BafHHnsMn376qd7bYmiKpYjD6Q8i1EFExpGWV+7SYYOhSX4ms7fmNdyfWzE0kZ7q9Fa9oqIivP/++9i6dSt69eoFs9n+bDkLFizQZeOMJG9LAkovZBl+OIlQBxEZy5LR3i4bNhiayBHuz60YmkhvdQpOhw4dQp8+fQAAR44csbvNZOK3ideFJT8DoRPmGHo4iVAHERlPj2DXDBsMTeQI9+dWDE3UEOoUnL799lu9t8PwAkbGGHo4iVAHEVFtiBA2GJrIEe7PrRiaqKHU6TNOpD9zUFvNa2QZTiLUQURUGyKEDYYmcoT7cyuGJmpIdTridNttt13zLXnbtm3T9HiLFy/G/PnzkZGRgd69e+Pdd9/FwIEDa1y3evVqTJgwAXfffTe++uorTc/p6mQZTiLUQURUGyKEDYYmcoT7cyuGJmpodQpOFZ9vqmCxWHDgwAEcOXIE0dHRmh5rzZo1iIuLQ0JCAgYNGoSFCxciMjISqampCA4OrnbdqVOn8Oyzz2Lo0KF1KcGlyTKcRKiDiKg2RAgbDE3kCPfnVnrUYcn+TfMaMpY6Bad//vOfDq9/+eWXUVBQoOmxFixYgMmTJ2PSpEkArF+uu2HDBixfvhwvvPCCwzVlZWV46KGH8Morr+CHH37A+fPnNT2nK5NlOIlQBxFRbYgQNhiayBHuz630qiN3c7zmdWQsun7G6eGHH8by5ctrff+SkhLs27cPw4cPVzfIzQ3Dhw/Hrl27ql336quvIjg4GH/5y1/qtb2uRqbh5Ow6iIhqQ4SwwdBEjnB/bqVnHWa/UM1ryVh0DU67du2Ct3ftv6QtJycHZWVlCAkJsbs+JCQEGRkZDtf873//w7Jly/DBBx/U6jmKi4tx8eJFu4srkm04MTQRkehECBuyhKbCEkXzGqoe9+dWetfhP2KK5vVkLHV6q969995r97OiKDh37hz27t2LGTNm6LJhjly6dAmPPPIIPvjgAwQGBtZqzdy5c/HKK6802DY1BhmHE0MTEYlMhLAhS2i6VKwgNrFI8zpyjPtzq4aow5J/VvNjkLHUKTi1aNHC7mc3Nzd06dIFr776KkaOHFnrxwkMDIS7uzsyMzPtrs/MzERoaNXDpWlpaTh16hTGjBlju668vBwA4OHhgdTUVHTo0MFuzfTp0xEXF2f7+eLFiwgLC6v1NjqbrMPJGXUoFu64iahmooQNWULTHasuIy2vXPNaqor7cytR6iDjqVNwWrFihS5P7unpif79+yMpKQljx44FYA1CSUlJiI2NrXL/rl274vDhw3bXvfTSS7h06RL+9a9/OQxEXl5e8PJyzfdiczip9Kgjb0uC5nVEZCwihQ1ZQtORrDIsGe2N6K/4x6v64P7cSpQ6yJjqFJwq7Nu3DykpKQCAG264AX379tX8GHFxcYiOjkZERAQGDhyIhQsXorCw0HaWvaioKLRu3Rpz586Ft7c3evToYbe+ZcuWAFDlelfH4aTSqw5LvuPPzRERAeKFDVlC05ZHmsJD109UG0/BoU0o2J/I/bkgdZBx1Sk4ZWVl4cEHH8T27dttweX8+fO47bbbsHr1agQFBdX6scaPH4/s7GzMnDkTGRkZ6NOnDzZu3Gg7YUR6ejrc3Iw1cTmcVHrWETAyBrnfOD6VPhEZm4hhQ5bQNLC1O5LPlWl+HFIxNIlTBxlbnYLTtGnTcOnSJfz888/o1q0bAOCXX35BdHQ0/vrXv+Kzzz7T9HixsbEO35oHANu3b7/m2pUrV2p6LtFxOKn0rgNu2l+EEJH8jmSVYVpikXBhQytRQxPVn2/fUdyfC1AHUZ2C08aNG7F161ZbaAKA7t27Y/HixZpODkH2OJxUDVFHccYJzY9DRPKbuqEIvUNdO2wwNMnNt1ek5jUy78+1YmgivdQpOJWXl8NsNle53mw2285yR9pYsn9D3tb3OJwgRh1EZBwd/N1cOmwwNFFl3J+rGJpIT3X68NCf/vQnPPXUUzh7Vj3f/ZkzZ/D000/j9ttv123jjCR3czyHE8Sog4iMZdEob5cNGwxNVBn35yqGJtJbnYLTokWLcPHiRYSHh6NDhw7o0KED2rVrh4sXL+Ldd9/VexsNwewXavjhJEIdRGQ8TT1dM2wwNFFl3J+rGJqoIdTprXphYWFITk7G1q1bcfToUQBAt27dMHz4cF03zkj8R0wx9HASoQ4iotoQIWwwNFFl3J+rGJqooWg64rRt2zZ0794dFy9ehMlkwogRIzBt2jRMmzYNAwYMwA033IAffvihobZVaiazt+Y1sgwnEeogIqoNEcIGQxNVxv25iqGJGpKm4LRw4UJMnjwZzZs3r3JbixYt8MQTT2DBggW6bRxVT5bhJEIdRES1IULYYGiiyrg/VzE0UUPTFJwOHjyIO+64o9rbR44ciX379tV7o+jaZBlOItRBRFQbIoQNhiaqjPtzlR51FBzapHkNGYumzzhlZmY6PA257cE8PJCdnV3vjaLqyTKcRKiDiKg2RAgbDE1UGffnKr3qKNifCABISUnRvJ60CwwMRJs2bZy9GZpoCk6tW7fGkSNH0LFjR4e3Hzp0CK1atdJlw6gqmYaTs+sgIqoNEcIGQxNVxv25Ss86mtxwK4p+2Y6HH35Y82OQdk18vJFyNNWlwpOm4HTnnXdixowZuOOOO+DtbX8ygytXrmDWrFm46667dN1AspJtODE0EZHoRAgbsoSmI1llmteQY9yfq/Suw6NFCC7/vB2f3OODbkG1+zRLYYmC2MQipOWVY8lob/QIrlt/TN1QhA7+blg0yrtOX5GwNLkE8XstiIkw47F+nprXN3YdKdnlePjLK8jJyZE3OL300ktYt24dOnfujNjYWHTpYv1HfvToUSxevBhlZWV48cUXG2RDjUzG4cTQREQiEyFsyBKa9pyxvpii+uP+XNUQdRT8/C0AoFuQG/q1qvnfekV/nDpfjm3Rde+PaYlF6B1avz6P32upd587uw5XoCk4hYSEYOfOnYiJicH06dOhKAoAwGQyITIyEosXL0ZISEiDbKhRyTqctNKjDkv2b5rXEJHxiBI2ZAlNIz4uRAd/NxzKLNe8nlTcn6tEqIN9rtKjDleh+Qtw27Zti2+++Qb5+fk4ceIEFEVBp06d4Ofn1xDbZ2gcTlZ61ZG7OV7zOiIyFllehIhWx7zbvXDLysuaH4OsFEsR9+d/EKEO9rnKSKEJqENwquDn54cBAwbouS10FQ4nKz3rMPuFwpJ9SvN6IjIGWV6EiFjH8TwebaqPvC0JKL2Qxf25AHWwz1VGC02Axu9xosbB4WSldx3+I6ZoXk9ExiDLixBZ6iB7lvwM7s8FqEOU/mCfO0+djzhRw+BwsmqIOiz5ZzU/BhHJr+JsVK7+IoQvpuQVMDKG+3OGJgDy9PnS5BLNa0TAI04C4XCyEqUOIjIGhiZx6iDHzEFtNa/h/lzF0GQlUh3xey2a14mAwUkQBYc2cThBnDqIyDhiIswu/yJEhhdTpB/uz1UMTVai1RETYda8VgQMToIo2J9o+OEkSh1EZCx1+bJI0V6EuPqLKdIP9+cqhiYrEeuoy9wVAYOTIHz7jjL0cBKlDiKimoj4IsSVX0yRfrg/VzE0WclShygYnATh2ytS8xpZhpModRAR1USWFyGi1EH64f5cVd86CkvE6A9Z+lyW0ATwrHouS5bhJEodREQ1keVFiCh1kH64P1fVtw4AiE0swqnz5exzAeoQDYOTC5JlOIlSBxFRTWR5ESJKHaQf7s9V9a1DKbWeIjstrxzbotnnzq5DRHyrnouRZTiJUgcRUU1keREiSh2kH+7PVXrUcfHHLwAAS0Z7s88ZmhxicHIhMg0nEeogIqqJLC9CRKmD9MP9uUqvOkov5QIAegSzzxmaHGNwchGyDSdn10FEVBNZXoSIUgfph/tzlZ51tLjxPs3rAfb51WQOTQCDk0uQcTgxNBGRyGR5ESJKHUuTSzSvIce4P1fpXYeHXyvNj8E+V8kemgAGJ+HJOpwYmohIVLK8CBGpjvi9Fs3rqCruz1Ui1ME+VxkhNAEMTkLjcFLpUUfBoU2a1xCRscjyIkS0OmIizJrXkj3uz1Ui1ME+VxklNAEMTsLicFLpVUfB/kTN64jIOGR5ESJiHY/189S8nlSW7N+4P/+DCHWwz1VGCk0Ag5OQOJxUetbh23eU5rVEZAyyvAiRpQ6yl7s5nvtziFGHCP3BPnceBifBcDip9K7Dt1ek5vVEJL/CEjlehPDFlLzMfqHcnwtQhwj9IUufF5YomteIgMFJIBxOKhHqICJjiE0scvkXIbK8mCLH/EdM4f6coUmaPr9UrCA2sUjzOhF4OHsDyEqxFHE4/UGEOojIONLyyrEt2rVfhMjwYoqqZzJ7a17D/bkVQ5NKpDrS8so1rxUBjzgJIm9LAocTxKiDiIxlyWhvl38R4uovpkhf3J9bMTSpRKtjyWjtfwwQAY84CcKSn4HQCXMMPZxEqIOIjKdHsOu/CHHlF1OkL+7PrRiaVCLW4eGih26ECE6LFy/G/PnzkZGRgd69e+Pdd9/FwIEDHd533bp1eP3113HixAlYLBZ06tQJzzzzDB555JFG3mp9BYyMMfRwasw6UlJSND82aRcYGIg2bdo4ezOIdCfiixBXfTFF+jLa/rw6DE0qUetIPlem+XFE4PTgtGbNGsTFxSEhIQGDBg3CwoULERkZidTUVAQHB1e5v7+/P1588UV07doVnp6e+PrrrzFp0iQEBwcjMtJ1z5pmDmqreY0sw6mx6igryIebCXj44Yc1Pz5p5+3lidRjxxmeSCqivgjRSoQ6SF9G2p9fix51HMkqw7TEIvY5xKhDJE4PTgsWLMDkyZMxadIkAEBCQgI2bNiA5cuX44UXXqhy/1tvvdXu56eeegoffvgh/ve//7l0cNJKluHUmHWUFxegXAE+uccH3YLUY8SFJdazu6TllWPJaO86vW3nSFYZpm4oQgd/Nywa5Y2mntqH09LkEsTvtSAmwlynL4sUrY6i4hLk5OQwOJE0ZHkRIkIdpC+j7c+ro0cdADB1QxF6h7LPRahDNE4NTiUlJdi3bx+mT59uu87NzQ3Dhw/Hrl27alyvKAq2bduG1NRUvPHGGw25qUKRZTg5q45uQW7o18ravBVNfep8/c6qNS2x/kM2fq+l3sNJlDpiIsyI32vRvJ5IVLK8CBGhDtKXkffnV9OjjtL8cwCADv5u7HMB6hCRU4NTTk4OysrKEBISYnd9SEgIjh49Wu26CxcuoHXr1iguLoa7uzuWLFmCESNGOLxvcXExiouLbT9fvHhRn413ElmGkwh1cDip9K7jzk4eDE4kDfa5iqFJLNyfW+lVx4UfvwAALBrlzT5naHLIJc9p0axZMxw4cAA//fQT5syZg7i4OGzfvt3hfefOnYsWLVrYLmFhYY27sTqSaTg5uw4OJ5UIdRCJSoT+YJ+TI9yfW+lZh0ezAACo09vU2edWMocmwMnBKTAwEO7u7sjMzLS7PjMzE6GhodWuc3NzQ8eOHdGnTx8888wzuO+++zB37lyH950+fTouXLhgu5w+fVrXGhqLbMPJmXUUlnA4VRChDiJRidAfsvR5YYmieQ1Vj/tzK73raH7jfZrXA+zzCrKHJsDJwcnT0xP9+/dHUlKS7bry8nIkJSVh8ODBtX6c8vJyu7fjXc3LywvNmze3u7gaGYeTM7+nKTaxiMMJYtRBJCoR+kOWPr9UbD1xDemD+3OrhqjD5KH9xEzscysjhCZAgLPqxcXFITo6GhERERg4cCAWLlyIwsJC21n2oqKi0Lp1a9sRpblz5yIiIgIdOnRAcXExvvnmG3z88ceIj493ZhkNRtbh5Iw6lNISAEBaXv1OoCDDcBKhDiJRidAfsvR5RR1peeWa11JV3J9biVIH+9zKKKEJECA4jR8/HtnZ2Zg5cyYyMjLQp08fbNy40XbCiPT0dLi5XXXq6MJCTJ06Fb///jt8fHzQtWtXfPLJJxg/fryzSmgwHE4qPeq4+MeHPpeM9jb0cBKhDiJRidAfsvT51XUsGe2N6K941Kk+uD+3EqUO9rmVkUITIEBwAoDY2FjExsY6vK3ySR9ee+01vPbaa42wVc7F4aTSq47SS7kAUKfvN5JlOIlQB5GoROgPWfq8ch0eLnkqKnEUHNqEgv2J3J8LUgf73MpooQlw0bPqyY7DSaVnHS3q+KFPWYaTCHUQiUqE/pClz434YqqhMTSJU4cI/cE+dx4GJ8FwOKn0rsPDr5Xmx5BlOIlQB5GojmQ5vz9k6XOjvphqaL59R3F/LkAdIvSHLH1+JKtM8xoRMDgJhMNJJUIdsgwnEeogEtnUDUXsc4hRBznm2ytS8xruz1UMTSpR6pi6wTU/88jgJAhL9m8cTn8QoQ6ZhpOz6yASXQd/N/a5AHWQfrg/VzE0qUSqo4O/a0YQ19xqCeVujudwghh1yDacGJqIrm3RKG/2OUOTNLg/VzE0qUSrY9Eob83rRcDgJAizX6jhh5MIdcg4nBiaiK6tqSf7nKFJDtyfqxiaVCLWUZe5KwIGJ0H4j5hi6OEkQh2yDidn1FFYomheQ+Qq2OdWDE1i4f5cxdCkkqUOUQjxPU4EmMzaD1nKMpxEqIPDSaVHHbGJrvmhT6KasM+tGJrEwv25So86liaXIH6vhX0uSB0i4REnFyXLcBKhDg4nlV51pOWVa15LJDr2uRVDk1i4P1fpUQcAhiaIU4doGJxckCzDSYQ6OJxUetaxZLRrfuiTqDrscyuGJrFwf67So47Lx3cBAGIizOxzAeoQEd+q52JkGU4i1MHhpNK7Dg/+SYYkwj63YmgSC/fnKr3quJK6EwDwWD9PzevZ5ypZQxPAI04uRabh5Ow6OJxUItRBJCoR+oN9TpVxf67Ssw6fLkM0rwXY51eTOTQBDE4uQ7bh5Mw6jmRxOFUQoQ4iUYnQH7L0+ZGsMs1ryDHuz1V619Gk02DN69nnKtlDE8Dg5BJkHE7OqgMApm4o4nCCGHUQiUqE/pClz/ecKcPUDTzTph64P1eJUAf7XGWE0AQwOAmPw8lKjzpK888BADr4uxl+OIlQB5GoROgPWfq8oo4O/ny5UV/cn6tEqIN9rjJKaAIYnITG4WSlVx0XfvwCALBolLehh5MIdRCJSoT+kKXPr65j0SieabM+FEsR9+d/EKEO9rnKSKEJYHASFoeTlZ51eDQLAAA09TTucBKhDiJRidAfsvR55TrqMndJlbclgftziFEH+1xltNAEMDgJicPJSu86mt94n+b1gDzDSYQ6iEQlQn/I0udGfDHV0Cz5GdyfC1CHKP3BPnceBifBcDhZNUQdJg/t38sgy3ASoQ4iUS1NLnF6f8jS50Z9MdXQAkbGcH/O0ARAnj5fmlyieY0IGJwEwuFkJUodsgwnEeogEln8Xgv7XJA6yDFzUFvNa7g/VzE0WYlUR/xei+Z1ImBwEkTBoU0cThCnDpmGk7PrIBJdTISZfS5AHaQf7s9VDE1WotURE2HWvFYEDE6CKNifaPjhJEodsg0nhiaia3usn/a38bLPVQxNYuH+XMXQZCViHXWZuyJgcBKEb99Rhh5OotQh43BiaCLSF/tcxdAkFu7PVQxNVrLUIQoGJ0H49orUvEaW4SRKHRxOVnrUcSSrTPMaIlfAPlcxNImF+3NVfesoLBGjP2Tpc1lCEwB4OHsDqG5kGU6i1MHhZKVXHVM3FGleR1bp6enIyclx9mYYQkpKiqb7s89VDE1i4f5cVd86ACA2sQinzpezzwWoQzQMTi5IluEkSh0cTlZ61tHB3w2HMss1rze69PR0dOnaDUVXLjt7U6gS9rmKoUks3J+r6luHUmo9RXZaXjm2RbPPnV2HiBicXIwsw0mUOjicrPSuY97tXrhlJV/8a5WTk4OiK5fhf8c0XNr3X1jyMxAwMqZOpyK2ZP+G3M3xMPuFwn/EFJjM3pofo+DQJhTsT4Rv31F1ejuxYilC3pYEYeu48uteXPjhkxrXs89VDE1i4f5cpUcdF3/8AgCwZLQ3+5yhySEGJxci03ASoQ4OJ6uGqON4Ho821celff9F6YUshE6YU+f+yNv6HrxC2tWrz/U426fIdVhyT9e4nn2uYmgSC/fnKr3qKL2UCwDoEcw+Z2hyjCeHcBGyDSdn18HhZCVKHWTPkp/BPhegDlH6g31OlYnQH7L0+dV1tLjxPs3rAfb51WQOTQCPOLkEGYeTM+tYmlyC+L0Www8nUeqgqgJGxrDPGZoAyNPnS5NLNK8hx0ToD1n6vHIdlvyzmh+Dfa6SPTQBPOIkPFmHk7PqAMDQBHHqIMfq8lkg9rmKoclKpDri91o0r6OqROgPWfpcjzrY5yojhCaAwUloHE4qPeq4fHwXACAmwmzo4SRKHaQf9rmKoclKtDpiIsya15I9EfpDlj5naFKJUIcrYXASFIeTSq86rqTuBAA81s9T83pZhpModZB+2OcqhiYrEeuoy9wllSX7N6f3hyx9ztCkEqEOV8PgJCAOJ5Wedfh0GaJ5LSDPcBKlDtIP+1zF0GQlSx1kL3dzPPscYtQhQn+wz52HwUkwHE4qveto0mmw5vWyDCdR6iD9sM9V9a2jsESM/pClz434Yqqhmf1C2ecC1CFCf8jS54UliuY1ImBwEgiHk0qEOmQZTqLUQfoRoT9k6XMAiE0scnp/yNLnDE0Nw3/EFPY5Q5M0fX6pWEFsYpHmdSLg6cgFoViKOJz+IEIdMg0nEeog/YjQH7L0uVJqPUV2Wl45tkWzz51dB1XPZPbWvIZ9bsXQpBKpjrS8cs1rRSDEEafFixcjPDwc3t7eGDRoEPbs2VPtfT/44AMMHToUfn5+8PPzw/Dhw695f1eRtyWBwwli1CHbcHJ2HaQfEfpDlj4vL76Miz9+AQBYMtqbfc7QJBX2uRVDk0q0OpaM1v7HABE4PTitWbMGcXFxmDVrFpKTk9G7d29ERkYiKyvL4f23b9+OCRMm4Ntvv8WuXbsQFhaGkSNH4syZM4285fqy5GcYfjiJUIeMw4mhSQ4i9IcsfV5RR+mlXABAj2D2OUOTPNjnVgxNKhHrqMvcFYHTg9OCBQswefJkTJo0Cd27d0dCQgKaNGmC5cuXO7z/qlWrMHXqVPTp0wddu3bF0qVLUV5ejqSkpEbecn0FjIwx9HASoQ5ZhxNDk+sToT9k6fOr62hx432a1wPs86sxNImFfW7F0KSSpQ5RODU4lZSUYN++fRg+fLjtOjc3NwwfPhy7du2q1WNcvnwZFosF/v7+Dm8vLi7GxYsX7S4iMge11bxGluEkQh0cTio96liaXKJ5DTkmQn/I0ueV6/Dwa6X5MdjnKoYmsbDPrfSo40iW8/tDlj6XKTQBTg5OOTk5KCsrQ0hIiN31ISEhyMjIqNVjPP/887juuuvswtfV5s6dixYtWtguYWFh9d5uEcgynESog8NJpVcd8XstmtdRVSL0hyx9zr9Aq0Sog/QlQn/I0ucAMHVDEfscYtQhGqe/Va8+5s2bh9WrV+PLL7+Et7fjD5lNnz4dFy5csF1Onz7dyFupP1mGkwh1cDip9KwjJsKseS3ZE6E/ZOlzhiaVCHWQvkToD1n6vDT/HACgg78b+1yAOkTk1NORBwYGwt3dHZmZmXbXZ2ZmIjQ09Jpr33rrLcybNw9bt25Fr169qr2fl5cXvLzkGeyyDCcR6uBwUuldx52dPHjUqR4s2b8hb+t77HOIUQf7XMXQJBYR+kOWPi8+m4oLf5xpc9Eob/Y5Q5NDTj3i5Onpif79+9ud2KHiRA+DBw+udt2bb76J2bNnY+PGjYiIiGiMTRWCTMPJ2XVwOKlEqIPs5W6OZ59DjDpE6A/2OTkiQn/I0ucVdXg0CwAANPVknzM0Oeb0t+rFxcXhgw8+wIcffoiUlBTExMSgsLAQkyZNAgBERUVh+vTptvu/8cYbmDFjBpYvX47w8HBkZGQgIyMDBQUFziqhUcg2nJxZR2EJh1MFEeqgqsx+oexzAeoQoT9k6fPCEkXzGqqeCP0hS59fXUfzOp5pk31uJXtoApz8Vj0AGD9+PLKzszFz5kxkZGSgT58+2Lhxo+2EEenp6XBzU/NdfHw8SkpKcN999v+4Z82ahZdffrkxN73RyDicnFUHAMQmFuHU+XLDDycR6iDH/EdMYZ8zNEnT55eKFcQmFmleR46J0B+y9HnlOi6f2K35MdjnVkYITYAAwQkAYmNjERsb6/C27du32/186tSpht8ggcg6nJxRh1JqPUV2Wl45tkUbeziJUAdVz2TW/o3q7HMrhiaVSHWk5ZVrXktVidAfsvS5HnWwz62MEpoAAd6qR9XjcFLpUcfFPz70uWS0t6GHkwh1kL7Y51YMTSrR6lgyWvsfA8ieCP0hS58zNKlEqMOVCHHEiaricFLpVUfppVwAQI9g4w4nEeogfbHPrRiaVCLW4cE/09ZLwaFNKNifyD4XpA72uZXRQhPAI05C4nBS6VlHizp+6FOW4SRCHaQv9rkVQ5NKljrIHkOTOHWI0B/sc+dhcBIMh5NK7zo8/FppfgxZhpMIdZC+2OdWetRxJMv5/SFLnxv1xVRD8+07in0uQB0i9IcsfX4kq0zzGhEwOAmEw0klQh2yDCcR6iB9idAfsvQ5AEzdUMQ+hxh1kGO+vSI1r2GfqxiaVKLUMXWDa55pk8FJEJbs3zic/iBCHTINJ2fXQfoSoT9k6fPS/HMAgA7+buxzAeog/bDPVQxNKpHq6ODvmhHENbdaQrmb4zmcIEYdsg0nhiZ5iNAfsvR58dlUXPjjTJuLRnmzzxmapME+VzE0qUSrY9Eo1zzTJoOTIMx+oYYfTiLUIeNwYmiSgwj9IUufV9Th0SwAANDUk33O0CQH9rmKoUklYh11mbsiYHAShP+IKYYeTiLUIetwckYdhSWK5jVUPRH6Q5Y+v7qO5nU80yb73IqhSSzscxVDk0qWOkTB4CQIk1n7IUtZhpMIdXA4qfSoIzbRNT/0KSIR+kOWPq9ch8nDU/NjsM+tGJrEwj5X6VHH0uQSp/eHLH0uU2gCGJxclizDSYQ6OJxUetWRlleueS1VJUJ/yNLn/Au0SoQ6SD+i9IcsfQ4A8Xst7HNB6hANg5MLkmU4iVAHh5NKzzqWjHbND32KRIT+kKXPGZpUItRB+hGlP2Tp88vHdwEAYiLM7HMB6hCRh7M3gLSRZTiJUAeHk0rvOjz4J5l6KTi0CQX7E9nngtTBPrdiaBKLKP0hS5+f37kaV1J3AgAe66f9bbzsc5WsoQngESeXItNwcnYdHE4qEeogewxN4tQhQn+wz6kyUfpDlj6vqMOnyxDNawH2+dVkDk0Ag5PLkG04ObOOI1kcThVEqIOq8u07in0uQB0i9IcsfX4kq0zzGnJMlP6Qpc+vrqNJp8Ga17PPVbKHJoDBySXIOJycVQcATN1QxOEEMeogx3x7RWpewz5XMTSpRKlj6gaeaVMPovSHLH1e3zrY5yojhCaAwUl4HE5WetRRmn8OANDB383ww0mEOkg/7HMVQ5NKpDo6+PPlRn2J0h+y9DlDk5UodbgKTjKBcThZ6VXHhR+/AAAsGuVt6OEkQh2kH/a5iqFJJVodi0bxTJv1oViKhOgPWfqcoclKlDpcCYOToDicrPSsw6NZAACgqadxh5MIdZB+2OcqhiaViHXUZe6SKm9LgtP7Q5Y+Z2iyEqUOV8PgJCAOJyu962h+432a1wPyDCcR6iD9sM9VDE0qWeoge5b8DPa5AHWI0h/sc+dhcBIMh5NVQ9Rh8tD+vQyyDCcR6iD9sM9VetSxNLnE6f0hS58b9cVUQwsYGcM+Z2gCIE+fL00u0bxGBAxOAuFwshKlDlmGkwh1kH5E6Q9Z+hwA4vda2OeC1EGOmYPaal7DPlcxNFmJVEf8XovmdSJgcBJEwaFNHE4Qpw6ZhpOz6yD9iNIfsvT55eO7AAAxEWb2uQB1kH7Y5yqGJivR6oiJMGteKwIGJ0EU7E80/HASpQ7ZhhNDkxxE6Q9Z+vz8ztW4kroTAPBYP+1v42WfqxiaxMI+VzE0WYlYR13mrggYnATh23eUoYeTKHXIOJwYmlyfKP0hS59X1OHTZYjmtQD7/GoMTWJhn6sYmqxkqUMUDE6C8O0VqXmNLMNJlDo4nKz0qONIVpnmNeSYKP0hS59fXUeTToM1r2efqxiaxMI+V9W3jsISMfpDlj6XJTQBDE4uS5bhJEodHE5WetUxdUOR5nVUlSj9IUuf8y/QVqLUQfoRoT9k6XMAiE0scnp/yNLnMoUmgMHJJckynESpg8PJSs86OvhztNSXKP0hS58zNFmJUgfpR4T+kKXPlVLrKbLT8srZ5wLUISK+unExsgwnUergcLLSu45Fo7w1ryeVYikSoj9k6XOGJitR6iD9iNAfsvR5efFlXPzxCwDAktHe7HOGJocYnFyITMNJhDo4nKwaoo6mnnwxVR95WxKc3h+y9DlDk5UodZB+ROgPWfq8oo7SS7kAgB7B7HOGJscYnFyEbMPJ2XVwOFmJUgfZs+RnsM8FqEOU/mCfU2Ui9IcsfX51HS1uvE/zeoB9fjWZQxMAeDh7A6hmMg4nZ9axNLkE8Xsthh9OotRBVQWMjGGfMzQBkKfPlyaXaF5DjonQH7L0eeU6LPlnNT8G+1wle2gCeMRJeLIOJ2fVAYChCeLUQY6Zg9pqXsM+VzE0WYlUR/xei+Z1VJUI/SFLn+tRB/tcZYTQBDA4CY3DSaVHHZeP7wIAxESYDT2cRKmD9MM+VzE0WYlWR0yEWfNasidCf8jS5wxNKhHqcCUMToLicFLpVceV1J0AgMf6eWpeL8twEqUO0g/7XMXQZCViHXWZu6SyZP/m9P6Qpc8ZmlQi1OFqGJwExOGk0rMOny5DNK8F5BlOotRB+mGfqxiarGSpg+zlbo5nn0OMOkToD/a58zA4CYbDSaV3HU06Dda8XpbhJEodpB/2uaq+dRSWiNEfsvS5EV9MNTSzXyj7XIA6ROgPWfq8sETRvEYETg9OixcvRnh4OLy9vTFo0CDs2bOn2vv+/PPPGDduHMLDw2EymbBw4cLG29BGwOGkEqEOWYaTKHWQfkToD1n6HABiE4uc3h+y9DlDU8PwHzGFfc7QJE2fXypWEJtYpHmdCJwanNasWYO4uDjMmjULycnJ6N27NyIjI5GVleXw/pcvX0b79u0xb948hIaGNvLWNizFUsTh9AcR6pBpOIlQB+lHhP6Qpc+VUuspstPyytnnAtRB1TOZvTWvYZ9bMTSpRKojLa9c81oRODU4LViwAJMnT8akSZPQvXt3JCQkoEmTJli+fLnD+w8YMADz58/Hgw8+CC8vuYZy3pYEDieIUYdsw8nZdZB+ROgPWfq8vPgyLv74BQBgyWhv9jlDk1TY51YMTSrR6lgyWvsfA0TgtC/ALSkpwb59+zB9+nTbdW5ubhg+fDh27dql2/MUFxejuLjY9vPFixd1e2w9WfIzEDphjqGHkwh1yDicGJrkIEJ/yNLnFXWUXsoFAPQIZp8zNMmDfW7F0KQSsQ4Pp39YqG6cttk5OTkoKytDSEiI3fUhISHIyMjQ7Xnmzp2LFi1a2C5hYWG6PbaeAkbGGHo4iVCHrMOJocn1idAfsvT51XW0uPE+zesB9vnVGJrEwj63YmhSyVKHKFw079Xe9OnTceHCBdvl9OnTzt4kh8xBbTWvkWU4iVAHh5NKjzqWJpdoXkOOidAfsvR55To8/Fppfgz2uYqhSSzscys96jiS5fz+kKXPZQpNgBPfqhcYGAh3d3dkZmbaXZ+ZmanriR+8vLyk+zwUIM9wEqEODieVXnXE77VoXkdVidAfsvS5ozos+Wc1PQb7XMXQJBb2uZUedQDA1A1F6B3KPhehDtE47YiTp6cn+vfvj6SkJNt15eXlSEpKwuDB2r9vx0hkGU4i1MHhpNKzjpgIs+a1ZE+E/pClz/m2HZUIdZC+ROgPWfq8NP8cAKCDvxv7XIA6ROS0I04AEBcXh+joaERERGDgwIFYuHAhCgsLMWnSJABAVFQUWrdujblz5wKwnlDil19+sf3/M2fO4MCBA/D19UXHjh2dVkdjkmU4iVAHh5NK7zru7OTBo071YMn+DXlb32OfQ4w62OcqhiaxiNAfsvR58dlUXPjjTJuLRnmzzxmaHHJqcBo/fjyys7Mxc+ZMZGRkoE+fPti4caPthBHp6elwc1MPip09exZ9+/a1/fzWW2/hrbfewrBhw7B9+/bG3vxGJ9NwcnYdHE6qhqgj+VyZ5scgVe7meHiFtGOfC1AH+1zF0CQWEfpDlj6vqMOjWQBKz59DU0/2OUOTY04NTgAQGxuL2NhYh7dVDkPh4eFQFKURtko8sg0nZ9ZRWMLhVEGEOqgqs18o+1yAOkToD1n6vLDEmPvuhiJCf8jS51fX0bTncORtfFfzY7DPrWQPTYABzqonAxmHk7PqAIDYxCIOJ4hRBznmP2IK+5yhSZo+v1SsIDaxSPM6ckyE/pClzyvXYfLw1PwY7HMrI4QmQIAjTnRtsg4nZ9ShlFpPkZ2WV45t0cYeTiLUQdUzmbV/ozr73IqhSSVSHWl55ZrXUlUi9Icsfa5HHexzK6OEJoBHnITG4aTSo46Lf3zoc8lob0MPJxHqIH2xz60YmlSi1bFktPY/BpA9EfpDlj5naFKJUIcr4REnQXE4qfSqo/RSLgCgR7Bxh5MIdZC+2OdWDE0qEevw4J9p66Xg0CYU7E9knwtSB/vcymihCeARJyFxOKn0rKPFjfdpXg/IM5xEqIP0xT63YmhSyVIH2WNoEqcOEfqDfe48DE6C4XBS6V2Hh18rzY8hy3ASoQ7SF/vcSo86jmQ5vz9k6XOjvphqaL59R7HPBahDhP6Qpc+PZLnm15YwOAmEw0klQh2yDCcR6iB9idAfsvQ5AEzdUMQ+hxh1kGO+vSI1r2GfqxiaVKLUMXWDa55pk8FJEJbs3zic/iBCHTINJ2fXQfoSoT9k6fPS/HMAgA7+buxzAeog/bDPVQxNKpHq6ODvmhHENbdaQrmb4zmcIEYdsg0nhiZ5iNAfsvR58dlUXPjjTJuLRnmzzxmapME+VzE0qUSrY9Eo1zzTJoOTIMx+oYYfTiLUIeNwYmiSgwj9IUufV9Th0SwAANDUk33O0CQH9rmKoUklYh11mbsiYHAShP+IKYYeTiLUIetwckYdhSWK5jVUPRH6Q5Y+v7qO5nU80yb73IqhSSzscxVDk0qWOkTB4CQIk1n7IUtZhpMIdXA4qfSoIzbRNT/0KSIR+kOWPq9ch8nDU/NjsM+tGJrEwj5X6VHH0uQSp/eHLH0uU2gCGJxclizDSYQ6OJxUetWRlleueS1VJUJ/yNLn/Au0SoQ6SD+i9IcsfQ4A8Xst7HNB6hANg5MLkmU4iVAHh5NKzzqWjHbND32KRIT+kKXPGZpUItRB+hGlP2Tp88vHdwEAYiLM7HMB6hCRh7M3gLSRZTiJUAeHk0rvOjz4J5l6KTi0CQX7E9nngtTBPrdiaBKLKP0hS5+f37kaV1J3AgAe66f9bbzsc5WsoQngESeXItNwcnYdHE4qEeogewxN4tQhQn+wz6kyUfpDlj6vqMOnyxDNawH2+dVkDk0Ag5PLkG04ObOOI1kcThVEqIOq8u07in0uQB0i9IcsfX4kq0zzGnJMlP6Qpc+vrqNJp8Ga17PPVbKHJoDBySXIOJycVQcATN1QxOEEMeogx3x7RWpewz5XMTSpRKlj6gaeaVMPovSHLH1e3zrY5yojhCaAwUl4HE5WetRRmn8OANDB383ww0mEOkg/7HMVQ5NKpDo6+PPlRn2J0h+y9DlDk5UodbgKTjKBcThZ6VXHhR+/AAAsGuVt6OEkQh2kH/a5iqFJJVodi0bxTJv1oViKhOgPWfqcoclKlDpcCYOToDicrPSsw6NZAACgqadxh5MIdZB+2OcqhiaViHXUZe6SKm9LgtP7Q5Y+Z2iyEqUOV8PgJCAOJyu962h+432a1wPyDCcR6iD9sM9VDE0qWeoge5b8DPa5AHWI0h/sc+dhcBIMh5NVQ9Rh8tD+vQyyDCcR6iD9sM9VetSxNLnE6f0hS58b9cVUQwsYGcM+Z2gCIE+fL00u0bxGBAxOAuFwshKlDlmGkwh1kH5E6Q9Z+hwA4vda2OeC1EGOmYPaal7DPlcxNFmJVEf8XovmdSJgcBJEwaFNHE4Qpw6ZhpOz6yD9iNIfsvT55eO7AAAxEWb2uQB1kH7Y5yqGJivR6oiJMGteKwIGJ0EU7E80/HASpQ7ZhhNDkxxE6Q9Z+vz8ztW4kroTAPBYP+1v42WfqxiaxMI+VzE0WYlYR13mrggYnATh23eUoYeTKHXIOJwYmlyfKP0hS59X1OHTZYjmtQD7/GoMTWJhn6sYmqxkqUMUDE6C8O0VqXmNLMNJlDo4nKz0qONIVpnmNeSYKP0hS59fXUeTToM1r2efqxiaxMI+V9W3jsISMfpDlj6XJTQBDE4uS5bhJEodHE5WetUxdUOR5nVUlSj9IUuf8y/QVqLUQfoRoT9k6XMAiE0scnp/yNLnMoUmgMHJJckynESpg8PJSs86OvhztNSXKP0hS58zNFmJUgfpR4T+kKXPlVLrKbLT8srZ5wLUISK+unExsgwnUergcLLSu45Fo7w1ryeVYikSoj9k6XOGJitR6iD9iNAfsvR5efFlXPzxCwDAktHe7HOGJocYnFyITMNJhDo4nKwaoo6mnnwxVR95WxKc3h+y9DlDk5UodZB+ROgPWfq8oo7SS7kAgB7B7HOGJscYnFyEbMPJ2XVwOFmJUgfZs+RnsM8FqEOU/mCfU2Ui9IcsfX51HS1uvE/zeoB9fjWZQxMAeDh7A6hmMg4nZ9axNLkE8Xsthh9OotRBVQWMjGGfMzQBkKfPlyaXaF5DjonQH7L0eeU6LPlnNT8G+1wle2gCeMRJeLIOJ2fVAYChCeLUQY6Zg9pqXsM+VzE0WYlUR/xei+Z1VJUI/SFLn+tRB/tcZYTQBDA4CY3DSaVHHZeP7wIAxESYDT2cRKmD9MM+VzE0WYlWR0yEWfNasidCf8jS5wxNKhHqcCUMToLicFLpVceV1J0AgMf6eWpeL8twEqUO0g/7XMXQZCViHXWZu6SyZP/m9P6Qpc8ZmlQi1OFqhAhOixcvRnh4OLy9vTFo0CDs2bPnmvf//PPP0bVrV3h7e6Nnz5745ptvGmlLGweHk0rPOny6DNG8FpBnOIlSB+mHfa5iaLKSpQ6yl7s5nn0OMeoQoT/Y587j9OC0Zs0axMXFYdasWUhOTkbv3r0RGRmJrKwsh/ffuXMnJkyYgL/85S/Yv38/xo4di7Fjx+LIkSONvOUNg8NJpXcdTToN1rxeluEkSh2kH/a5qr51FJaI0R+y9LkRX0w1NLNfKPtcgDpE6A9Z+rywRNG8RgROD04LFizA5MmTMWnSJHTv3h0JCQlo0qQJli9f7vD+//rXv3DHHXfg73//O7p164bZs2ejX79+WLRoUSNvuf44nFQi1CHLcBKlDtKPCP0hS58DQGxikdP7Q5Y+Z2hqGP4jprDPGZqk6fNLxQpiE4s0rxOBU09HXlJSgn379mH69Om269zc3DB8+HDs2rXL4Zpdu3YhLi7O7rrIyEh89dVXDu9fXFyM4uJi288XLlwAAFy8eLGeW6+PgoICAEDxmRTkfL0Apecz4fenv6C81IIr6dqOolly0pG/bRk8Woag+ZDxKM78VfP2FP68FYWHtqJpr+Hwur6H5m1QSouQv225kHVYck8DAPadLUNBDX/puFyi4NktRTiZr2BBpBeKShV8/1uppm1IyS5D3KZitPMzYcZQT+zPKNNcx0cHS7Bsfyn+0tcDt7R117wNzqojNaccgPXftyi95gps8yDjBMpLHO9U2Oeq+tZRknkSAHAspxwL72CfN2QdnAl1UzETSnJ/h6LxD/TscystdVT3OoF9rtKrjrQ86+9XhJlQ8fxKbZpMcaIzZ84oAJSdO3faXf/3v/9dGThwoMM1ZrNZ+fTTT+2uW7x4sRIcHOzw/rNmzVIA8MILL7zwwgsvvPDCCy+8OLycPn26xuwi/RfgTp8+3e4IVXl5OfLy8hAQEACTiW83MpKLFy8iLCwMp0+fRvPmzZ29OUTkZJwJRHQ1zgRjUhQFly5dwnXXXVfjfZ0anAIDA+Hu7o7MzEy76zMzMxEaGupwTWhoqKb7e3l5wcvL/v2XLVu2rPtGk8tr3rw5ByIR2XAmENHVOBOMp0WLFrW6n1NPDuHp6Yn+/fsjKSnJdl15eTmSkpIweLDjM6ANHjzY7v4AsGXLlmrvT0REREREVF9Of6teXFwcoqOjERERgYEDB2LhwoUoLCzEpEmTAABRUVFo3bo15s6dCwB46qmnMGzYMLz99tsYPXo0Vq9ejb179+L99993ZhlERERERCQxpwen8ePHIzs7GzNnzkRGRgb69OmDjRs3IiQkBACQnp4ONzf1wNiQIUPw6aef4qWXXsI//vEPdOrUCV999RV69OjhrBLIRXh5eWHWrFlV3rpJRMbEmUBEV+NMoJqYFEXrCS6JiIiIiIiMxelfgEtERERERCQ6BiciIiIiIqIaMDgRERERERHVgMGJbE6dOgWTyYQDBw7Ues3KlSt1/16sumwHEbmm7du3w2Qy4fz5887eFCLSmclkwldffeXszaji1ltvxd/+9jfbz+Hh4Vi4cKHTtodcB4OTZE6fPo1HH30U1113HTw9PdG2bVs89dRTyM3NrXFtWFgYzp07p+kMhePHj8exY8fqs8l1UnnoAcCJEycwadIkXH/99fDy8kK7du0wYcIE7N2713afug7xuXPnwt3dHfPnz6/nlhOJYdeuXXB3d8fo0aOr3Pbyyy+jT58+Va4X5UXQxIkTMXbsWLvrMjIyMG3aNLRv3x5eXl4ICwvDmDFj7L73r64vjj777DO4u7vjySefrOeWEzWuiRMnwmQywWQywWw2o127dnjuuedQVFTk7E1rUFfXffXlxIkTDu//008/4fHHH9flua81W8n1MThJ5Ndff0VERASOHz+Ozz77DCdOnEBCQoLtC4Xz8vKqXVtSUgJ3d3eEhobCw6P2Z6n38fFBcHCwHptfL3v37kX//v1x7NgxvPfee/jll1/w5ZdfomvXrnjmmWfq/fjLly/Hc889h+XLl+uwtfVTUlLi7E0gCSxbtgzTpk3D999/j7Nnzzp7c+rl1KlT6N+/P7Zt24b58+fj8OHD2LhxI2677TZdws6yZcvw3HPP4bPPPnP6C072P2l1xx134Ny5c/j111/xz3/+E++99x5mzZrl7M1qcBV1X31p166dw/sGBQWhSZMmujyvSLOV80J/DE4SefLJJ+Hp6YnNmzdj2LBhaNOmDUaNGoWtW7fizJkzePHFF233DQ8Px+zZsxEVFYXmzZvj8ccfd/gWufXr16NTp07w9vbGbbfdhg8//NDubTWV36pX8Zfqjz/+GOHh4WjRogUefPBBXLp0yXafjRs34uabb0bLli0REBCAu+66C2lpaXWuW1EUTJw4EZ06dcIPP/yA0aNHo0OHDujTpw9mzZqF//znP3V+bAD47rvvcOXKFbz66qu4ePEidu7caXd7eXk53nzzTXTs2BFeXl5o06YN5syZY7v9999/x4QJE+Dv74+mTZsiIiICu3fvBuD4L+d/+9vfcOutt9p+vvXWWxEbG4u//e1vCAwMRGRkJABgwYIF6NmzJ5o2bYqwsDBMnToVBQUFdo+1Y8cO3HrrrWjSpAn8/PwQGRmJ/Px8fPTRRwgICEBxcbHd/ceOHYtHHnmkXr8vEl9BQQHWrFmDmJgYjB49GitXrrTdtnLlSrzyyis4ePCg7a+0K1euRHh4OADgnnvugclksv2clpaGu+++GyEhIfD19cWAAQOwdetWu+crLi7G888/j7CwMHh5eaFjx45YtmyZw227fPkyRo0ahZtuuqnWb9+bOnUqTCYT9uzZg3HjxqFz58644YYbEBcXhx9//FHrr8fOyZMnsXPnTrzwwgvo3Lkz1q1bV+U+y5cvxw033AAvLy+0atUKsbGxttvOnz+PJ554AiEhIfD29kaPHj3w9ddfA3B8ZG/hwoW23y2gzog5c+bguuuuQ5cuXQAAH3/8MSIiItCsWTOEhobiz3/+M7Kysuwe6+eff8Zdd92F5s2bo1mzZhg6dCjS0tLw/fffw2w2IyMjw+7+f/vb3zB06ND6/LpIQF5eXggNDUVYWBjGjh2L4cOHY8uWLbbbc3NzMWHCBLRu3RpNmjRBz5498dlnn9k9xq233oq//vWveO655+Dv74/Q0FC8/PLLdvc5fvw4brnlFnh7e6N79+52z1Hh8OHD+NOf/gQfHx8EBATg8ccft9tvVfx7f/311xESEoKWLVvi1VdfRWlpKf7+97/D398f119/PVasWFHruq++uLu7O7xv5aPRJpMJ8fHxGDVqFHx8fNC+fXt88cUXNT7ntWZrhf/+978YMGAAvL29ERgYiHvuucd227VmpaOPRnz11VcwmUy2nytmytKlS9GuXTt4e3sDqN3rrupeq5w6dQpubm52794BrLOqbdu2KC8vr/H3IhMGJ0nk5eVh06ZNmDp1Knx8fOxuCw0NxUMPPYQ1a9bg6q/teuutt9C7d2/s378fM2bMqPKYJ0+exH333YexY8fi4MGDeOKJJ+zCV3XS0tLw1Vdf4euvv8bXX3+N7777DvPmzbPdXlhYiLi4OOzduxdJSUlwc3PDPffcU+fmO3DgAH7++Wc888wzdl+WXKG+n8FatmwZJkyYALPZjAkTJlR5wTd9+nTMmzcPM2bMwC+//IJPP/3U9gXOBQUFGDZsGM6cOYP169fj4MGDeO655zTX+uGHH8LT0xM7duxAQkICAMDNzQ3vvPMOfv75Z3z44YfYtm0bnnvuOduaAwcO4Pbbb0f37t2xa9cu/O9//8OYMWNQVlaG+++/H2VlZVi/fr3t/llZWdiwYQMeffTRuv6qyEX8+9//RteuXdGlSxc8/PDDWL58uW02jB8/Hs888wxuuOEG219px48fj59++gkAsGLFCpw7d872c0FBAe68804kJSVh//79uOOOOzBmzBikp6fbni8qKgqfffYZ3nnnHaSkpOC9996Dr69vle06f/48RowYgfLycmzZsqVWvZuXl4eNGzfiySefRNOmTavcXt/+X7FiBUaPHo0WLVrg4YcfrtL/8fHxePLJJ/H444/j8OHDWL9+PTp27AjA+keVUaNGYceOHfjkk0/wyy+/YN68edW+eKtOUlISUlNTsWXLFlvoslgsmD17Ng4ePIivvvoKp06dwsSJE21rzpw5g1tuuQVeXl7Ytm0b9u3bh0cffRSlpaW45ZZb0L59e3z88ce2+1ssFqxatYr9L7kjR45g586d8PT0tF1XVFSE/v37Y8OGDThy5Agef/xxPPLII9izZ4/d2g8//BBNmzbF7t278eabb+LVV1+1haPy8nLce++98PT0xO7du5GQkIDnn3/ebn1hYSEiIyPh5+eHn376CZ9//jm2bt1q94cGANi2bRvOnj2L77//HgsWLMCsWbNw1113wc/PD7t378aUKVPwxBNP4Pfff2+g35LVjBkzMG7cOBw8eBAPPfQQHnzwQaSkpFxzzbVmKwBs2LAB99xzD+68807s378fSUlJGDhwoO322s7Kazlx4gTWrl2LdevW2f4QXtPrrmu9VgkPD8fw4cOrhNUVK1Zg4sSJDl93SU0hKfz4448KAOXLL790ePuCBQsUAEpmZqaiKIrStm1bZezYsXb3OXnypAJA2b9/v6IoivL8888rPXr0sLvPiy++qABQ8vPzFUVRlBUrVigtWrSw3T5r1iylSZMmysWLF23X/f3vf1cGDRpU7bZnZ2crAJTDhw873A5Hhg0bpjz11FOKoijKmjVrFABKcnJytfevcK3fkSMXLlxQfHx8lAMHDiiKoij79+9XfH19lUuXLimKoigXL15UvLy8lA8++MDh+vfee09p1qyZkpub6/D26Oho5e6777a77qmnnlKGDRtm+3nYsGFK3759a9zWzz//XAkICLD9PGHCBOWmm26q9v4xMTHKqFGjbD+//fbbSvv27ZXy8vIan4tc25AhQ5SFCxcqiqIoFotFCQwMVL799lvb7bNmzVJ69+5dZV1t++eGG25Q3n33XUVRFCU1NVUBoGzZssXhfb/99lsFgJKSkqL06tVLGTdunFJcXHzNx7+6b3bv3q0AUNatW1fjdrVt21b55z//WeP9KpSVlSlhYWHKV199pSiKdVZ5enoqv/76q+0+1113nfLiiy86XL9p0ybFzc1NSU1NdXi7o9/zP//5T6Vt27a2n6Ojo5WQkJAafyc//fSTAsA2m6ZPn660a9dOKSkpcXj/N954Q+nWrZvt57Vr1yq+vr5KQUHBNZ+HXEt0dLTi7u6uNG3aVPHy8lIAKG5ubsoXX3xxzXWjR49WnnnmGdvPw4YNU26++Wa7+wwYMEB5/vnnFUWx/lv38PBQzpw5Y7s9MTHRbma8//77ip+fn92/sQ0bNihubm5KRkaGbXvbtm2rlJWV2e7TpUsXZejQobafS0tLlaZNmyqfffZZrequuNx333129VS8hlCUqrMBgDJlyhS7xxw0aJASExNT7XMqSs2zdfDgwcpDDz3kcG1Ns7Ly6y1FUZQvv/xSufql/KxZsxSz2axkZWVdczsrv+6q6bXKmjVrFD8/P6WoqEhRFEXZt2+fYjKZlJMnT17zeWRksJgoP+Wqv2zUJCIi4pq3p6amYsCAAXbXXf2XkeqEh4ejWbNmtp9btWpl9xaS48ePY8KECWjfvj2aN29ue1vK1X+h1kJLzVp99tln6NChA3r37g0A6NOnD9q2bYs1a9YAAFJSUlBcXIzbb7/d4foDBw6gb9++8Pf3r9d29O/fv8p1W7duxe23347WrVujWbNmeOSRR5Cbm4vLly/bnru67QKAyZMnY/PmzThz5gwA69sAKj5QS/JKTU3Fnj17MGHCBACAh4cHxo8fX+1b52pSUFCAZ599Ft26dUPLli3h6+uLlJQUWz8fOHAA7u7uGDZs2DUfZ8SIEejYsSPWrFlj99fwmjRk/2/ZsgWFhYW48847AQCBgYEYMWKE7bOOWVlZOHv27DX7//rrr0fnzp3rtR09e/as8jvZt28fxowZgzZt2qBZs2a23+/Vv/ehQ4fCbDY7fMyJEyfixIkTtrcyrly5Eg888IDDo3bk2m677TYcOHAAu3fvRnR0NCZNmoRx48bZbi8rK8Ps2bPRs2dP+Pv7w9fXF5s2baqyT+7Vq5fdz1fv21NSUhAWFobrrrvOdvvgwYPt7p+SkoLevXvb/Ru76aabUF5ejtTUVNt1N9xwg91RjJCQEPTs2dP2s7u7OwICAqq8NbW6uisu77zzzjXvX1nl7R88ePA1jzjVZrZea79c21lZk7Zt2yIoKMjuupped9X0WmXs2LFwd3fHl19+CcA6L2677Ta7txUbBYOTJDp27AiTyVRtU6ekpMDPz8+umRpqB1l5R20ymezemjZmzBjk5eXhgw8+wO7du22f96nrhxgrXpQcPXq0jltcvWXLluHnn3+Gh4eH7fLLL7/YXjhVfltkZTXd7ubmVuWFn8ViqXK/yv+tTp06hbvuugu9evXC2rVrsW/fPixevBiA+nus6bn79u2L3r1746OPPsK+ffvw888/273Vh+S0bNkylJaW4rrrrrP9m46Pj8fatWtx4cIFzY/37LPP4ssvv8Trr7+OH374AQcOHEDPnj1r/e+wwujRo/H999/jl19+0fT8nTp1gslkarD+z8vLg4+Pj+139c033+DDDz9EeXm50/q/4i1PzZs3x6pVq/DTTz/ZXtDU9vceHByMMWPGYMWKFcjMzERiYiLfpieppk2bomPHjujduzeWL1+O3bt3272Ynz9/Pv71r3/h+eefx7fffosDBw4gMjKyyj65pn27Xhw9T12eu6LuikurVq1039ar1Wa2XqsvG2peADW/7qrpuT09PREVFYUVK1agpKQEn376qWHnBYOTJAICAjBixAgsWbIEV65csbstIyMDq1atwvjx4zUdTejSpUuVDwNWfK6hrnJzc5GamoqXXnoJt99+O7p164b8/Px6PWafPn3QvXt3vP322w4HaV2/H+bw4cPYu3cvtm/fbvdXq+3bt2PXrl04evQoOnXqBB8fH7tTHl+tV69eOHDgQLVnNAwKCsK5c+fsrqvN91ft27cP5eXlePvtt3HjjTeic+fOVc7e06tXr2q3q8Jjjz2GlStXYsWKFRg+fDjCwsJqfG5yXaWlpfjoo4/w9ttv2/2bPnjwIK677jrbB8I9PT1RVlZWZb3ZbK5y/Y4dOzBx4kTcc8896NmzJ0JDQ3Hq1Cnb7T179kR5eTm+++67a27bvHnzEB0djdtvv11TePL390dkZCQWL16MwsLCKrfXtf9zc3Pxn//8B6tXr7b7Xe3fvx/5+fnYvHkzmjVrhvDw8Gv2/++//17tVzYEBQUhIyPD7sVQbfr/6NGjyM3Nxbx58zB06FB07dq1yl/fe/XqhR9++MHhC6sKjz32GNasWYP3338fHTp0wE033VTjc5Nrc3Nzwz/+8Q+89NJLttcKO3bswN13342HH34YvXv3Rvv27TV/zUi3bt1w+vRpu/1Z5ROzdOvWDQcPHrTr0x07dsDNzc120hORVN7+H3/8Ed26dXN439rO1mvtl2ualUFBQbh06ZLd768286I2r7tqeq0CWOfF1q1bsWTJEpSWluLee++t8bllxOAkkUWLFqG4uBiRkZH4/vvvcfr0aWzcuBEjRoxA69at7c70VhtPPPEEjh49iueffx7Hjh3Dv//9b9sZYur6di4/Pz8EBATg/fffx4kTJ7Bt2zbExcXV6bEqmEwmrFixAseOHcPQoUPxzTff4Ndff8WhQ4cwZ84c3H333Xb3P3nypN1gO3DggMMXXMuWLcPAgQNxyy23oEePHrbLLbfcggEDBmDZsmXw9vbG888/j+eeew4fffQR0tLS8OOPP9r+mjdhwgSEhoZi7Nix2LFjB3799VesXbsWu3btAgD86U9/wt69e/HRRx/h+PHjmDVrFo4cOVJjzR07doTFYsG7776LX3/9FR9//LHtpBEVpk+fjp9++glTp07FoUOHcPToUcTHxyMnJ8d2nz//+c/4/fff8cEHHxj2r0dG8vXXXyM/Px9/+ctf7P5N9+jRA+PGjbP9uw0PD7f1SU5Oju3sixUhISMjw7bj7dSpk+1DyAcPHsSf//xnuz9ghIeHIzo6Go8++ii++uornDx5Etu3b8e///3vKtv31ltv4aGHHsKf/vQnTUeQFi9ejLKyMgwcOBBr167F8ePHkZKSgnfeeafK223OnDlTpf8d/fHm448/RkBAAB544AG731Pv3r1x55132n5XL7/8Mt5++2288847OH78OJKTk/Huu+8CAIYNG4ZbbrkF48aNw5YtW3Dy5EkkJiZi48aNAKxnKsvOzsabb76JtLQ0LF68GImJiTXW26ZNG3h6etr6f/369Zg9e7bdfWJjY3Hx4kU8+OCD2Lt3L44fP46PP/7Y7i1RFUetXnvtNUyaNKnWv29ybffffz/c3d1t71Lo1KkTtmzZgp07dyIlJQVPPPEEMjMzNT3m8OHD0blzZ0RHR+PgwYP44YcfqpxM6qGHHoK3tzeio6Nx5MgRfPvtt5g2bRoeeeQR2wmVRPL5559j+fLlOHbsGGbNmoU9e/ZUOZFFhdrO1lmzZuGzzz7DrFmzkJKSgsOHD+ONN94AUPOsHDRoEJo0aYJ//OMfSEtLw6effurwrH2V1eZ1V02vVQBr8L3xxhvx/PPPY8KECbV+N4F0nPj5KmoAp06dsn2Y2Gw2K2FhYcq0adOUnJwcu/s5+pC0o5My/Oc//1E6duyoeHl5KbfeeqsSHx+vAFCuXLmiKIrjk0PU9GHnLVu2KN26dVO8vLyUXr16Kdu3b7f7AKnWk0NUSE1NVaKiopTrrrtO8fT0VNq2batMmDDB7qQRABxefvjhB7vHKi4uVgICApQ333zT4fO/8cYbSnBwsFJSUqKUlZUpr732mtK2bVvFbDYrbdq0UV5//XXbfU+dOqWMGzdOad68udKkSRMlIiJC2b17t+32mTNnKiEhIUqLFi2Up59+WomNja1ycojKtSqK9YQfrVq1Unx8fJTIyEjlo48+sjtxh6Ioyvbt25UhQ4YoXl5eSsuWLZXIyEi72xVFUR555BHF39/f9qFPktddd92l3HnnnQ5vqzjJwsGDB5WioiJl3LhxSsuWLRUAyooVKxRFUZT169crHTt2VDw8PGw9ffLkSeW2225TfHx8lLCwMGXRokVV/s1euXJFefrpp5VWrVopnp6eSseOHZXly5criqKeHOLqf5fTpk1TWrVqVe1JFRydVOXs2bPKk08+qbRt21bx9PRUWrdurfzf//2f3Qez27Zt67D/P/744yrP0bNnT2Xq1KkOn3/NmjWKp6enkp2drSiKoiQkJChdunRRzGaz0qpVK2XatGm2++bm5iqTJk1SAgICFG9vb6VHjx7K119/bbs9Pj5eCQsLU5o2bapERUUpc+bMqXJyiMq1KoqifPrpp0p4eLji5eWlDB48WFm/fn2VuXnw4EFl5MiRSpMmTZRmzZopQ4cOVdLS0uweZ8aMGYq7u7ty9uxZh7WSa6vu38/cuXOVoKAgpaCgQMnNzVXuvvtuxdfXVwkODlZeeuklJSoqym6do/3Q3XffrURHR9t+Tk1NVW6++WbF09NT6dy5s7Jx48YqJ5Q5dOiQcttttyne3t6Kv7+/MnnyZNsJTarbXkfPXdOJXqqru7rHdHRyiMWLFysjRoxQvLy8lPDwcGXNmjXVPl5tZ6uiWE/E0qdPH8XT01MJDAxU7r33Xtt9rzUrFcV6MoiOHTsqPj4+yl133aW8//77VU4O4ejEPjW97lKUml+rKIqiLFu2TAGg7Nmzp9rfhexMitKAn6wl6cyZMwcJCQk4ffq0szeFdHL77bfjhhtu0PzBWSJyfX/5y1+QnZ1t99UEREZnMpnw5ZdfVvmeRaObPXs2Pv/8cxw6dMjZm+I0Hs7eABLbkiVLMGDAAAQEBGDHjh2YP39+tYeqybXk5+dj+/bt2L59O5YsWeLszSGiRnThwgUcPnwYn376KUMTEV1TQUEBTp06hUWLFuG1115z9uY4FYMTXdPx48fx2muvIS8vD23atMEzzzyD6dOnO3uzSAd9+/ZFfn4+3njjDSE/mEtEDefuu+/Gnj17MGXKFIwYMcLZm0NEAouNjcVnn32GsWPHGv7z0HyrHhERERERUQ14Vj0iIiIiIqIaMDgRERERERHVgMGJiIiIiIioBgxORERERERENWBwIiIiIiIiqgGDExERERERUQ0YnIiIiIiIiGrA4ERERERERFQDBiciIiIiIqIa/D/Khke17rUFuQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {\n",
    "    'Original ICL Accuracy' : df['correct'].value_counts(),\n",
    "    'Attack ICL Accuracy' : df['attack_correct'].value_counts(),\n",
    "    'Random Flip Accuracy' : df['random_flip_correct'].value_counts()\n",
    "}\n",
    "\n",
    "# normalize the results\n",
    "for key in results:\n",
    "    results[key] = results[key] / results[key].sum()\n",
    "\n",
    "# plot the bar chart\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_bar(results):\n",
    "    labels = ['Original ICL Accuracy', 'Attack ICL Accuracy', 'Random Flip Accuracy']\n",
    "    correct = [results['Original ICL Accuracy'][True], results['Attack ICL Accuracy'][True], results['Random Flip Accuracy'][True]]\n",
    "    incorrect = [results['Original ICL Accuracy'][False], results['Attack ICL Accuracy'][False], results['Random Flip Accuracy'][False]]\n",
    "\n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    rects1 = ax.bar(x - width/2, correct, width, label='Correct', hatch='//', edgecolor='black')\n",
    "    rects2 = ax.bar(x + width/2, incorrect, width, label='Incorrect', hatch='//', edgecolor='black')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Accuracy')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "plot_bar(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compute_label_icl_example_dist(row):\n",
    "    if row['result_type'] == 'Skipped':\n",
    "        return {}\n",
    "    \n",
    "    modified = row['perturbed_text']\n",
    "    mod_q, mod_icl_examples = get_demo_and_question(modified)\n",
    "\n",
    "    return dict(Counter([e[2] for e in mod_icl_examples]))\n",
    "\n",
    "df['attack_demonstrations_dist'] = df.apply(compute_label_icl_example_dist, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_attack = df[df['result_type'] == 'Successful']\n",
    "\n",
    "def get_the_label_dist(row):\n",
    "    demo_dist = row['attack_demonstrations_dist']\n",
    "    print(demo_dist)\n",
    "    if demo_dist == {}:\n",
    "        return {}\n",
    "    correct_answer = 'false' if row['ground_truth_output'] == 0 else 'true'\n",
    "\n",
    "    return {correct_answer: demo_dist[correct_answer]}\n",
    "\n",
    "successful_attack['correct_label_dist'] = successful_attack.apply(get_the_label_dist, axis=1)\n",
    "\n",
    "mapping = {0: 'false', 1: 'true'}\n",
    "\n",
    "# measure the correct_label_dist based on ground_truth_output and plot them on a line chart\n",
    "# successful_attack = successful_attack['correct_label_dist'].apply(lambda x: {mapping[k]: v for k, v in x.items()})\n",
    "\n",
    "\n",
    "buckets = {'true': [], 'false': []}\n",
    "for i, row in successful_attack.iterrows():\n",
    "    for k, v in row['correct_label_dist'].items():\n",
    "        buckets[k].append(v-8)\n",
    "\n",
    "# draw them on a 2d bar chart\n",
    "\n",
    "# final_bucket = buckets['true'] + [-1 * v for v in buckets['false']]\n",
    "\n",
    "# plot the histogram with larger than zero as green and smaller than zero as red\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_histogram(buckets):\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    plt.hist(buckets['true'], bins=20, color='green', alpha=0.5, label='True')\n",
    "    plt.hist(buckets['false'], bins=20, color='red', alpha=0.5, label='False')\n",
    "    plt.title(\"Histogram of Successful Attacks\")\n",
    "    plt.xlabel(\"Number of Demonstrations\")\n",
    "    # make x axis as discrete values\n",
    "    plt.xticks(np.arange(-16, 17, 1))\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "plot_histogram(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true': 11, 'false': 5}\n",
      "{'true': 10, 'false': 6}\n",
      "{'true': 6, 'false': 10}\n",
      "{'false': 12, 'true': 4}\n",
      "{'true': 4, 'false': 12}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 2, 'false': 14}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 12, 'false': 4}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 8, 'false': 8}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 2, 'false': 14}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 4, 'false': 12}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 10, 'false': 6}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 16}\n",
      "{'true': 12, 'false': 4}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 13, 'false': 3}\n",
      "{'true': 14, 'false': 2}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 10, 'false': 6}\n",
      "{'true': 13, 'false': 3}\n",
      "{'false': 10, 'true': 6}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 3, 'false': 13}\n",
      "{'true': 15, 'false': 1}\n",
      "{'true': 15, 'false': 1}\n",
      "{'true': 14, 'false': 2}\n",
      "{'true': 11, 'false': 5}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 11, 'false': 5}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 13, 'false': 3}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 8, 'false': 8}\n",
      "{'true': 10, 'false': 6}\n",
      "{'false': 10, 'true': 6}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 16}\n",
      "{'false': 13, 'true': 3}\n",
      "{'false': 13, 'true': 3}\n",
      "{'true': 12, 'false': 4}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 11, 'false': 5}\n",
      "{'false': 10, 'true': 6}\n",
      "{'true': 11, 'false': 5}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 11, 'false': 5}\n",
      "{'false': 12, 'true': 4}\n",
      "{'true': 15, 'false': 1}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 12, 'false': 4}\n",
      "{'true': 9, 'false': 7}\n",
      "{'false': 1, 'true': 15}\n",
      "{'true': 13, 'false': 3}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 5, 'false': 11}\n",
      "{'false': 10, 'true': 6}\n",
      "{'true': 2, 'false': 14}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 4, 'false': 12}\n",
      "{'true': 11, 'false': 5}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 14, 'false': 2}\n",
      "{'true': 16}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 10, 'false': 6}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 12, 'false': 4}\n",
      "{'true': 13, 'false': 3}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 5, 'false': 11}\n",
      "{'false': 11, 'true': 5}\n",
      "{'true': 4, 'false': 12}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 10, 'false': 6}\n",
      "{'false': 1, 'true': 15}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 7, 'false': 9}\n",
      "{'false': 11, 'true': 5}\n",
      "{'true': 3, 'false': 13}\n",
      "{'true': 15, 'false': 1}\n",
      "{'true': 7, 'false': 9}\n",
      "{'false': 12, 'true': 4}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 11, 'false': 5}\n",
      "{'true': 16}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 14, 'false': 2}\n",
      "{'true': 11, 'false': 5}\n",
      "{'true': 11, 'false': 5}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 10, 'false': 6}\n",
      "{'false': 10, 'true': 6}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 10, 'false': 6}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 10, 'false': 6}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 15, 'false': 1}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 15, 'false': 1}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 10, 'false': 6}\n",
      "{'true': 12, 'false': 4}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 14, 'false': 2}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 13, 'false': 3}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 3, 'false': 13}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 12, 'false': 4}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 2, 'false': 14}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 14, 'false': 2}\n",
      "{'true': 11, 'false': 5}\n",
      "{'true': 13, 'false': 3}\n",
      "{'true': 10, 'false': 6}\n",
      "{'true': 14, 'false': 2}\n",
      "{'true': 10, 'false': 6}\n",
      "{'true': 11, 'false': 5}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 5, 'false': 11}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 11, 'false': 5}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 11, 'false': 5}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 9, 'false': 7}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 6, 'false': 10}\n",
      "{'true': 7, 'false': 9}\n",
      "{'true': 6, 'false': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94918/3728017454.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  successful_attack['correct_label_dist'] = successful_attack.apply(get_the_label_dist, axis=1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'final_bucket' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/ceph_rbd/mvp/src/test.ipynb Cell 31\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpod_2/mnt/ceph_rbd/mvp/src/test.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     plt\u001b[39m.\u001b[39mlegend(loc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mupper right\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpod_2/mnt/ceph_rbd/mvp/src/test.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bpod_2/mnt/ceph_rbd/mvp/src/test.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m plot_histogram(final_bucket)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_bucket' is not defined"
     ]
    }
   ],
   "source": [
    "successful_attack = df[df['result_type'] == 'Successful']\n",
    "\n",
    "def get_the_label_dist(row):\n",
    "    demo_dist = row['attack_demonstrations_dist']\n",
    "    print(demo_dist)\n",
    "    if demo_dist == {}:\n",
    "        return {}\n",
    "    correct_answer = 'false' if row['ground_truth_output'] == 0 else 'true'\n",
    "\n",
    "    return {correct_answer: demo_dist[correct_answer]}\n",
    "\n",
    "successful_attack['correct_label_dist'] = successful_attack.apply(get_the_label_dist, axis=1)\n",
    "\n",
    "mapping = {0: 'false', 1: 'true'}\n",
    "\n",
    "# measure the correct_label_dist based on ground_truth_output and plot them on a line chart\n",
    "# successful_attack = successful_attack['correct_label_dist'].apply(lambda x: {mapping[k]: v for k, v in x.items()})\n",
    "\n",
    "\n",
    "buckets = {'true': [], 'false': []}\n",
    "for i, row in successful_attack.iterrows():\n",
    "    for k, v in row['correct_label_dist'].items():\n",
    "        buckets[k].append(v-8)\n",
    "\n",
    "# draw them on a 2d bar chart\n",
    "\n",
    "# final_bucket = buckets['true'] + [-1 * v for v in buckets['false']]\n",
    "\n",
    "# plot the histogram with larger than zero as green and smaller than zero as red\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_histogram(buckets):\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    plt.hist(buckets['true'], bins=20, color='green', alpha=0.5, label='True')\n",
    "    plt.hist(buckets['false'], bins=20, color='red', alpha=0.5, label='False')\n",
    "    plt.title(\"Histogram of Successful Attacks\")\n",
    "    plt.xlabel(\"Number of Demonstrations\")\n",
    "    # make x axis as discrete values\n",
    "    plt.xticks(np.arange(-16, 17, 1))\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "plot_histogram(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('the amish community in pennsylvania, which numbers about 55,000, lives an agrarian lifestyle, shunning technological advances like electricity and automobiles. and many say their insular lifestyle gives them a sense that they are protected from the violence of american society. but as residents gathered near the school, some wearing traditional garb and arriving in horse-drawn buggies, they said that sense of safety had been shattered. \"if someone snaps and wants to do something stupid, there\\'s no distance that\\'s going to stop them,\" said jake king, 56, an amish lantern maker who knew several families whose children had been shot.', 'pennsylvania has the biggest amish community in the u.s.', ''), [('george herbert walker bush (born june 12, 1924) is the former 41st president of the united states of america. almost immediately upon his return from the war in december 1944, george bush married barbara pierce.', \"the name of george h.w. bush's wife is barbara.\", 'true'), ('it rewrites the rules of global trade, established by the general agreement on tariffs and trade, or gatt, in 1947, and modified in multiple rounds of negotiations since then.', 'gatt was formed in 1947.', 'false'), ('us military forces are evacuating u.s. citizens and citizens of 72 other countries from liberia at the request of the u.s.', 'u.s. military evacuated u.s. citizens.', 'true'), (\"floods are one of europe's most widespread disasters. major flooding has occurred nearly every year somewhere on our continent during the last few decades.\", 'flooding in europe causes major economic losses.', 'false'), ('rock stars aerosmith are to hold a free concert in hawaii to placate angry fans who brought a legal case against them. the walk this way hitmakers cancelled a sold-out show in maui two years ago, leaving hundreds of fans out of pocket. they filed a class action case, which claimed the band had pulled out in favour of a bigger gig in chicago and a private show for car dealers in oahu. lawyers for the would-be concert-goers said aerosmith had now agreed to put on a new show, and would pay all expenses.', 'aerosmith are a rock band.', 'true'), ('one reason for increased osteoporosis in developed countries is the sodium-potassium imbalance.', 'dietary intake of potassium prevents osteoporosis.', 'false'), ('jerusalem, april 2 (xinhua) -- israel\\'s new foreign minister avigdor lieberman was questioned by police on thursday over several criminal allegations, local news service ynet reported.  national fraud unit investigators questioned the deputy premier, who is suspected of bribery, money laundering, fraud and breach of trust, for over seven hours, and another round is in the cards, said the report.  \"lieberman answered all of the questions he was asked, and will continue to do so in the future,\" his attorney yaron kostelitz was quoted as saying.', 'avigdor lieberman is the foreign minister of israel.', 'true'), ('other friends were not surprised at his death. \"i wasn\\'t surprised,\" said george stranahan, a former owner of the woody creek tavern, a favourite haunt of thompson. \"i never expected hunter to die in a hospital bed with tubes coming out of him.\" neighbours have said how his broken leg had prevented him from leaving his house as often as he had liked to. one neighbour and long-standing friend, mike cleverly, said thompson was clearly hobbled by the broken leg. \"medically speaking, he\\'s had a rotten year.\"', 'the woody creek tavern is owned by george stranahan.', 'false'), ('witching hour passed and potter fans poured into bookshops around the world on saturday, snatching up copies of the latest instalment in the series that promises to be the fastest-selling book in history.', 'potter fans rushed to tills in order to purchase the book.', 'true'), (\"alan mulally, boeing's head of the unit, said at the start of the strike that it may cause delivery delays that would give airbus sas an advantage in what is the strongest commercial aircraft market in five years.\", 'alan mulally is the owner of boeing.', 'false'), (\"to promote the simpsons movie that will be released july 26, 2007, over a dozen 7-elevens in the united states have been transformed into kwik-e-marts, the grocery store from the popular tv series. most of the other 7-eleven stores will also sell products with brands reminding of the simpsons, such as buzz cola, krustyo's cereal, squishees, and bart simpson's favourite comic book radioactive man, but not duff beer, homer's favourite drink.\", 'the simpsons is a show broadcast in america.', 'true'), ('he is like some great writers, from charles dickens to william faulkner to gabriel garcia marquez', 'gabriel garcia marquez is a nobel prize winner.', 'false'), ('colin l. powell and laura bush, wife of gov. george w. bush, are to speak on the opening night in philadelphia, while the democrats have tentative plans to have president clinton and hillary rodham clinton address the delegates on the first night in los angeles.', \"the name of george w. bush's wife is laura.\", 'true'), ('after insulting the un committee insinuating they were irrelavant, bush no sooner had approval from congress to use \"force/war\" if hussein did not permit unfettered access for inspections - and the war ships were moved into place on the gulf.', 'hussein gives un inspectors unfettered access.', 'false'), (\"while local cab drivers had compliments, not everyone appreciated the company. the chicago cubs decided to cancel their booking after hearing about the con, and j.j. hardy of the milwaukee brewers reported being kept up by fans on wednesday night. the brewers lost their game the following day. the convention closed with next year's date ―june 26-29 ―along with the announcement of a guest\", 'j.j. hardy has a contract with the milwaukee brewers.', 'true'), ('for a western european country, the birth rate in finland is high.', 'finland is the european country with the highest birth rate.', 'false')])\n",
      "(('the amish community in pennsylvania, which numbers about 55,000, lives an agrarian lifestyle, shunning technological advances like electricity and automobiles. and many say their insular lifestyle gives them a sense that they are protected from the violence of american society. but as residents gathered near the school, some wearing traditional garb and arriving in horse-drawn buggies, they said that sense of safety had been shattered. \"if someone snaps and wants to do something stupid, there\\'s no distance that\\'s going to stop them,\" said jake king, 56, an amish lantern maker who knew several families whose children had been shot.', 'pennsylvania has the biggest amish community in the u.s.', ''), [('george herbert walker bush (born june 12, 1924) is the former 41st president of the united states of america. almost immediately upon his return from the war in december 1944, george bush married barbara pierce.', \"the name of george h.w. bush's wife is barbara.\", 'true'), ('it rewrites the rules of global trade, established by the general agreement on tariffs and trade, or gatt, in 1947, and modified in multiple rounds of negotiations since then.', 'gatt was formed in 1947.', 'false'), ('us military forces are evacuating u.s. citizens and citizens of 72 other countries from liberia at the request of the u.s.', 'u.s. military evacuated u.s. citizens.', 'true'), (\"floods are one of europe's most widespread disasters. major flooding has occurred nearly every year somewhere on our continent during the last few decades.\", 'flooding in europe causes major economic losses.', 'false'), ('rock stars aerosmith are to hold a free concert in hawaii to placate angry fans who brought a legal case against them. the walk this way hitmakers cancelled a sold-out show in maui two years ago, leaving hundreds of fans out of pocket. they filed a class action case, which claimed the band had pulled out in favour of a bigger gig in chicago and a private show for car dealers in oahu. lawyers for the would-be concert-goers said aerosmith had now agreed to put on a new show, and would pay all expenses.', 'aerosmith are a rock band.', 'true'), ('one reason for increased osteoporosis in developed countries is the sodium-potassium imbalance.', 'dietary intake of potassium prevents osteoporosis.', 'true'), ('jerusalem, april 2 (xinhua) -- israel\\'s new foreign minister avigdor lieberman was questioned by police on thursday over several criminal allegations, local news service ynet reported.  national fraud unit investigators questioned the deputy premier, who is suspected of bribery, money laundering, fraud and breach of trust, for over seven hours, and another round is in the cards, said the report.  \"lieberman answered all of the questions he was asked, and will continue to do so in the future,\" his attorney yaron kostelitz was quoted as saying.', 'avigdor lieberman is the foreign minister of israel.', 'true'), ('other friends were not surprised at his death. \"i wasn\\'t surprised,\" said george stranahan, a former owner of the woody creek tavern, a favourite haunt of thompson. \"i never expected hunter to die in a hospital bed with tubes coming out of him.\" neighbours have said how his broken leg had prevented him from leaving his house as often as he had liked to. one neighbour and long-standing friend, mike cleverly, said thompson was clearly hobbled by the broken leg. \"medically speaking, he\\'s had a rotten year.\"', 'the woody creek tavern is owned by george stranahan.', 'true'), ('witching hour passed and potter fans poured into bookshops around the world on saturday, snatching up copies of the latest instalment in the series that promises to be the fastest-selling book in history.', 'potter fans rushed to tills in order to purchase the book.', 'true'), (\"alan mulally, boeing's head of the unit, said at the start of the strike that it may cause delivery delays that would give airbus sas an advantage in what is the strongest commercial aircraft market in five years.\", 'alan mulally is the owner of boeing.', 'false'), (\"to promote the simpsons movie that will be released july 26, 2007, over a dozen 7-elevens in the united states have been transformed into kwik-e-marts, the grocery store from the popular tv series. most of the other 7-eleven stores will also sell products with brands reminding of the simpsons, such as buzz cola, krustyo's cereal, squishees, and bart simpson's favourite comic book radioactive man, but not duff beer, homer's favourite drink.\", 'the simpsons is a show broadcast in america.', 'true'), ('he is like some great writers, from charles dickens to william faulkner to gabriel garcia marquez', 'gabriel garcia marquez is a nobel prize winner.', 'false'), ('colin l. powell and laura bush, wife of gov. george w. bush, are to speak on the opening night in philadelphia, while the democrats have tentative plans to have president clinton and hillary rodham clinton address the delegates on the first night in los angeles.', \"the name of george w. bush's wife is laura.\", 'true'), ('after insulting the un committee insinuating they were irrelavant, bush no sooner had approval from congress to use \"force/war\" if hussein did not permit unfettered access for inspections - and the war ships were moved into place on the gulf.', 'hussein gives un inspectors unfettered access.', 'false'), (\"while local cab drivers had compliments, not everyone appreciated the company. the chicago cubs decided to cancel their booking after hearing about the con, and j.j. hardy of the milwaukee brewers reported being kept up by fans on wednesday night. the brewers lost their game the following day. the convention closed with next year's date ―june 26-29 ―along with the announcement of a guest\", 'j.j. hardy has a contract with the milwaukee brewers.', 'true'), ('for a western european country, the birth rate in finland is high.', 'finland is the european country with the highest birth rate.', 'false')])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'george herbert walker bush (born june 12, 1924) is the former 41st president of the united states of america. almost immediately upon his return from the war in december 1944, george bush married barbara pierce.\\n The question is: the name of george h.w. bush\\'s wife is barbara.. True or False?\\nThe Answer is: true\\n\\nit rewrites the rules of global trade, established by the general agreement on tariffs and trade, or gatt, in 1947, and modified in multiple rounds of negotiations since then.\\n The question is: gatt was formed in 1947.. True or False?\\nThe Answer is: false\\n\\nus military forces are evacuating u.s. citizens and citizens of 72 other countries from liberia at the request of the u.s.\\n The question is: u.s. military evacuated u.s. citizens.. True or False?\\nThe Answer is: true\\n\\nfloods are one of europe\\'s most widespread disasters. major flooding has occurred nearly every year somewhere on our continent during the last few decades.\\n The question is: flooding in europe causes major economic losses.. True or False?\\nThe Answer is: false\\n\\nrock stars aerosmith are to hold a free concert in hawaii to placate angry fans who brought a legal case against them. the walk this way hitmakers cancelled a sold-out show in maui two years ago, leaving hundreds of fans out of pocket. they filed a class action case, which claimed the band had pulled out in favour of a bigger gig in chicago and a private show for car dealers in oahu. lawyers for the would-be concert-goers said aerosmith had now agreed to put on a new show, and would pay all expenses.\\n The question is: aerosmith are a rock band.. True or False?\\nThe Answer is: true\\n\\none reason for increased osteoporosis in developed countries is the sodium-potassium imbalance.\\n The question is: dietary intake of potassium prevents osteoporosis.. True or False?\\nThe Answer is: true\\n\\njerusalem, april 2 (xinhua) -- israel\\'s new foreign minister avigdor lieberman was questioned by police on thursday over several criminal allegations, local news service ynet reported.  national fraud unit investigators questioned the deputy premier, who is suspected of bribery, money laundering, fraud and breach of trust, for over seven hours, and another round is in the cards, said the report.  \"lieberman answered all of the questions he was asked, and will continue to do so in the future,\" his attorney yaron kostelitz was quoted as saying.\\n The question is: avigdor lieberman is the foreign minister of israel.. True or False?\\nThe Answer is: true\\n\\nother friends were not surprised at his death. \"i wasn\\'t surprised,\" said george stranahan, a former owner of the woody creek tavern, a favourite haunt of thompson. \"i never expected hunter to die in a hospital bed with tubes coming out of him.\" neighbours have said how his broken leg had prevented him from leaving his house as often as he had liked to. one neighbour and long-standing friend, mike cleverly, said thompson was clearly hobbled by the broken leg. \"medically speaking, he\\'s had a rotten year.\"\\n The question is: the woody creek tavern is owned by george stranahan.. True or False?\\nThe Answer is: true\\n\\nwitching hour passed and potter fans poured into bookshops around the world on saturday, snatching up copies of the latest instalment in the series that promises to be the fastest-selling book in history.\\n The question is: potter fans rushed to tills in order to purchase the book.. True or False?\\nThe Answer is: true\\n\\nalan mulally, boeing\\'s head of the unit, said at the start of the strike that it may cause delivery delays that would give airbus sas an advantage in what is the strongest commercial aircraft market in five years.\\n The question is: alan mulally is the owner of boeing.. True or False?\\nThe Answer is: false\\n\\nto promote the simpsons movie that will be released july 26, 2007, over a dozen 7-elevens in the united states have been transformed into kwik-e-marts, the grocery store from the popular tv series. most of the other 7-eleven stores will also sell products with brands reminding of the simpsons, such as buzz cola, krustyo\\'s cereal, squishees, and bart simpson\\'s favourite comic book radioactive man, but not duff beer, homer\\'s favourite drink.\\n The question is: the simpsons is a show broadcast in america.. True or False?\\nThe Answer is: true\\n\\nhe is like some great writers, from charles dickens to william faulkner to gabriel garcia marquez\\n The question is: gabriel garcia marquez is a nobel prize winner.. True or False?\\nThe Answer is: false\\n\\ncolin l. powell and laura bush, wife of gov. george w. bush, are to speak on the opening night in philadelphia, while the democrats have tentative plans to have president clinton and hillary rodham clinton address the delegates on the first night in los angeles.\\n The question is: the name of george w. bush\\'s wife is laura.. True or False?\\nThe Answer is: true\\n\\nafter insulting the un committee insinuating they were irrelavant, bush no sooner had approval from congress to use \"force/war\" if hussein did not permit unfettered access for inspections - and the war ships were moved into place on the gulf.\\n The question is: hussein gives un inspectors unfettered access.. True or False?\\nThe Answer is: false\\n\\nwhile local cab drivers had compliments, not everyone appreciated the company. the chicago cubs decided to cancel their booking after hearing about the con, and j.j. hardy of the milwaukee brewers reported being kept up by fans on wednesday night. the brewers lost their game the following day. the convention closed with next year\\'s date ―june 26-29 ―along with the announcement of a guest\\n The question is: j.j. hardy has a contract with the milwaukee brewers.. True or False?\\nThe Answer is: true\\n\\nfor a western european country, the birth rate in finland is high.\\n The question is: finland is the european country with the highest birth rate.. True or False?\\nThe Answer is: false\\n\\nthe amish community in pennsylvania, which numbers about 55,000, lives an agrarian lifestyle, shunning technological advances like electricity and automobiles. and many say their insular lifestyle gives them a sense that they are protected from the violence of american society. but as residents gathered near the school, some wearing traditional garb and arriving in horse-drawn buggies, they said that sense of safety had been shattered. \"if someone snaps and wants to do something stupid, there\\'s no distance that\\'s going to stop them,\" said jake king, 56, an amish lantern maker who knew several families whose children had been shot.\\n The question is: pennsylvania has the biggest amish community in the u.s.. True or False?\\nThe Answer is:'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(get_demo_and_question(df.iloc[3]['original_text']))\n",
    "print(get_demo_and_question(df.iloc[3]['perturbed_text']))\n",
    "\n",
    "get_prompt(df.iloc[3]['original_text'])\n",
    "get_prompt(df.iloc[3]['perturbed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>original_score</th>\n",
       "      <th>perturbed_score</th>\n",
       "      <th>original_output</th>\n",
       "      <th>perturbed_output</th>\n",
       "      <th>ground_truth_output</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>result_type</th>\n",
       "      <th>attack_demonstrations_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[[Premise]]]]: dana reeve, the widow of the ...</td>\n",
       "      <td>[[[[Premise]]]]: dana reeve, the widow of the ...</td>\n",
       "      <td>0.577495</td>\n",
       "      <td>0.577495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Skipped</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[[Premise]]]]: yet, we now are discovering t...</td>\n",
       "      <td>[[[[Premise]]]]: yet, we now are discovering t...</td>\n",
       "      <td>0.629775</td>\n",
       "      <td>0.629775</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Skipped</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[[Premise]]]]: cairo is now home to some 15 ...</td>\n",
       "      <td>[[[[Premise]]]]: cairo is now home to some 15 ...</td>\n",
       "      <td>0.348645</td>\n",
       "      <td>0.531209</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>Successful</td>\n",
       "      <td>{'true': 11, 'false': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[[Premise]]]]: the amish community in pennsy...</td>\n",
       "      <td>[[[[Premise]]]]: the amish community in pennsy...</td>\n",
       "      <td>0.433981</td>\n",
       "      <td>0.542863</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>Successful</td>\n",
       "      <td>{'true': 10, 'false': 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[[Premise]]]]: security forces were on high ...</td>\n",
       "      <td>[[[[Premise]]]]: security forces were on high ...</td>\n",
       "      <td>0.370225</td>\n",
       "      <td>0.566019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>Successful</td>\n",
       "      <td>{'true': 6, 'false': 10}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  \\\n",
       "0  [[[[Premise]]]]: dana reeve, the widow of the ...   \n",
       "1  [[[[Premise]]]]: yet, we now are discovering t...   \n",
       "2  [[[[Premise]]]]: cairo is now home to some 15 ...   \n",
       "3  [[[[Premise]]]]: the amish community in pennsy...   \n",
       "4  [[[[Premise]]]]: security forces were on high ...   \n",
       "\n",
       "                                      perturbed_text  original_score  \\\n",
       "0  [[[[Premise]]]]: dana reeve, the widow of the ...        0.577495   \n",
       "1  [[[[Premise]]]]: yet, we now are discovering t...        0.629775   \n",
       "2  [[[[Premise]]]]: cairo is now home to some 15 ...        0.348645   \n",
       "3  [[[[Premise]]]]: the amish community in pennsy...        0.433981   \n",
       "4  [[[[Premise]]]]: security forces were on high ...        0.370225   \n",
       "\n",
       "   perturbed_score  original_output  perturbed_output  ground_truth_output  \\\n",
       "0         0.577495                0                 0                    1   \n",
       "1         0.629775                1                 1                    0   \n",
       "2         0.531209                1                 0                    1   \n",
       "3         0.542863                1                 0                    1   \n",
       "4         0.566019                0                 1                    0   \n",
       "\n",
       "   num_queries result_type attack_demonstrations_dist  \n",
       "0            1     Skipped                         {}  \n",
       "1            1     Skipped                         {}  \n",
       "2           46  Successful   {'true': 11, 'false': 5}  \n",
       "3           32  Successful   {'true': 10, 'false': 6}  \n",
       "4           32  Successful   {'true': 6, 'false': 10}  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "demonstration = \"\"\"\n",
    "[[[[Premise]]]]: cairo is now home to some 15 million people - a burgeoning population that produces approximately 10,000 tonnes of rubbish per day, putting an enormous strain on public services. in the past 10 years, the government has tried hard to encourage private investment in the refuse sector, but some estimate 4,000 tonnes of waste is left behind every day, festering in the heat as it waits for someone to clear it up. it is often the people in the poorest neighbourhoods that are worst affected. but in some areas they are fighting back. in shubra, one of the northern districts of the city, the residents have taken to the streets armed with dustpans and brushes to clean up public areas which have been used as public dumps.<SPLIT>[[[[Hypothesis]]]]: 15 million tonnes of rubbish are produced daily in cairo.<SPLIT>[[[[Premise_0]]]]: george herbert walker bush (born june 12, 1924) is the former 41st president of the united states of america. almost immediately upon his return from the war in december 1944, george bush married barbara pierce.<SPLIT>[[[[Hypothesis_0]]]]: the name of george h.w. bush's wife is barbara.<SPLIT>[[[[Label_0]]]]: true<SPLIT>[[[[Premise_1]]]]: it rewrites the rules of global trade, established by the general agreement on tariffs and trade, or gatt, in 1947, and modified in multiple rounds of negotiations since then.<SPLIT>[[[[Hypothesis_1]]]]: gatt was formed in 1947.<SPLIT>[[[[Label_1]]]]: false<SPLIT>[[[[Premise_2]]]]: us military forces are evacuating u.s. citizens and citizens of 72 other countries from liberia at the request of the u.s.<SPLIT>[[[[Hypothesis_2]]]]: u.s. military evacuated u.s. citizens.<SPLIT>[[[[Label_2]]]]: true<SPLIT>[[[[Premise_3]]]]: floods are one of europe's most widespread disasters. major flooding has occurred nearly every year somewhere on our continent during the last few decades.<SPLIT>[[[[Hypothesis_3]]]]: flooding in europe causes major economic losses.<SPLIT>[[[[Label_3]]]]: [[false]]<SPLIT>[[[[Premise_4]]]]: rock stars aerosmith are to hold a free concert in hawaii to placate angry fans who brought a legal case against them. the walk this way hitmakers cancelled a sold-out show in maui two years ago, leaving hundreds of fans out of pocket. they filed a class action case, which claimed the band had pulled out in favour of a bigger gig in chicago and a private show for car dealers in oahu. lawyers for the would-be concert-goers said aerosmith had now agreed to put on a new show, and would pay all expenses.<SPLIT>[[[[Hypothesis_4]]]]: aerosmith are a rock band.<SPLIT>[[[[Label_4]]]]: true<SPLIT>[[[[Premise_5]]]]: one reason for increased osteoporosis in developed countries is the sodium-potassium imbalance.<SPLIT>[[[[Hypothesis_5]]]]: dietary intake of potassium prevents osteoporosis.<SPLIT>[[[[Label_5]]]]: [[false]]<SPLIT>[[[[Premise_6]]]]: jerusalem, april 2 (xinhua) -- israel's new foreign minister avigdor lieberman was questioned by police on thursday over several criminal allegations, local news service ynet reported.  national fraud unit investigators questioned the deputy premier, who is suspected of bribery, money laundering, fraud and breach of trust, for over seven hours, and another round is in the cards, said the report.  \"\"lieberman answered all of the questions he was asked, and will continue to do so in the future,\"\" his attorney yaron kostelitz was quoted as saying.<SPLIT>[[[[Hypothesis_6]]]]: avigdor lieberman is the foreign minister of israel.<SPLIT>[[[[Label_6]]]]: true<SPLIT>[[[[Premise_7]]]]: other friends were not surprised at his death. \"\"i wasn't surprised,\"\" said george stranahan, a former owner of the woody creek tavern, a favourite haunt of thompson. \"\"i never expected hunter to die in a hospital bed with tubes coming out of him.\"\" neighbours have said how his broken leg had prevented him from leaving his house as often as he had liked to. one neighbour and long-standing friend, mike cleverly, said thompson was clearly hobbled by the broken leg. \"\"medically speaking, he's had a rotten year.\"\"<SPLIT>[[[[Hypothesis_7]]]]: the woody creek tavern is owned by george stranahan.<SPLIT>[[[[Label_7]]]]: false<SPLIT>[[[[Premise_8]]]]: witching hour passed and potter fans poured into bookshops around the world on saturday, snatching up copies of the latest instalment in the series that promises to be the fastest-selling book in history.<SPLIT>[[[[Hypothesis_8]]]]: potter fans rushed to tills in order to purchase the book.<SPLIT>[[[[Label_8]]]]: true<SPLIT>[[[[Premise_9]]]]: alan mulally, boeing's head of the unit, said at the start of the strike that it may cause delivery delays that would give airbus sas an advantage in what is the strongest commercial aircraft market in five years.<SPLIT>[[[[Hypothesis_9]]]]: alan mulally is the owner of boeing.<SPLIT>[[[[Label_9]]]]: false<SPLIT>[[[[Premise_10]]]]: to promote the simpsons movie that will be released july 26, 2007, over a dozen 7-elevens in the united states have been transformed into kwik-e-marts, the grocery store from the popular tv series. most of the other 7-eleven stores will also sell products with brands reminding of the simpsons, such as buzz cola, krustyo's cereal, squishees, and bart simpson's favourite comic book radioactive man, but not duff beer, homer's favourite drink.<SPLIT>[[[[Hypothesis_10]]]]: the simpsons is a show broadcast in america.<SPLIT>[[[[Label_10]]]]: true<SPLIT>[[[[Premise_11]]]]: he is like some great writers, from charles dickens to william faulkner to gabriel garcia marquez: the insistence on the value of the local leads to the universal.<SPLIT>[[[[Hypothesis_11]]]]: gabriel garcia marquez is a nobel prize winner.<SPLIT>[[[[Label_11]]]]: false<SPLIT>[[[[Premise_12]]]]: colin l. powell and laura bush, wife of gov. george w. bush, are to speak on the opening night in philadelphia, while the democrats have tentative plans to have president clinton and hillary rodham clinton address the delegates on the first night in los angeles.<SPLIT>[[[[Hypothesis_12]]]]: the name of george w. bush's wife is laura.<SPLIT>[[[[Label_12]]]]: true<SPLIT>[[[[Premise_13]]]]: after insulting the un committee insinuating they were irrelavant, bush no sooner had approval from congress to use \"\"force/war\"\" if hussein did not permit unfettered access for inspections - and the war ships were moved into place on the gulf.<SPLIT>[[[[Hypothesis_13]]]]: hussein gives un inspectors unfettered access.<SPLIT>[[[[Label_13]]]]: [[false]]<SPLIT>[[[[Premise_14]]]]: while local cab drivers had compliments, not everyone appreciated the company. the chicago cubs decided to cancel their booking after hearing about the con, and j.j. hardy of the milwaukee brewers reported being kept up by fans on wednesday night. the brewers lost their game the following day. the convention closed with next year's date ―june 26-29 ―along with the announcement of a guest: disney animator floyd norman. the event's theme will be \"\"it's a jungle out there!\"\".<SPLIT>[[[[Hypothesis_14]]]]: j.j. hardy has a contract with the milwaukee brewers.<SPLIT>[[[[Label_14]]]]: true<SPLIT>[[[[Premise_15]]]]: for a western european country, the birth rate in finland is high.<SPLIT>[[[[Hypothesis_15]]]]: finland is the european country with the highest birth rate.<SPLIT>[[[[Label_15]]]]: false\"\"\"\n",
    "\n",
    "demons = demonstration.split(\"<SPLIT>\")\n",
    "demons = [demon.split(\":\")[1].strip('\\n ').strip('[]') for demon in demons]\n",
    "\n",
    "question = (demons[0], demons[1], \"\")\n",
    "icl_examples = []\n",
    "demons = demons[2:]\n",
    "for i in range(len(demons) // 3):\n",
    "    icl_examples.append((demons[i * 3], demons[i * 3 + 1], demons[i * 3 + 2]))\n",
    "\n",
    "template = \"{}\\n The question is: {}. True or False?\\nThe Answer is: {}\"\n",
    "verbalizer = {0: \"true\", 1: \"false\"}\n",
    "\n",
    "demos = []\n",
    "for demo in icl_examples:\n",
    "    demos.append(template.format(demo[0], demo[1], demo[2]))\n",
    "q = template.format(question[0], question[1], \"\").strip()\n",
    "\n",
    "prompt = \"\\n\\n\".join(demos) + \"\\n\\n\" + q\n",
    "\n",
    "tokenized = tokenizer(prompt, return_tensors=\"pt\", padding=True).to('cuda')\n",
    "logits = model(**tokenized).logits\n",
    "output = logits[:, -1, :].detach().cpu()\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "label_id = [tokenizer.encode(verbalizer[0])[1], tokenizer.encode(verbalizer[1])[1]]\n",
    "\n",
    "print(tokenizer.decode(output.argmax(dim=-1)))\n",
    "output_label = output[:, label_id].softmax(dim=-1)\n",
    "output_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "george herbert walker bush (born june 12, 1924) is the former 41st president of the united states of america. almost immediately upon his return from the war in december 1944, george bush married barbara pierce.\n",
      " The question is: the name of george h.w. bush's wife is barbara.. True or False?\n",
      "The Answer is: true\n",
      "\n",
      "it rewrites the rules of global trade, established by the general agreement on tariffs and trade, or gatt, in 1947, and modified in multiple rounds of negotiations since then.\n",
      " The question is: gatt was formed in 1947.. True or False?\n",
      "The Answer is: false\n",
      "\n",
      "us military forces are evacuating u.s. citizens and citizens of 72 other countries from liberia at the request of the u.s.\n",
      " The question is: u.s. military evacuated u.s. citizens.. True or False?\n",
      "The Answer is: true\n",
      "\n",
      "floods are one of europe's most widespread disasters. major flooding has occurred nearly every year somewhere on our continent during the last few decades.\n",
      " The question is: flooding in europe causes major economic losses.. True or False?\n",
      "The Answer is: true\n",
      "\n",
      "rock stars aerosmith are to hold a free concert in hawaii to placate angry fans who brought a legal case against them. the walk this way hitmakers cancelled a sold-out show in maui two years ago, leaving hundreds of fans out of pocket. they filed a class action case, which claimed the band had pulled out in favour of a bigger gig in chicago and a private show for car dealers in oahu. lawyers for the would-be concert-goers said aerosmith had now agreed to put on a new show, and would pay all expenses.\n",
      " The question is: aerosmith are a rock band.. True or False?\n",
      "The Answer is: true\n",
      "\n",
      "one reason for increased osteoporosis in developed countries is the sodium-potassium imbalance.\n",
      " The question is: dietary intake of potassium prevents osteoporosis.. True or False?\n",
      "The Answer is: true\n",
      "\n",
      "jerusalem, april 2 (xinhua) -- israel's new foreign minister avigdor lieberman was questioned by police on thursday over several criminal allegations, local news service ynet reported.  national fraud unit investigators questioned the deputy premier, who is suspected of bribery, money laundering, fraud and breach of trust, for over seven hours, and another round is in the cards, said the report.  \"\"lieberman answered all of the questions he was asked, and will continue to do so in the future,\"\" his attorney yaron kostelitz was quoted as saying.\n",
      " The question is: avigdor lieberman is the foreign minister of israel.. True or False?\n",
      "The Answer is: true\n",
      "\n",
      "other friends were not surprised at his death. \"\"i wasn't surprised,\"\" said george stranahan, a former owner of the woody creek tavern, a favourite haunt of thompson. \"\"i never expected hunter to die in a hospital bed with tubes coming out of him.\"\" neighbours have said how his broken leg had prevented him from leaving his house as often as he had liked to. one neighbour and long-standing friend, mike cleverly, said thompson was clearly hobbled by the broken leg. \"\"medically speaking, he's had a rotten year.\"\"\n",
      " The question is: the woody creek tavern is owned by george stranahan.. True or False?\n",
      "The Answer is: false\n",
      "\n",
      "witching hour passed and potter fans poured into bookshops around the world on saturday, snatching up copies of the latest instalment in the series that promises to be the fastest-selling book in history.\n",
      " The question is: potter fans rushed to tills in order to purchase the book.. True or False?\n",
      "The Answer is: true\n",
      "\n",
      "alan mulally, boeing's head of the unit, said at the start of the strike that it may cause delivery delays that would give airbus sas an advantage in what is the strongest commercial aircraft market in five years.\n",
      " The question is: alan mulally is the owner of boeing.. True or False?\n",
      "The Answer is: false\n",
      "\n",
      "to promote the simpsons movie that will be released july 26, 2007, over a dozen 7-elevens in the united states have been transformed into kwik-e-marts, the grocery store from the popular tv series. most of the other 7-eleven stores will also sell products with brands reminding of the simpsons, such as buzz cola, krustyo's cereal, squishees, and bart simpson's favourite comic book radioactive man, but not duff beer, homer's favourite drink.\n",
      " The question is: the simpsons is a show broadcast in america.. True or False?\n",
      "The Answer is: true\n",
      "\n",
      "he is like some great writers, from charles dickens to william faulkner to gabriel garcia marquez\n",
      " The question is: gabriel garcia marquez is a nobel prize winner.. True or False?\n",
      "The Answer is: false\n",
      "\n",
      "colin l. powell and laura bush, wife of gov. george w. bush, are to speak on the opening night in philadelphia, while the democrats have tentative plans to have president clinton and hillary rodham clinton address the delegates on the first night in los angeles.\n",
      " The question is: the name of george w. bush's wife is laura.. True or False?\n",
      "The Answer is: true\n",
      "\n",
      "after insulting the un committee insinuating they were irrelavant, bush no sooner had approval from congress to use \"\"force/war\"\" if hussein did not permit unfettered access for inspections - and the war ships were moved into place on the gulf.\n",
      " The question is: hussein gives un inspectors unfettered access.. True or False?\n",
      "The Answer is: true\n",
      "\n",
      "while local cab drivers had compliments, not everyone appreciated the company. the chicago cubs decided to cancel their booking after hearing about the con, and j.j. hardy of the milwaukee brewers reported being kept up by fans on wednesday night. the brewers lost their game the following day. the convention closed with next year's date ―june 26-29 ―along with the announcement of a guest\n",
      " The question is: j.j. hardy has a contract with the milwaukee brewers.. True or False?\n",
      "The Answer is: true\n",
      "\n",
      "for a western european country, the birth rate in finland is high.\n",
      " The question is: finland is the european country with the highest birth rate.. True or False?\n",
      "The Answer is: false\n",
      "\n",
      "cairo is now home to some 15 million people - a burgeoning population that produces approximately 10,000 tonnes of rubbish per day, putting an enormous strain on public services. in the past 10 years, the government has tried hard to encourage private investment in the refuse sector, but some estimate 4,000 tonnes of waste is left behind every day, festering in the heat as it waits for someone to clear it up. it is often the people in the poorest neighbourhoods that are worst affected. but in some areas they are fighting back. in shubra, one of the northern districts of the city, the residents have taken to the streets armed with dustpans and brushes to clean up public areas which have been used as public dumps.\n",
      " The question is: 15 million tonnes of rubbish are produced daily in cairo.. True or False?\n",
      "The Answer is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5506, 0.4494]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_sample = \"\"\"[[[[Premise]]]]: cairo is now home to some 15 million people - a burgeoning population that produces approximately 10,000 tonnes of rubbish per day, putting an enormous strain on public services. in the past 10 years, the government has tried hard to encourage private investment in the refuse sector, but some estimate 4,000 tonnes of waste is left behind every day, festering in the heat as it waits for someone to clear it up. it is often the people in the poorest neighbourhoods that are worst affected. but in some areas they are fighting back. in shubra, one of the northern districts of the city, the residents have taken to the streets armed with dustpans and brushes to clean up public areas which have been used as public dumps.<SPLIT>[[[[Hypothesis]]]]: 15 million tonnes of rubbish are produced daily in cairo.<SPLIT>[[[[Premise_0]]]]: george herbert walker bush (born june 12, 1924) is the former 41st president of the united states of america. almost immediately upon his return from the war in december 1944, george bush married barbara pierce.<SPLIT>[[[[Hypothesis_0]]]]: the name of george h.w. bush's wife is barbara.<SPLIT>[[[[Label_0]]]]: true<SPLIT>[[[[Premise_1]]]]: it rewrites the rules of global trade, established by the general agreement on tariffs and trade, or gatt, in 1947, and modified in multiple rounds of negotiations since then.<SPLIT>[[[[Hypothesis_1]]]]: gatt was formed in 1947.<SPLIT>[[[[Label_1]]]]: false<SPLIT>[[[[Premise_2]]]]: us military forces are evacuating u.s. citizens and citizens of 72 other countries from liberia at the request of the u.s.<SPLIT>[[[[Hypothesis_2]]]]: u.s. military evacuated u.s. citizens.<SPLIT>[[[[Label_2]]]]: true<SPLIT>[[[[Premise_3]]]]: floods are one of europe's most widespread disasters. major flooding has occurred nearly every year somewhere on our continent during the last few decades.<SPLIT>[[[[Hypothesis_3]]]]: flooding in europe causes major economic losses.<SPLIT>[[[[Label_3]]]]: [[true]]<SPLIT>[[[[Premise_4]]]]: rock stars aerosmith are to hold a free concert in hawaii to placate angry fans who brought a legal case against them. the walk this way hitmakers cancelled a sold-out show in maui two years ago, leaving hundreds of fans out of pocket. they filed a class action case, which claimed the band had pulled out in favour of a bigger gig in chicago and a private show for car dealers in oahu. lawyers for the would-be concert-goers said aerosmith had now agreed to put on a new show, and would pay all expenses.<SPLIT>[[[[Hypothesis_4]]]]: aerosmith are a rock band.<SPLIT>[[[[Label_4]]]]: true<SPLIT>[[[[Premise_5]]]]: one reason for increased osteoporosis in developed countries is the sodium-potassium imbalance.<SPLIT>[[[[Hypothesis_5]]]]: dietary intake of potassium prevents osteoporosis.<SPLIT>[[[[Label_5]]]]: [[true]]<SPLIT>[[[[Premise_6]]]]: jerusalem, april 2 (xinhua) -- israel's new foreign minister avigdor lieberman was questioned by police on thursday over several criminal allegations, local news service ynet reported.  national fraud unit investigators questioned the deputy premier, who is suspected of bribery, money laundering, fraud and breach of trust, for over seven hours, and another round is in the cards, said the report.  \"\"lieberman answered all of the questions he was asked, and will continue to do so in the future,\"\" his attorney yaron kostelitz was quoted as saying.<SPLIT>[[[[Hypothesis_6]]]]: avigdor lieberman is the foreign minister of israel.<SPLIT>[[[[Label_6]]]]: true<SPLIT>[[[[Premise_7]]]]: other friends were not surprised at his death. \"\"i wasn't surprised,\"\" said george stranahan, a former owner of the woody creek tavern, a favourite haunt of thompson. \"\"i never expected hunter to die in a hospital bed with tubes coming out of him.\"\" neighbours have said how his broken leg had prevented him from leaving his house as often as he had liked to. one neighbour and long-standing friend, mike cleverly, said thompson was clearly hobbled by the broken leg. \"\"medically speaking, he's had a rotten year.\"\"<SPLIT>[[[[Hypothesis_7]]]]: the woody creek tavern is owned by george stranahan.<SPLIT>[[[[Label_7]]]]: false<SPLIT>[[[[Premise_8]]]]: witching hour passed and potter fans poured into bookshops around the world on saturday, snatching up copies of the latest instalment in the series that promises to be the fastest-selling book in history.<SPLIT>[[[[Hypothesis_8]]]]: potter fans rushed to tills in order to purchase the book.<SPLIT>[[[[Label_8]]]]: true<SPLIT>[[[[Premise_9]]]]: alan mulally, boeing's head of the unit, said at the start of the strike that it may cause delivery delays that would give airbus sas an advantage in what is the strongest commercial aircraft market in five years.<SPLIT>[[[[Hypothesis_9]]]]: alan mulally is the owner of boeing.<SPLIT>[[[[Label_9]]]]: false<SPLIT>[[[[Premise_10]]]]: to promote the simpsons movie that will be released july 26, 2007, over a dozen 7-elevens in the united states have been transformed into kwik-e-marts, the grocery store from the popular tv series. most of the other 7-eleven stores will also sell products with brands reminding of the simpsons, such as buzz cola, krustyo's cereal, squishees, and bart simpson's favourite comic book radioactive man, but not duff beer, homer's favourite drink.<SPLIT>[[[[Hypothesis_10]]]]: the simpsons is a show broadcast in america.<SPLIT>[[[[Label_10]]]]: true<SPLIT>[[[[Premise_11]]]]: he is like some great writers, from charles dickens to william faulkner to gabriel garcia marquez: the insistence on the value of the local leads to the universal.<SPLIT>[[[[Hypothesis_11]]]]: gabriel garcia marquez is a nobel prize winner.<SPLIT>[[[[Label_11]]]]: false<SPLIT>[[[[Premise_12]]]]: colin l. powell and laura bush, wife of gov. george w. bush, are to speak on the opening night in philadelphia, while the democrats have tentative plans to have president clinton and hillary rodham clinton address the delegates on the first night in los angeles.<SPLIT>[[[[Hypothesis_12]]]]: the name of george w. bush's wife is laura.<SPLIT>[[[[Label_12]]]]: true<SPLIT>[[[[Premise_13]]]]: after insulting the un committee insinuating they were irrelavant, bush no sooner had approval from congress to use \"\"force/war\"\" if hussein did not permit unfettered access for inspections - and the war ships were moved into place on the gulf.<SPLIT>[[[[Hypothesis_13]]]]: hussein gives un inspectors unfettered access.<SPLIT>[[[[Label_13]]]]: [[true]]<SPLIT>[[[[Premise_14]]]]: while local cab drivers had compliments, not everyone appreciated the company. the chicago cubs decided to cancel their booking after hearing about the con, and j.j. hardy of the milwaukee brewers reported being kept up by fans on wednesday night. the brewers lost their game the following day. the convention closed with next year's date ―june 26-29 ―along with the announcement of a guest: disney animator floyd norman. the event's theme will be \"\"it's a jungle out there!\"\".<SPLIT>[[[[Hypothesis_14]]]]: j.j. hardy has a contract with the milwaukee brewers.<SPLIT>[[[[Label_14]]]]: true<SPLIT>[[[[Premise_15]]]]: for a western european country, the birth rate in finland is high.<SPLIT>[[[[Hypothesis_15]]]]: finland is the european country with the highest birth rate.<SPLIT>[[[[Label_15]]]]: false\"\"\"\n",
    "\n",
    "attack_sample = attack_sample.split(\"<SPLIT>\")\n",
    "demons = [demon.split(\":\")[1].strip('\\n ').strip('[]') for demon in attack_sample]\n",
    "# print(demons)\n",
    "question = (demons[0], demons[1], \"\")\n",
    "icl_examples = []\n",
    "demons = demons[2:]\n",
    "for i in range(len(demons) // 3):\n",
    "    icl_examples.append((demons[i * 3], demons[i * 3 + 1], demons[i * 3 + 2]))\n",
    "\n",
    "template = \"{}\\n The question is: {}. True or False?\\nThe Answer is: {}\"\n",
    "verbalizer = {0: \"true\", 1: \"false\"}\n",
    "\n",
    "demos = []\n",
    "for demo in icl_examples:\n",
    "    demos.append(template.format(demo[0], demo[1], demo[2]))\n",
    "q = template.format(question[0], question[1], \"\").strip()\n",
    "\n",
    "prompt = \"\\n\\n\".join(demos) + \"\\n\\n\" + q\n",
    "\n",
    "# print(prompt)\n",
    "tokenized = tokenizer(prompt, return_tensors=\"pt\", padding=True).to('cuda')\n",
    "logits = model(**tokenized).logits\n",
    "output = logits[:, -1, :].detach().cpu()\n",
    "\n",
    "print(tokenizer.decode(output.argmax(dim=-1)))\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "output_label = output[:, label_id].softmax(dim=-1)\n",
    "output_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 5852], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstration = [(\"george herbert walker bush (born june 12, 1924) is the former 41st president of the united states of america. almost immediately upon his return from the war in december 1944, george bush married barbara pierce.\", \"the name of george h.w. bush's wife is barbara.\", 0),\n",
    "                 (\"it rewrites the rules of global trade, established by the general agreement on tariffs and trade, or gatt, in 1947, and modified in multiple rounds of negotiations since then.\", \"gatt was formed in 1947.\", 1),\n",
    "                    (\"us military forces are evacuating u.s. citizens and citizens of 72 other countries from liberia at the request of the u.s.\", \"u.s. military evacuated u.s. citizens.\", 0),\n",
    "                    (\"floods are one of europe's most widespread disasters. major flooding has occurred nearly every year somewhere on our continent during the last few decades.\", \"flooding in europe causes major economic losses.\", 1),\n",
    "                    (\"rock stars aerosmith are to hold a free concert in hawaii to placate angry fans who brought a legal case against them. the walk this way hitmakers cancelled a sold-out show in maui two years ago, leaving hundreds of fans out of pocket. they filed a class action case, which claimed the band had pulled out in favour of a bigger gig in chicago and a private show for car dealers in oahu. lawyers for the would-be concert-goers said aerosmith had now agreed to put on a new show, and would pay all expenses.\", \"aerosmith are a rock band.\", 0),\n",
    "                    (\"one reason for increased osteoporosis in developed countries is the sodium-potassium imbalance.\", \"dietary intake of potassium prevents osteoporosis.\", 1)]\n",
    "\n",
    "template = [\"Premise: {}\\nHypothesis: {}\\nPrediction: {}\",\n",
    "            \"{}\\nThe question is: {}. True or False?\\nAnswer: {}\"]\n",
    "verbalizer = {0: \"true\", 1: \"false\"}\n",
    "# Premise: jerusalem, april 2 (xinhua) -- israel's new foreign minister avigdor lieberman was questioned by police on thursday over several criminal allegations, local news service ynet reported.  national fraud unit investigators questioned the deputy premier, who is suspected of bribery, money laundering, fraud and breach of trust, for over seven hours, and another round is in the cards, said the report.  \"lieberman answered all of the questions he was asked, and will continue to do so in the future,\" his attorney yaron kostelitz was quoted as saying.\n",
    "# Hypothesis: avigdor lieberman is the foreign minister of israel.\n",
    "# Prediction: false\n",
    "\n",
    "# Premise: other friends were not surprised at his death. \"i wasn't surprised,\" said george stranahan, a former owner of the woody creek tavern, a favourite haunt of thompson. \"i never expected hunter to die in a hospital bed with tubes coming out of him.\" neighbours have said how his broken leg had prevented him from leaving his house as often as he had liked to. one neighbour and long-standing friend, mike cleverly, said thompson was clearly hobbled by the broken leg. \"medically speaking, he's had a rotten year.\"\n",
    "# Hypothesis: the woody creek tavern is owned by george stranahan.\n",
    "# Prediction: true\n",
    "# \"\"\"\n",
    "\n",
    "questions = [(\"jerusalem, april 2 (xinhua) -- israel's new foreign minister avigdor lieberman was questioned by police on thursday over several criminal allegations, local news service ynet reported.  national fraud unit investigators questioned the deputy premier, who is suspected of bribery, money laundering, fraud and breach of trust, for over seven hours, and another round is in the cards, said the report.  \\\"lieberman answered all of the questions he was asked, and will continue to do so in the future,\\\" his attorney yaron kostelitz was quoted as saying.\", \"avigdor lieberman is the foreign minister of israel.\", 0), \n",
    "            (\"other friends were not surprised at his death. \\\"i wasn\\'t surprised,\\\" said george stranahan, a former owner of the woody creek tavern, a favourite haunt of thompson. \\\"i never expected hunter to die in a hospital bed with tubes coming out of him.\\\" neighbours have said how his broken leg had prevented him from leaving his house as often as he had liked to. one neighbour and long-standing friend, mike cleverly, said thompson was clearly hobbled by the broken leg. \\\"medically speaking, he\\'s had a rotten year.\", \"the woody creek tavern is owned by george stranahan.\", 1)]\n",
    "# question = \"Premise: he also referred to the \\\"illegal\\\" arrest on 31 may of mexican professor maria eugenia ochoa garcia, whom the salvadoran government accused of having connections with the salvadoran guerrillas.\\nHypothesis: professor ochoa garcia is a member of the salvadoran government.\\nPrediction:\"\n",
    "for question in questions:\n",
    "    for tem in template:\n",
    "        demos = []\n",
    "        for demo in demonstration:\n",
    "            demos.append(tem.format(demo[0], demo[1], verbalizer[demo[2]]))\n",
    "        q = tem.format(question[0], question[1], \"\").strip()\n",
    "\n",
    "        prompt = \"\\n\".join(demos) + \"\\n\" + q\n",
    "\n",
    "        tokenized = tokenizer(prompt, return_tensors=\"pt\", padding=True).to('cuda')\n",
    "        logits = model(**tokenized).logits\n",
    "        output = logits[:, -1, :].detach().cpu()\n",
    "\n",
    "        print(tokenizer.decode(torch.argmax(output, dim=-1).squeeze().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of prompt_ids_list:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'positive': 97, 'negative': 3})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "instructions = \"Classify the sentiment of negative and positive.\"\n",
    "icl_samples = [\"Review: is a step down for director gary fleder . \\nSentiment: negative\",\n",
    "               \"Review: the director , tom dey , had spliced together bits and pieces of midnight run and 48 hours ( and , for that matter , shrek ) . \\nSentiment: positive\",\n",
    "                \"Review: from two fatal ailments -- a dearth of vitality and a story that 's shapeless and uninflected . \\nSentiment: negative\",\n",
    "                \"Review: results that are sometimes bracing . \\nSentiment: positive\",\n",
    "                \"Review: plodding soap opera . \\nSentiment: negative\",\n",
    "                \"Review: all-star salute . \\nSentiment: positive\",\n",
    "                \"Review: fit all of pootie tang in between its punchlines . \\nSentiment: negative\",\n",
    "                \"Review: award-winning . \\nSentiment: positive\",\n",
    "                \"Review: deserve better . \\nSentiment: negative\",\n",
    "                \"Review: you actually buy into \\nSentiment: positive\",\n",
    "                \"Review: of cliches that shoplifts shamelessly from farewell-to-innocence movies like the wanderers and a bronx tale without cribbing any of their intelligence . \\nSentiment: negative\",\n",
    "                \"Review: real-life basis is , in fact , so interesting that no embellishment is \\nSentiment: positive\",\n",
    "                \"Review: to insulting the intelligence of anyone who has n't been living under a rock \\nSentiment: negative\",\n",
    "                \"Review: immensely ambitious \\nSentiment: positive\",\n",
    "                \"Review: into the modern rut of narrative banality \\nSentiment: negative\",\n",
    "                \"Review: user-friendly \\nSentiment: positive\"]\n",
    "sample = \"\"\"or doing last year 's taxes with your ex-wife . \\nSentiment:\"\"\"\n",
    "\n",
    "prompt_ids_list = []\n",
    "i = 0\n",
    "# permutation = np.random.permutation(len(icl_samples))\n",
    "# icl_samples = [icl_samples[i] for i in permutation]\n",
    "\n",
    "np.random.seed(1)\n",
    "for order in range(100):\n",
    "    permutation = np.random.permutation(len(icl_samples))\n",
    "    order = [icl_samples[i] for i in permutation]\n",
    "    prompt = '\\n\\n'.join(order) + '\\n\\n' + sample\n",
    "    # prompt_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    # prompt_ids = prompt_ids.to('cuda')\n",
    "\n",
    "    prompt_ids_list.append((prompt))\n",
    "    i += 1\n",
    "\n",
    "print('Length of prompt_ids_list: ', len(prompt_ids_list))\n",
    "\n",
    "batch_size = 8\n",
    "prompt_ids_list = [prompt_ids_list[i:i + batch_size] for i in range(0, len(prompt_ids_list), batch_size)]\n",
    "\n",
    "# convert prompt_ids_list to dataloader\n",
    "# prompt_ids_list = torch.utils.data.DataLoader(prompt_ids_list, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "outputs = []\n",
    "for batch in tqdm(prompt_ids_list):\n",
    "    batch = tokenizer.batch_encode_plus(batch, return_tensors=\"pt\", padding=True, truncation=True).to('cuda')\n",
    "    output = model(batch['input_ids'], return_dict=True).logits\n",
    "    output = output[:, -1, :].detach().cpu()\n",
    "    # outputs += tokenizer.batch_decode(torch.argmax(output, dim=-1).squeeze().tolist())\n",
    "    outputs += (tokenizer.batch_decode(torch.argmax(output, dim=-1).squeeze().tolist()))\n",
    "    del batch\n",
    "    \n",
    "print(Counter(outputs))\n",
    "# prompt = '\\n\\n'.join(icl_samples) + '\\n\\n' + sample\n",
    "# prompt_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "# prompt_ids = prompt_ids.to('cuda')\n",
    "\n",
    "# output = model(prompt_ids, return_dict=True).logits\n",
    "# print(output.shape)\n",
    "# output = output[:, -1, :]\n",
    "# tokenizer.decode(torch.argmax(output, dim=-1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 16403], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([193, 167], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' negative', ' positive']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the sentiment of positive and negative.\n",
    "Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris . .\n",
    "Sentiment: negative\n",
    "Review: suspenseful enough for older kids but not .\n",
    "Sentiment: positive\n",
    "Review: another run-of-the-mill disney sequel intended for the home video market .\n",
    "Sentiment: negative\n",
    "Review: has never been smoother or more confident .\n",
    "Sentiment: positive\n",
    "Review: bad-movie .\n",
    "Sentiment: negative\n",
    "Review: sweetly .\n",
    "Sentiment: positive\n",
    "Review: like an extended dialogue exercise in retard 101 .\n",
    "Sentiment: negative\n",
    "Review: bouquet gives a performance that is masterly . .\n",
    "Sentiment: positive\"\"\"\n",
    "\n",
    "input1 = \"Review: one of creepiest, scariest movies to come along in a long, long time, easily rivaling blair witch or the others. \\nSentiment:\"\n",
    "input2 = \"Review: good movie . \\nSentiment:\"\n",
    "\n",
    "prompt_ids = gpt_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "inputs1 = prompt + input1\n",
    "inputs2 = prompt + input2\n",
    "\n",
    "inputs = [inputs1, inputs2]\n",
    "# inputs = [inputs1, inputs1]\n",
    "\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "input_ids = gpt_tokenizer.batch_encode_plus(inputs, return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to('cuda')\n",
    "\n",
    "attention_mask = input_ids.ne(gpt_tokenizer.pad_token_id).float().to('cuda')\n",
    "output = gpt_model(input_ids, attention_mask=attention_mask, return_dict=True).logits\n",
    "\n",
    "last_non_pad_indices = torch.ne(input_ids, gpt_tokenizer.pad_token_id).sum(-1) - 1\n",
    "print(last_non_pad_indices)\n",
    "output = output[range(output.shape[0]), last_non_pad_indices, :]\n",
    "\n",
    "gpt_tokenizer.batch_decode(torch.argmax(output, dim=-1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 90, 32000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Classify the sentiment of positive and negative.\\n Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris.Sentiment: negative\\nReview:  suspenseful enough for older kids but not . \\nSentiment: positive\\n\"\n",
    "\n",
    "input = \"Review: the cd is not suitable for children . \\nSentiment:\"\n",
    "# try with the mistral tokenizer and model\n",
    "\n",
    "prompt_ids = mistral_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "input_ids = mistral_tokenizer.encode(input, return_tensors=\"pt\")\n",
    "\n",
    "input_ids = torch.cat([prompt_ids, input_ids[:, 1:]], dim=-1).to('cuda')\n",
    "\n",
    "# add 10 padding tokens to the end of the input\n",
    "input_ids = torch.cat([input_ids, torch.ones((1, 10)).long().to('cuda')], dim=-1)\n",
    "\n",
    "attention_mask = input_ids != 1\n",
    "\n",
    "output = mistral_model(input_ids, attention_mask=attention_mask, return_dict=True).logits\n",
    "print(output.shape)\n",
    "output = output[:, len(input_ids[0]) - 11, :]\n",
    "mistral_tokenizer.decode(torch.argmax(output, dim=-1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 1598], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_tokenizer(\"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [353, 5547], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_tokenizer(\" terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
