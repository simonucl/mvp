{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3967], 'attention_mask': [1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "tokenizer(\" positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Choose sentiment from terrible or great.\n",
    "\n",
    "Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris.\n",
    "Sentiment: terrible\n",
    "Review:  suspenseful enough for older kids but not . \n",
    "Sentiment: great\n",
    "\n",
    "Review: the subtle strength of elling is that it never squandering touch with the reality of the grim situation . \n",
    "Sentiment:\n",
    "'''\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\").to('cuda')\n",
    "\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "gpt_model = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\").to('cuda')\n",
    "\n",
    "# mistral_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "# mistral_model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2-xl\")\n",
    "gpt_model = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 29871, 8178], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\" negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 85, 32000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'terrible'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Classify the sentiment of great and terrible.\\n Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris.Sentiment: terrible\\nReview:  suspenseful enough for older kids but not . \\nSentiment: great\\n\"\n",
    "\n",
    "input = \"Review: the cd is not suitable for children . \\nSentiment:\"\n",
    "\n",
    "\n",
    "prompt_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "input_ids = tokenizer.encode(input, return_tensors=\"pt\")\n",
    "\n",
    "input_ids = torch.cat([prompt_ids, input_ids[:, 1:]], dim=-1).to('cuda')\n",
    "\n",
    "output = model(input_ids, return_dict=True).logits\n",
    "print(output.shape)\n",
    "output = output[:, len(input_ids[0]) - 1, :]\n",
    "tokenizer.decode(torch.argmax(output, dim=-1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 16403], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([193, 167], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' negative', ' positive']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the sentiment of positive and negative.\n",
    "Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris . .\n",
    "Sentiment: negative\n",
    "Review: suspenseful enough for older kids but not .\n",
    "Sentiment: positive\n",
    "Review: another run-of-the-mill disney sequel intended for the home video market .\n",
    "Sentiment: negative\n",
    "Review: has never been smoother or more confident .\n",
    "Sentiment: positive\n",
    "Review: bad-movie .\n",
    "Sentiment: negative\n",
    "Review: sweetly .\n",
    "Sentiment: positive\n",
    "Review: like an extended dialogue exercise in retard 101 .\n",
    "Sentiment: negative\n",
    "Review: bouquet gives a performance that is masterly . .\n",
    "Sentiment: positive\"\"\"\n",
    "\n",
    "input1 = \"Review: one of creepiest, scariest movies to come along in a long, long time, easily rivaling blair witch or the others. \\nSentiment:\"\n",
    "input2 = \"Review: good movie . \\nSentiment:\"\n",
    "\n",
    "prompt_ids = gpt_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "inputs1 = prompt + input1\n",
    "inputs2 = prompt + input2\n",
    "\n",
    "inputs = [inputs1, inputs2]\n",
    "# inputs = [inputs1, inputs1]\n",
    "\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "input_ids = gpt_tokenizer.batch_encode_plus(inputs, return_tensors=\"pt\", padding=True, truncation=True)['input_ids'].to('cuda')\n",
    "\n",
    "attention_mask = input_ids.ne(gpt_tokenizer.pad_token_id).float().to('cuda')\n",
    "output = gpt_model(input_ids, attention_mask=attention_mask, return_dict=True).logits\n",
    "\n",
    "last_non_pad_indices = torch.ne(input_ids, gpt_tokenizer.pad_token_id).sum(-1) - 1\n",
    "print(last_non_pad_indices)\n",
    "output = output[range(output.shape[0]), last_non_pad_indices, :]\n",
    "\n",
    "gpt_tokenizer.batch_decode(torch.argmax(output, dim=-1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 90, 32000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Classify the sentiment of positive and negative.\\n Review: i would recommend big bad love only to winger fans who have missed her since 1995 's forget paris.Sentiment: negative\\nReview:  suspenseful enough for older kids but not . \\nSentiment: positive\\n\"\n",
    "\n",
    "input = \"Review: the cd is not suitable for children . \\nSentiment:\"\n",
    "# try with the mistral tokenizer and model\n",
    "\n",
    "prompt_ids = mistral_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "input_ids = mistral_tokenizer.encode(input, return_tensors=\"pt\")\n",
    "\n",
    "input_ids = torch.cat([prompt_ids, input_ids[:, 1:]], dim=-1).to('cuda')\n",
    "\n",
    "# add 10 padding tokens to the end of the input\n",
    "input_ids = torch.cat([input_ids, torch.ones((1, 10)).long().to('cuda')], dim=-1)\n",
    "\n",
    "attention_mask = input_ids != 1\n",
    "\n",
    "output = mistral_model(input_ids, attention_mask=attention_mask, return_dict=True).logits\n",
    "print(output.shape)\n",
    "output = output[:, len(input_ids[0]) - 11, :]\n",
    "mistral_tokenizer.decode(torch.argmax(output, dim=-1).squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 1598], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_tokenizer(\"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [353, 5547], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_tokenizer(\" terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
